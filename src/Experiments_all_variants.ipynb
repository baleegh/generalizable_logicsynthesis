{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "667f7342",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e0ed0699",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get all the train and test files\n",
    "\n",
    "train_files = []\n",
    "test_files = []\n",
    "\n",
    "for (dirpath, dirnames, filenames) in os.walk( 'iwls2020-lsml-contest/benchmarks/train/' ):\n",
    "    for file in filenames:\n",
    "      train_files.append(os.path.join(dirpath,file) )\n",
    "for (dirpath, dirnames, filenames) in os.walk( 'iwls2020-lsml-contest/benchmarks/vaidation/' ):\n",
    "    for file in filenames:\n",
    "      train_files.append(os.path.join(dirpath,file) )\n",
    "for (dirpath, dirnames, filenames) in os.walk( 'iwls2020-lsml-contest/benchmarks/test/' ):\n",
    "    for file in filenames:\n",
    "      test_files.append(os.path.join(dirpath,file) )\n",
    "\n",
    "train_files.sort()\n",
    "test_files.sort()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b9f58d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1a - 2 layer NN with pruning\n",
    "\n",
    "def split(word): \n",
    "    return [char for char in word] \n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size,10)\n",
    "    self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    return x\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  output = output >=0.5\n",
    "  acc = torch.sum(output==labels)/len(labels)\n",
    "  return acc\n",
    "\n",
    "def get_tensors_from_example_files(train_file, test_file):\n",
    "  ''' get features and label tensors from training and test files'''\n",
    "  file_train_data = open(train_file, 'r')\n",
    "  file_train_data = file_train_data.readlines()\n",
    "\n",
    "  file_test_data = open(test_file, 'r')\n",
    "  file_test_data = file_test_data.readlines()\n",
    "\n",
    "  # preprocess files to separate inputs and outputs\n",
    "  x_train = []\n",
    "  y_train = []\n",
    "  for line in file_train_data:\n",
    "    if not (line.startswith('.')):\n",
    "      x_train.append( line[:line.index(' ')] )\n",
    "      y_train.append( line[ line.index(' ')+1:line.index(' ')+2 ] ) \n",
    "\n",
    "  x_test = []\n",
    "  y_test = []\n",
    "  for line in file_test_data:\n",
    "    if not (line.startswith('.')):\n",
    "      x_test.append( line[:line.index(' ')] )\n",
    "      y_test.append( line[ line.index(' ')+1:line.index(' ')+2 ] ) \n",
    "\n",
    "  # convert data to tensors\n",
    "  for i,input in enumerate(x_train):\n",
    "    x_train[i] = split(input)\n",
    "    # convert each character to integer\n",
    "    for j,bit in enumerate(x_train[i]):\n",
    "        x_train[i][j] = int(bit)\n",
    "  features_train = torch.FloatTensor(x_train)\n",
    "  y_train = [int(i) for i in y_train]\n",
    "  labels_train = torch.FloatTensor(y_train)\n",
    "\n",
    "  for i,input in enumerate(x_test):\n",
    "    x_test[i] = split(input)\n",
    "    # convert each character to integer\n",
    "    for j,bit in enumerate(x_test[i]):\n",
    "        x_test[i][j] = int(bit)\n",
    "  features_test = torch.FloatTensor(x_test)\n",
    "  y_test = [int(i) for i in y_test]\n",
    "  labels_test = torch.FloatTensor(y_test)\n",
    "\n",
    "  return features_train, labels_train, features_test, labels_test\n",
    "\n",
    "def get_dataloaders(features_train, labels_train, features_test, labels_test):\n",
    "  ''' form iterable dataloaders for features and labels'''\n",
    "  batch_size = 10\n",
    "  train_data_iter = load_array((features_train, labels_train), batch_size)\n",
    "  test_data_iter = load_array((features_train, labels_train), batch_size)\n",
    "  return train_data_iter, test_data_iter\n",
    "\n",
    "def define_neural_net(input_size):\n",
    "\n",
    "  net = BinaryClassification(input_size)\n",
    "  net.to(device)\n",
    "  Loss = nn.BCELoss()\n",
    "  optimizer = torch.optim.SGD(net.parameters(), lr=0.01)\n",
    "\n",
    "  return net, Loss, optimizer\n",
    "\n",
    "def train_truth_table( net, Loss, optimizer, train_data_iter, num_epochs, features_train, labels_train ):\n",
    "\n",
    "  net.train()\n",
    "  for epoch in range(num_epochs):\n",
    "      for X, y in train_data_iter:\n",
    "          X = X.cuda()\n",
    "          y = y.cuda()\n",
    "          output = net(X)\n",
    "          l = Loss(output, y.reshape(-1,1) )\n",
    "          optimizer.zero_grad()\n",
    "          l.backward()\n",
    "          optimizer.step()\n",
    "#       if (epoch%10==0):\n",
    "#         acc = accuracy(net(features_train.cuda()).cpu(), labels_train.reshape(-1,1))\n",
    "#         l = Loss(net(features_train.cuda()).cpu(), labels_train.reshape(-1,1))\n",
    "  \n",
    "  return net\n",
    "\n",
    "def test_net( net, test_data_iter):\n",
    "  acc = 0\n",
    "  net.eval()\n",
    "  with torch.no_grad():\n",
    "    for X,y in test_data_iter:\n",
    "      X = X.cuda()\n",
    "      output = net(X)\n",
    "      acc = acc + accuracy(output.cpu(), y.reshape(-1,1))\n",
    "    acc = acc/ len(test_data_iter)\n",
    "  return acc\n",
    "\n",
    "# get_lut_y\n",
    "def get_lut_y(input_size,w,b):\n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = 1/(1 + np.exp(-out)) >=0.5\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0   \n",
    "    return lut_y\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    remain_after_pruning = 8 + ( (10-8)/(768-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "\n",
    "    # prune first layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.3\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 10\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.4\n",
    "    )\n",
    "\n",
    "    # prune second layer\n",
    "    prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=0.3, dim=1, n='fro'\n",
    "    )\n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net\n",
    "\n",
    "def get_aig_size(net):\n",
    "    # get list of neurons in NN\n",
    "    neurons = [] # each element is a neuron with a weight vector and a bias scalar\n",
    "    weights = [] # each element is the weight matrix of a layer\n",
    "    biases  = [] # each element contains biases for that layer\n",
    "    for name, param in net.named_parameters():\n",
    "        if '.weight'in name:\n",
    "            weights.append( param.detach().cpu().numpy() )\n",
    "        if '.bias' in name:\n",
    "            biases.append( param.detach().cpu().numpy() )\n",
    "\n",
    "    weights.reverse()\n",
    "    biases.reverse()\n",
    "    ignore_neurons = [] # element in list: (i,j) neuron j in layer i\n",
    "    for i,layer_weights in enumerate(weights): # i = layer (starting from highest)\n",
    "\n",
    "        # check which neurons in lower layer can be ignored\n",
    "        for k in range( len(layer_weights[0]) ):\n",
    "            if( len( np.nonzero(layer_weights[:,k])[0] )==0 ):\n",
    "                ignore_neurons.append( (i+1,k) )\n",
    "\n",
    "        for j,weight_vector in enumerate(layer_weights): # j = neuron in layer i\n",
    "            if not (i,j) in ignore_neurons:\n",
    "                neurons.append((weight_vector,biases[i][j]))\n",
    "\n",
    "    # get size of aig  \n",
    "#     print(\"getting size of aig\")\n",
    "    size_aig = 0\n",
    "\n",
    "    for neuron in neurons: \n",
    "        '''form LUT for each neuron'''\n",
    "        w = neuron[0]\n",
    "        b = neuron[1]\n",
    "        w = w[w.nonzero()]\n",
    "        input_size = len(w)\n",
    "        # get the LUT\n",
    "        lut_y = get_lut_y(input_size, w, b)\n",
    "\n",
    "        '''create text for verilog file representing LUT'''\n",
    "        n=input_size\n",
    "#         print(input_size)\n",
    "        file_string ='module lut_verilog(\\ninput wire['+str(input_size-1)+':0] in,\\noutput reg out\\n);\\n\\nalways@(in) begin\\ncase(in)\\n'\n",
    "        input_vector = np.zeros( (input_size) )\n",
    "        for idx in range ( pow(2,input_size) ):\n",
    "            # add to file string\n",
    "            file_string += str(input_size)+'\\'b'+''.join(str(int(e)) for e in input_vector)+' : out = '+str(int(lut_y[idx]))+';\\n'\n",
    "            # increment input vector\n",
    "            for i in range(len(input_vector)-1, -1, -1):\n",
    "                if input_vector[i] == 0:\n",
    "                    input_vector[i] = 1\n",
    "                    break\n",
    "                input_vector[i] = 0\n",
    "        file_string+='endcase\\nend\\nendmodule\\n'\n",
    "\n",
    "        '''write to verilog file'''\n",
    "        f = open(\"lut_verilog.v\", \"w\")\n",
    "        f.write(file_string)\n",
    "        f.close()\n",
    "\n",
    "        '''produce the .aig file using yosys script'''\n",
    "        cmd = \"yosys neuron_to_aig_size.ys >/dev/null 2>&1\"\n",
    "        os.system(cmd)\n",
    "\n",
    "        '''get the number of and gates in aig and add to the running sum'''\n",
    "        f = open(\"lut_verilog.aig\", \"r\")\n",
    "        line = f.readline()\n",
    "        size_aig = size_aig + int(line.split(' ')[5].split('\\n')[0])\n",
    "        #     print(\"size: \", line.split(' ')[5].split('\\n')[0] )\n",
    "        #     print(\"running sum: \",size_aig)\n",
    "    return size_aig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3aee187c",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "916fbca4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  746\n",
      "test accuracy achieved:  0.5146874785423279\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  833\n",
      "test accuracy achieved:  0.933906078338623\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1834\n",
      "test accuracy achieved:  0.5320314168930054\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1811\n",
      "test accuracy achieved:  0.899686336517334\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4196\n",
      "test accuracy achieved:  0.5065627694129944\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1480\n",
      "test accuracy achieved:  0.9406243562698364\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  17706\n",
      "test accuracy achieved:  0.5460940599441528\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3359\n",
      "test accuracy achieved:  0.968593418598175\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  180419\n",
      "test accuracy achieved:  0.5090627074241638\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  44771\n",
      "test accuracy achieved:  0.9509369134902954\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1339\n",
      "test accuracy achieved:  0.798279881477356\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1464\n",
      "test accuracy achieved:  0.7360932230949402\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2468\n",
      "test accuracy achieved:  0.6610943675041199\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3501\n",
      "test accuracy achieved:  0.645156741142273\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  28840\n",
      "test accuracy achieved:  0.6582816243171692\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1379\n",
      "test accuracy achieved:  0.8281232714653015\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3465\n",
      "test accuracy achieved:  0.8364049792289734\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3559\n",
      "test accuracy achieved:  0.7753114104270935\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7443\n",
      "test accuracy achieved:  0.6401569843292236\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  29426\n",
      "test accuracy achieved:  0.8251544237136841\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  468\n",
      "test accuracy achieved:  0.5125001668930054\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  560\n",
      "test accuracy achieved:  0.5309373140335083\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  479\n",
      "test accuracy achieved:  0.49859386682510376\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  510\n",
      "test accuracy achieved:  0.5295314788818359\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1075\n",
      "test accuracy achieved:  0.5250004529953003\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  866\n",
      "test accuracy achieved:  0.5065627098083496\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3512\n",
      "test accuracy achieved:  0.53578120470047\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4252\n",
      "test accuracy achieved:  0.4903126657009125\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  15794\n",
      "test accuracy achieved:  0.5429688692092896\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  13754\n",
      "test accuracy achieved:  0.5259374976158142\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  683\n",
      "test accuracy achieved:  0.9374991655349731\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1385\n",
      "test accuracy achieved:  0.9679688215255737\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  805\n",
      "test accuracy achieved:  0.9346866607666016\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2434\n",
      "test accuracy achieved:  0.9857813715934753\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2041\n",
      "test accuracy achieved:  0.9687497019767761\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1770\n",
      "test accuracy achieved:  0.970624566078186\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2002\n",
      "test accuracy achieved:  0.9823437929153442\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3013\n",
      "test accuracy achieved:  0.9701560735702515\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2881\n",
      "test accuracy achieved:  0.9435935020446777\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2237\n",
      "test accuracy achieved:  0.9718747138977051\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  380\n",
      "test accuracy achieved:  0.5432815551757812\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  754\n",
      "test accuracy achieved:  0.6075006127357483\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  787\n",
      "test accuracy achieved:  0.528906524181366\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  639\n",
      "test accuracy achieved:  0.5210939645767212\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1524\n",
      "test accuracy achieved:  0.5295316576957703\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  791\n",
      "test accuracy achieved:  0.5214067697525024\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2131\n",
      "test accuracy achieved:  0.5337501764297485\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  856\n",
      "test accuracy achieved:  0.513750433921814\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12667\n",
      "test accuracy achieved:  0.528906524181366\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2071\n",
      "test accuracy achieved:  0.5198441743850708\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  988\n",
      "test accuracy achieved:  0.7932802438735962\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2100\n",
      "test accuracy achieved:  0.5106251239776611\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1484\n",
      "test accuracy achieved:  0.595625638961792\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1219\n",
      "test accuracy achieved:  0.7521874904632568\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1148\n",
      "test accuracy achieved:  0.7521868944168091\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  504\n",
      "test accuracy achieved:  0.8315609693527222\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2029\n",
      "test accuracy achieved:  0.6192189455032349\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  429\n",
      "test accuracy achieved:  0.9676566123962402\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1542\n",
      "test accuracy achieved:  0.8768739700317383\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12793\n",
      "test accuracy achieved:  0.6692193150520325\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1816\n",
      "test accuracy achieved:  0.7682810425758362\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  989\n",
      "test accuracy achieved:  0.7579684853553772\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1574\n",
      "test accuracy achieved:  0.8782796859741211\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1135\n",
      "test accuracy achieved:  0.8879672288894653\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1054\n",
      "test accuracy achieved:  0.9506245851516724\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1245\n",
      "test accuracy achieved:  0.7746871709823608\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1247\n",
      "test accuracy achieved:  0.7760927677154541\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1206\n",
      "test accuracy achieved:  0.7404682636260986\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1058\n",
      "test accuracy achieved:  0.9443745613098145\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  524\n",
      "test accuracy achieved:  0.9343745112419128\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  872\n",
      "test accuracy achieved:  0.9335931539535522\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  717\n",
      "test accuracy achieved:  0.9189052581787109\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  625\n",
      "test accuracy achieved:  0.8815611600875854\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1103\n",
      "test accuracy achieved:  0.6075009107589722\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  376\n",
      "test accuracy achieved:  0.5117185711860657\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  263\n",
      "test accuracy achieved:  0.3946872651576996\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1013\n",
      "test accuracy achieved:  0.793123722076416\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  853\n",
      "test accuracy achieved:  0.7931236028671265\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  479\n",
      "test accuracy achieved:  0.6417192816734314\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  981\n",
      "test accuracy achieved:  0.7931238412857056\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3315\n",
      "test accuracy achieved:  0.5768752098083496\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4352\n",
      "test accuracy achieved:  0.7396873235702515\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6597\n",
      "test accuracy achieved:  0.8343733549118042\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4939\n",
      "test accuracy achieved:  0.8339049220085144\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  13012\n",
      "test accuracy achieved:  0.7879678010940552\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7323\n",
      "test accuracy achieved:  0.5296874046325684\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8226\n",
      "test accuracy achieved:  0.5348438024520874\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3942\n",
      "test accuracy achieved:  0.7910926938056946\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12914\n",
      "test accuracy achieved:  0.8290611505508423\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10836\n",
      "test accuracy achieved:  0.7828117609024048\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  375187\n",
      "test accuracy achieved:  0.5201565027236938\n",
      "\n",
      "working on truth table:  ex91\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  476028\n",
      "test accuracy achieved:  0.5110938549041748\n",
      "\n",
      "working on truth table:  ex92\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  474636\n",
      "test accuracy achieved:  0.5476566553115845\n",
      "\n",
      "working on truth table:  ex93\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  661743\n",
      "test accuracy achieved:  0.5317188501358032\n",
      "\n",
      "working on truth table:  ex94\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1017241\n",
      "test accuracy achieved:  0.553750216960907\n",
      "\n",
      "working on truth table:  ex95\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  550106\n",
      "test accuracy achieved:  0.5987504720687866\n",
      "\n",
      "working on truth table:  ex96\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  148062\n",
      "test accuracy achieved:  0.5248436331748962\n",
      "\n",
      "working on truth table:  ex97\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  458732\n",
      "test accuracy achieved:  0.5040621757507324\n",
      "\n",
      "working on truth table:  ex98\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  396343\n",
      "test accuracy achieved:  0.4987497329711914\n",
      "\n",
      "working on truth table:  ex99\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  209708\n",
      "test accuracy achieved:  0.5329688787460327\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 1a\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)):\n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "95d77dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.5146874785423279, 746), ('ex01', 32, 0.933906078338623, 833), ('ex02', 64, 0.5320314168930054, 1834), ('ex03', 64, 0.899686336517334, 1811), ('ex04', 128, 0.5065627694129944, 4196), ('ex05', 128, 0.9406243562698364, 1480), ('ex06', 256, 0.5460940599441528, 17706), ('ex07', 256, 0.968593418598175, 3359), ('ex08', 512, 0.5090627074241638, 180419), ('ex09', 512, 0.9509369134902954, 44771), ('ex10', 32, 0.798279881477356, 1339), ('ex11', 64, 0.7360932230949402, 1464), ('ex12', 128, 0.6610943675041199, 2468), ('ex13', 256, 0.645156741142273, 3501), ('ex14', 512, 0.6582816243171692, 28840), ('ex15', 32, 0.8281232714653015, 1379), ('ex16', 64, 0.8364049792289734, 3465), ('ex17', 128, 0.7753114104270935, 3559), ('ex18', 256, 0.6401569843292236, 7443), ('ex19', 512, 0.8251544237136841, 29426), ('ex20', 16, 0.5125001668930054, 468), ('ex21', 16, 0.5309373140335083, 560), ('ex22', 32, 0.49859386682510376, 479), ('ex23', 32, 0.5295314788818359, 510), ('ex24', 64, 0.5250004529953003, 1075), ('ex25', 64, 0.5065627098083496, 866), ('ex26', 128, 0.53578120470047, 3512), ('ex27', 128, 0.4903126657009125, 4252), ('ex28', 256, 0.5429688692092896, 15794), ('ex29', 256, 0.5259374976158142, 13754), ('ex30', 20, 0.9374991655349731, 683), ('ex31', 40, 0.9679688215255737, 1385), ('ex32', 60, 0.9346866607666016, 805), ('ex33', 80, 0.9857813715934753, 2434), ('ex34', 100, 0.9687497019767761, 2041), ('ex35', 120, 0.970624566078186, 1770), ('ex36', 140, 0.9823437929153442, 2002), ('ex37', 160, 0.9701560735702515, 3013), ('ex38', 180, 0.9435935020446777, 2881), ('ex39', 200, 0.9718747138977051, 2237), ('ex40', 16, 0.5432815551757812, 380), ('ex41', 10, 0.6075006127357483, 754), ('ex42', 32, 0.528906524181366, 787), ('ex43', 18, 0.5210939645767212, 639), ('ex44', 64, 0.5295316576957703, 1524), ('ex45', 34, 0.5214067697525024, 791), ('ex46', 128, 0.5337501764297485, 2131), ('ex47', 66, 0.513750433921814, 856), ('ex48', 256, 0.528906524181366, 12667), ('ex49', 130, 0.5198441743850708, 2071), ('ex50', 19, 0.7932802438735962, 988), ('ex51', 44, 0.5106251239776611, 2100), ('ex52', 59, 0.595625638961792, 1484), ('ex53', 45, 0.7521874904632568, 1219), ('ex54', 48, 0.7521868944168091, 1148), ('ex55', 42, 0.8315609693527222, 504), ('ex56', 83, 0.6192189455032349, 2029), ('ex57', 24, 0.9676566123962402, 429), ('ex58', 80, 0.8768739700317383, 1542), ('ex59', 394, 0.6692193150520325, 12793), ('ex60', 43, 0.7682810425758362, 1816), ('ex61', 37, 0.7579684853553772, 989), ('ex62', 52, 0.8782796859741211, 1574), ('ex63', 38, 0.8879672288894653, 1135), ('ex64', 47, 0.9506245851516724, 1054), ('ex65', 19, 0.7746871709823608, 1245), ('ex66', 47, 0.7760927677154541, 1247), ('ex67', 46, 0.7404682636260986, 1206), ('ex68', 33, 0.9443745613098145, 1058), ('ex69', 16, 0.9343745112419128, 524), ('ex70', 23, 0.9335931539535522, 872), ('ex71', 23, 0.9189052581787109, 717), ('ex72', 35, 0.8815611600875854, 625), ('ex73', 16, 0.6075009107589722, 1103), ('ex74', 16, 0.5117185711860657, 376), ('ex75', 16, 0.3946872651576996, 263), ('ex76', 16, 0.793123722076416, 1013), ('ex77', 16, 0.7931236028671265, 853), ('ex78', 16, 0.6417192816734314, 479), ('ex79', 16, 0.7931238412857056, 981), ('ex80', 196, 0.5768752098083496, 3315), ('ex81', 196, 0.7396873235702515, 4352), ('ex82', 196, 0.8343733549118042, 6597), ('ex83', 196, 0.8339049220085144, 4939), ('ex84', 196, 0.7879678010940552, 13012), ('ex85', 196, 0.5296874046325684, 7323), ('ex86', 196, 0.5348438024520874, 8226), ('ex87', 196, 0.7910926938056946, 3942), ('ex88', 196, 0.8290611505508423, 12914), ('ex89', 196, 0.7828117609024048, 10836), ('ex90', 768, 0.5201565027236938, 375187), ('ex91', 768, 0.5110938549041748, 476028), ('ex92', 768, 0.5476566553115845, 474636), ('ex93', 768, 0.5317188501358032, 661743), ('ex94', 768, 0.553750216960907, 1017241), ('ex95', 768, 0.5987504720687866, 550106), ('ex96', 768, 0.5248436331748962, 148062), ('ex97', 768, 0.5040621757507324, 458732), ('ex98', 768, 0.4987497329711914, 396343), ('ex99', 768, 0.5329688787460327, 209708)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "200392ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [('ex00', 32, 0.5146874785423279, 746), ('ex01', 32, 0.933906078338623, 833), ('ex02', 64, 0.5320314168930054, 1834), ('ex03', 64, 0.899686336517334, 1811), ('ex04', 128, 0.5065627694129944, 4196), ('ex05', 128, 0.9406243562698364, 1480), ('ex06', 256, 0.5460940599441528, 17706), ('ex07', 256, 0.968593418598175, 3359), ('ex08', 512, 0.5090627074241638, 180419), ('ex09', 512, 0.9509369134902954, 44771), ('ex10', 32, 0.798279881477356, 1339), ('ex11', 64, 0.7360932230949402, 1464), ('ex12', 128, 0.6610943675041199, 2468), ('ex13', 256, 0.645156741142273, 3501), ('ex14', 512, 0.6582816243171692, 28840), ('ex15', 32, 0.8281232714653015, 1379), ('ex16', 64, 0.8364049792289734, 3465), ('ex17', 128, 0.7753114104270935, 3559), ('ex18', 256, 0.6401569843292236, 7443), ('ex19', 512, 0.8251544237136841, 29426), ('ex20', 16, 0.5125001668930054, 468), ('ex21', 16, 0.5309373140335083, 560), ('ex22', 32, 0.49859386682510376, 479), ('ex23', 32, 0.5295314788818359, 510), ('ex24', 64, 0.5250004529953003, 1075), ('ex25', 64, 0.5065627098083496, 866), ('ex26', 128, 0.53578120470047, 3512), ('ex27', 128, 0.4903126657009125, 4252), ('ex28', 256, 0.5429688692092896, 15794), ('ex29', 256, 0.5259374976158142, 13754), ('ex30', 20, 0.9374991655349731, 683), ('ex31', 40, 0.9679688215255737, 1385), ('ex32', 60, 0.9346866607666016, 805), ('ex33', 80, 0.9857813715934753, 2434), ('ex34', 100, 0.9687497019767761, 2041), ('ex35', 120, 0.970624566078186, 1770), ('ex36', 140, 0.9823437929153442, 2002), ('ex37', 160, 0.9701560735702515, 3013), ('ex38', 180, 0.9435935020446777, 2881), ('ex39', 200, 0.9718747138977051, 2237), ('ex40', 16, 0.5432815551757812, 380), ('ex41', 10, 0.6075006127357483, 754), ('ex42', 32, 0.528906524181366, 787), ('ex43', 18, 0.5210939645767212, 639), ('ex44', 64, 0.5295316576957703, 1524), ('ex45', 34, 0.5214067697525024, 791), ('ex46', 128, 0.5337501764297485, 2131), ('ex47', 66, 0.513750433921814, 856), ('ex48', 256, 0.528906524181366, 12667), ('ex49', 130, 0.5198441743850708, 2071), ('ex50', 19, 0.7932802438735962, 988), ('ex51', 44, 0.5106251239776611, 2100), ('ex52', 59, 0.595625638961792, 1484), ('ex53', 45, 0.7521874904632568, 1219), ('ex54', 48, 0.7521868944168091, 1148), ('ex55', 42, 0.8315609693527222, 504), ('ex56', 83, 0.6192189455032349, 2029), ('ex57', 24, 0.9676566123962402, 429), ('ex58', 80, 0.8768739700317383, 1542), ('ex59', 394, 0.6692193150520325, 12793), ('ex60', 43, 0.7682810425758362, 1816), ('ex61', 37, 0.7579684853553772, 989), ('ex62', 52, 0.8782796859741211, 1574), ('ex63', 38, 0.8879672288894653, 1135), ('ex64', 47, 0.9506245851516724, 1054), ('ex65', 19, 0.7746871709823608, 1245), ('ex66', 47, 0.7760927677154541, 1247), ('ex67', 46, 0.7404682636260986, 1206), ('ex68', 33, 0.9443745613098145, 1058), ('ex69', 16, 0.9343745112419128, 524), ('ex70', 23, 0.9335931539535522, 872), ('ex71', 23, 0.9189052581787109, 717), ('ex72', 35, 0.8815611600875854, 625), ('ex73', 16, 0.6075009107589722, 1103), ('ex74', 16, 0.5117185711860657, 376), ('ex75', 16, 0.3946872651576996, 263), ('ex76', 16, 0.793123722076416, 1013), ('ex77', 16, 0.7931236028671265, 853), ('ex78', 16, 0.6417192816734314, 479), ('ex79', 16, 0.7931238412857056, 981), ('ex80', 196, 0.5768752098083496, 3315), ('ex81', 196, 0.7396873235702515, 4352), ('ex82', 196, 0.8343733549118042, 6597), ('ex83', 196, 0.8339049220085144, 4939), ('ex84', 196, 0.7879678010940552, 13012), ('ex85', 196, 0.5296874046325684, 7323), ('ex86', 196, 0.5348438024520874, 8226), ('ex87', 196, 0.7910926938056946, 3942), ('ex88', 196, 0.8290611505508423, 12914), ('ex89', 196, 0.7828117609024048, 10836), ('ex90', 768, 0.5201565027236938, 375187), ('ex91', 768, 0.5110938549041748, 476028), ('ex92', 768, 0.5476566553115845, 474636), ('ex93', 768, 0.5317188501358032, 661743), ('ex94', 768, 0.553750216960907, 1017241), ('ex95', 768, 0.5987504720687866, 550106), ('ex96', 768, 0.5248436331748962, 148062), ('ex97', 768, 0.5040621757507324, 458732), ('ex98', 768, 0.4987497329711914, 396343), ('ex99', 768, 0.5329688787460327, 209708)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "64552d9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 100 benchmarks=  70.50028610229492  %\n",
      "26 networks exceeded size constraint:\n",
      "['ex06' 'ex08' 'ex09' 'ex14' 'ex18' 'ex19' 'ex28' 'ex29' 'ex48' 'ex59'\n",
      " 'ex82' 'ex84' 'ex85' 'ex86' 'ex88' 'ex89' 'ex90' 'ex91' 'ex92' 'ex93'\n",
      " 'ex94' 'ex95' 'ex96' 'ex97' 'ex98' 'ex99']\n",
      "overall accuracy across benchmarks under size constraints=  73.62306883206239  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 100 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b04ce1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp1a.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "54322e2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2a - 3 layer NN with pruning\n",
    "\n",
    "#Net\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size, input_size//2)\n",
    "    self.linear2 = nn.Linear(input_size//2, input_size//4)\n",
    "    self.linear3 = nn.Linear(input_size//4,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    x = torch.sigmoid( self.linear3(x) )\n",
    "    return x\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    remain_after_pruning = 8 + ( (10-8)/(768-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "\n",
    "    # prune first layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.3\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 10\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.4\n",
    "    )\n",
    "    \n",
    "    # prune second layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear2, 'weight', amount=0.3\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 10\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear2, 'weight', amount=0.4\n",
    "    )\n",
    "\n",
    "    input_layer3 = input_size//4\n",
    "    # map [768/4 ..... 2 ] to [12 ... 2]\n",
    "    remain_after_pruning = 2 + ( (12-2)/((768//4)-2) )*(input_layer3-2)\n",
    "    pruning_ratio_layer3 = (input_layer3-remain_after_pruning)/input_layer3\n",
    "    \n",
    "    # prune third layer\n",
    "    prune.ln_structured(\n",
    "       net.linear3, 'weight', amount=pruning_ratio_layer3, dim=1, n='fro'\n",
    "    )\n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear3, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ee1e8ff9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  424\n",
      "test accuracy achieved:  0.5079687237739563\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  807\n",
      "test accuracy achieved:  0.937498927116394\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  213\n",
      "test accuracy achieved:  0.5070310831069946\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  932\n",
      "test accuracy achieved:  0.7887492775917053\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  173\n",
      "test accuracy achieved:  0.5089061260223389\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1288\n",
      "test accuracy achieved:  0.8073423504829407\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  592\n",
      "test accuracy achieved:  0.4951561987400055\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2201\n",
      "test accuracy achieved:  0.6717190146446228\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2503\n",
      "test accuracy achieved:  0.5\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3809\n",
      "test accuracy achieved:  0.5049999952316284\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1317\n",
      "test accuracy achieved:  0.6587504744529724\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1430\n",
      "test accuracy achieved:  0.6632817983627319\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  983\n",
      "test accuracy achieved:  0.6528134942054749\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1476\n",
      "test accuracy achieved:  0.6445316076278687\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5021\n",
      "test accuracy achieved:  0.6585946679115295\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  892\n",
      "test accuracy achieved:  0.4946872591972351\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1998\n",
      "test accuracy achieved:  0.7410939335823059\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2098\n",
      "test accuracy achieved:  0.49406275153160095\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1954\n",
      "test accuracy achieved:  0.4899999499320984\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3527\n",
      "test accuracy achieved:  0.49734362959861755\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  313\n",
      "test accuracy achieved:  0.4968748092651367\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  186\n",
      "test accuracy achieved:  0.5075001120567322\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  33\n",
      "test accuracy achieved:  0.5014060735702515\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  134\n",
      "test accuracy achieved:  0.5015626549720764\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  144\n",
      "test accuracy achieved:  0.503437340259552\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  157\n",
      "test accuracy achieved:  0.5010939836502075\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  149\n",
      "test accuracy achieved:  0.4996875822544098\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  198\n",
      "test accuracy achieved:  0.5101560354232788\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  678\n",
      "test accuracy achieved:  0.5046876072883606\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  662\n",
      "test accuracy achieved:  0.5078125\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  419\n",
      "test accuracy achieved:  0.9414055943489075\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1314\n",
      "test accuracy achieved:  0.9531248211860657\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  872\n",
      "test accuracy achieved:  0.7974989414215088\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1333\n",
      "test accuracy achieved:  0.7918737530708313\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1376\n",
      "test accuracy achieved:  0.504843533039093\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  876\n",
      "test accuracy achieved:  0.5017188787460327\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1302\n",
      "test accuracy achieved:  0.7356252074241638\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1095\n",
      "test accuracy achieved:  0.8126554489135742\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1245\n",
      "test accuracy achieved:  0.645469069480896\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1720\n",
      "test accuracy achieved:  0.6748441457748413\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  66\n",
      "test accuracy achieved:  0.5021877884864807\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  85\n",
      "test accuracy achieved:  0.5821877717971802\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  174\n",
      "test accuracy achieved:  0.5007809400558472\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  226\n",
      "test accuracy achieved:  0.5023436546325684\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  242\n",
      "test accuracy achieved:  0.4989061951637268\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  148\n",
      "test accuracy achieved:  0.4895310401916504\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  72\n",
      "test accuracy achieved:  0.505937397480011\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  287\n",
      "test accuracy achieved:  0.5007813572883606\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  886\n",
      "test accuracy achieved:  0.4834372103214264\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  391\n",
      "test accuracy achieved:  0.4957813620567322\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  152\n",
      "test accuracy achieved:  0.5525004863739014\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  418\n",
      "test accuracy achieved:  0.5146876573562622\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  452\n",
      "test accuracy achieved:  0.5998443961143494\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  434\n",
      "test accuracy achieved:  0.7521870136260986\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  632\n",
      "test accuracy achieved:  0.7574991583824158\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  436\n",
      "test accuracy achieved:  0.5773441791534424\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1289\n",
      "test accuracy achieved:  0.910936713218689\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  202\n",
      "test accuracy achieved:  0.18484333157539368\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  728\n",
      "test accuracy achieved:  0.7604680061340332\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2377\n",
      "test accuracy achieved:  0.5225000977516174\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  950\n",
      "test accuracy achieved:  0.680469274520874\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  586\n",
      "test accuracy achieved:  0.7514058351516724\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1096\n",
      "test accuracy achieved:  0.851248562335968\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  684\n",
      "test accuracy achieved:  0.8873423337936401\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  491\n",
      "test accuracy achieved:  0.8873424530029297\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  435\n",
      "test accuracy achieved:  0.7584373950958252\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  731\n",
      "test accuracy achieved:  0.7898426651954651\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  797\n",
      "test accuracy achieved:  0.7809368371963501\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  647\n",
      "test accuracy achieved:  0.8792176246643066\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  371\n",
      "test accuracy achieved:  0.9460933804512024\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  375\n",
      "test accuracy achieved:  0.8728114366531372\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  598\n",
      "test accuracy achieved:  0.8998425602912903\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  513\n",
      "test accuracy achieved:  0.24999991059303284\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  207\n",
      "test accuracy achieved:  0.6410942673683167\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  45\n",
      "test accuracy achieved:  0.5117186903953552\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  71\n",
      "test accuracy achieved:  0.3946872353553772\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  149\n",
      "test accuracy achieved:  0.7931239604949951\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  134\n",
      "test accuracy achieved:  0.793123722076416\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  44\n",
      "test accuracy achieved:  0.6417196989059448\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  139\n",
      "test accuracy achieved:  0.7931238412857056\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1876\n",
      "test accuracy achieved:  0.4875001013278961\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1417\n",
      "test accuracy achieved:  0.4912498891353607\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1409\n",
      "test accuracy achieved:  0.47921842336654663\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1165\n",
      "test accuracy achieved:  0.513593852519989\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2064\n",
      "test accuracy achieved:  0.47562485933303833\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1777\n",
      "test accuracy achieved:  0.49359384179115295\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1825\n",
      "test accuracy achieved:  0.524374783039093\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1135\n",
      "test accuracy achieved:  0.4987502098083496\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1907\n",
      "test accuracy achieved:  0.4817185401916504\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1726\n",
      "test accuracy achieved:  0.4884374141693115\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6977\n",
      "test accuracy achieved:  0.5035936236381531\n",
      "\n",
      "working on truth table:  ex91\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6811\n",
      "test accuracy achieved:  0.5189059972763062\n",
      "\n",
      "working on truth table:  ex92\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  11745\n",
      "test accuracy achieved:  0.5034374594688416\n",
      "\n",
      "working on truth table:  ex93\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8845\n",
      "test accuracy achieved:  0.5064063668251038\n",
      "\n",
      "working on truth table:  ex94\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7061\n",
      "test accuracy achieved:  0.5104693174362183\n",
      "\n",
      "working on truth table:  ex95\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8751\n",
      "test accuracy achieved:  0.49312496185302734\n",
      "\n",
      "working on truth table:  ex96\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10091\n",
      "test accuracy achieved:  0.5021876692771912\n",
      "\n",
      "working on truth table:  ex97\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9984\n",
      "test accuracy achieved:  0.506250262260437\n",
      "\n",
      "working on truth table:  ex98\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8717\n",
      "test accuracy achieved:  0.4985935688018799\n",
      "\n",
      "working on truth table:  ex99\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8203\n",
      "test accuracy achieved:  0.5035935640335083\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 2a\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)):\n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "915f733f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.5079687237739563, 424), ('ex01', 32, 0.937498927116394, 807), ('ex02', 64, 0.5070310831069946, 213), ('ex03', 64, 0.7887492775917053, 932), ('ex04', 128, 0.5089061260223389, 173), ('ex05', 128, 0.8073423504829407, 1288), ('ex06', 256, 0.4951561987400055, 592), ('ex07', 256, 0.6717190146446228, 2201), ('ex08', 512, 0.5, 2503), ('ex09', 512, 0.5049999952316284, 3809), ('ex10', 32, 0.6587504744529724, 1317), ('ex11', 64, 0.6632817983627319, 1430), ('ex12', 128, 0.6528134942054749, 983), ('ex13', 256, 0.6445316076278687, 1476), ('ex14', 512, 0.6585946679115295, 5021), ('ex15', 32, 0.4946872591972351, 892), ('ex16', 64, 0.7410939335823059, 1998), ('ex17', 128, 0.49406275153160095, 2098), ('ex18', 256, 0.4899999499320984, 1954), ('ex19', 512, 0.49734362959861755, 3527), ('ex20', 16, 0.4968748092651367, 313), ('ex21', 16, 0.5075001120567322, 186), ('ex22', 32, 0.5014060735702515, 33), ('ex23', 32, 0.5015626549720764, 134), ('ex24', 64, 0.503437340259552, 144), ('ex25', 64, 0.5010939836502075, 157), ('ex26', 128, 0.4996875822544098, 149), ('ex27', 128, 0.5101560354232788, 198), ('ex28', 256, 0.5046876072883606, 678), ('ex29', 256, 0.5078125, 662), ('ex30', 20, 0.9414055943489075, 419), ('ex31', 40, 0.9531248211860657, 1314), ('ex32', 60, 0.7974989414215088, 872), ('ex33', 80, 0.7918737530708313, 1333), ('ex34', 100, 0.504843533039093, 1376), ('ex35', 120, 0.5017188787460327, 876), ('ex36', 140, 0.7356252074241638, 1302), ('ex37', 160, 0.8126554489135742, 1095), ('ex38', 180, 0.645469069480896, 1245), ('ex39', 200, 0.6748441457748413, 1720), ('ex40', 16, 0.5021877884864807, 66), ('ex41', 10, 0.5821877717971802, 85), ('ex42', 32, 0.5007809400558472, 174), ('ex43', 18, 0.5023436546325684, 226), ('ex44', 64, 0.4989061951637268, 242), ('ex45', 34, 0.4895310401916504, 148), ('ex46', 128, 0.505937397480011, 72), ('ex47', 66, 0.5007813572883606, 287), ('ex48', 256, 0.4834372103214264, 886), ('ex49', 130, 0.4957813620567322, 391), ('ex50', 19, 0.5525004863739014, 152), ('ex51', 44, 0.5146876573562622, 418), ('ex52', 59, 0.5998443961143494, 452), ('ex53', 45, 0.7521870136260986, 434), ('ex54', 48, 0.7574991583824158, 632), ('ex55', 42, 0.5773441791534424, 436), ('ex56', 83, 0.910936713218689, 1289), ('ex57', 24, 0.18484333157539368, 202), ('ex58', 80, 0.7604680061340332, 728), ('ex59', 394, 0.5225000977516174, 2377), ('ex60', 43, 0.680469274520874, 950), ('ex61', 37, 0.7514058351516724, 586), ('ex62', 52, 0.851248562335968, 1096), ('ex63', 38, 0.8873423337936401, 684), ('ex64', 47, 0.8873424530029297, 491), ('ex65', 19, 0.7584373950958252, 435), ('ex66', 47, 0.7898426651954651, 731), ('ex67', 46, 0.7809368371963501, 797), ('ex68', 33, 0.8792176246643066, 647), ('ex69', 16, 0.9460933804512024, 371), ('ex70', 23, 0.8728114366531372, 375), ('ex71', 23, 0.8998425602912903, 598), ('ex72', 35, 0.24999991059303284, 513), ('ex73', 16, 0.6410942673683167, 207), ('ex74', 16, 0.5117186903953552, 45), ('ex75', 16, 0.3946872353553772, 71), ('ex76', 16, 0.7931239604949951, 149), ('ex77', 16, 0.793123722076416, 134), ('ex78', 16, 0.6417196989059448, 44), ('ex79', 16, 0.7931238412857056, 139), ('ex80', 196, 0.4875001013278961, 1876), ('ex81', 196, 0.4912498891353607, 1417), ('ex82', 196, 0.47921842336654663, 1409), ('ex83', 196, 0.513593852519989, 1165), ('ex84', 196, 0.47562485933303833, 2064), ('ex85', 196, 0.49359384179115295, 1777), ('ex86', 196, 0.524374783039093, 1825), ('ex87', 196, 0.4987502098083496, 1135), ('ex88', 196, 0.4817185401916504, 1907), ('ex89', 196, 0.4884374141693115, 1726), ('ex90', 768, 0.5035936236381531, 6977), ('ex91', 768, 0.5189059972763062, 6811), ('ex92', 768, 0.5034374594688416, 11745), ('ex93', 768, 0.5064063668251038, 8845), ('ex94', 768, 0.5104693174362183, 7061), ('ex95', 768, 0.49312496185302734, 8751), ('ex96', 768, 0.5021876692771912, 10091), ('ex97', 768, 0.506250262260437, 9984), ('ex98', 768, 0.4985935688018799, 8717), ('ex99', 768, 0.5035935640335083, 8203)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2056a9ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp2a.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "5bc5b0c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [('ex00', 32, 0.5079687237739563, 424), ('ex01', 32, 0.937498927116394, 807), ('ex02', 64, 0.5070310831069946, 213), ('ex03', 64, 0.7887492775917053, 932), ('ex04', 128, 0.5089061260223389, 173), ('ex05', 128, 0.8073423504829407, 1288), ('ex06', 256, 0.4951561987400055, 592), ('ex07', 256, 0.6717190146446228, 2201), ('ex08', 512, 0.5, 2503), ('ex09', 512, 0.5049999952316284, 3809), ('ex10', 32, 0.6587504744529724, 1317), ('ex11', 64, 0.6632817983627319, 1430), ('ex12', 128, 0.6528134942054749, 983), ('ex13', 256, 0.6445316076278687, 1476), ('ex14', 512, 0.6585946679115295, 5021), ('ex15', 32, 0.4946872591972351, 892), ('ex16', 64, 0.7410939335823059, 1998), ('ex17', 128, 0.49406275153160095, 2098), ('ex18', 256, 0.4899999499320984, 1954), ('ex19', 512, 0.49734362959861755, 3527), ('ex20', 16, 0.4968748092651367, 313), ('ex21', 16, 0.5075001120567322, 186), ('ex22', 32, 0.5014060735702515, 33), ('ex23', 32, 0.5015626549720764, 134), ('ex24', 64, 0.503437340259552, 144), ('ex25', 64, 0.5010939836502075, 157), ('ex26', 128, 0.4996875822544098, 149), ('ex27', 128, 0.5101560354232788, 198), ('ex28', 256, 0.5046876072883606, 678), ('ex29', 256, 0.5078125, 662), ('ex30', 20, 0.9414055943489075, 419), ('ex31', 40, 0.9531248211860657, 1314), ('ex32', 60, 0.7974989414215088, 872), ('ex33', 80, 0.7918737530708313, 1333), ('ex34', 100, 0.504843533039093, 1376), ('ex35', 120, 0.5017188787460327, 876), ('ex36', 140, 0.7356252074241638, 1302), ('ex37', 160, 0.8126554489135742, 1095), ('ex38', 180, 0.645469069480896, 1245), ('ex39', 200, 0.6748441457748413, 1720), ('ex40', 16, 0.5021877884864807, 66), ('ex41', 10, 0.5821877717971802, 85), ('ex42', 32, 0.5007809400558472, 174), ('ex43', 18, 0.5023436546325684, 226), ('ex44', 64, 0.4989061951637268, 242), ('ex45', 34, 0.4895310401916504, 148), ('ex46', 128, 0.505937397480011, 72), ('ex47', 66, 0.5007813572883606, 287), ('ex48', 256, 0.4834372103214264, 886), ('ex49', 130, 0.4957813620567322, 391), ('ex50', 19, 0.5525004863739014, 152), ('ex51', 44, 0.5146876573562622, 418), ('ex52', 59, 0.5998443961143494, 452), ('ex53', 45, 0.7521870136260986, 434), ('ex54', 48, 0.7574991583824158, 632), ('ex55', 42, 0.5773441791534424, 436), ('ex56', 83, 0.910936713218689, 1289), ('ex57', 24, 0.18484333157539368, 202), ('ex58', 80, 0.7604680061340332, 728), ('ex59', 394, 0.5225000977516174, 2377), ('ex60', 43, 0.680469274520874, 950), ('ex61', 37, 0.7514058351516724, 586), ('ex62', 52, 0.851248562335968, 1096), ('ex63', 38, 0.8873423337936401, 684), ('ex64', 47, 0.8873424530029297, 491), ('ex65', 19, 0.7584373950958252, 435), ('ex66', 47, 0.7898426651954651, 731), ('ex67', 46, 0.7809368371963501, 797), ('ex68', 33, 0.8792176246643066, 647), ('ex69', 16, 0.9460933804512024, 371), ('ex70', 23, 0.8728114366531372, 375), ('ex71', 23, 0.8998425602912903, 598), ('ex72', 35, 0.24999991059303284, 513), ('ex73', 16, 0.6410942673683167, 207), ('ex74', 16, 0.5117186903953552, 45), ('ex75', 16, 0.3946872353553772, 71), ('ex76', 16, 0.7931239604949951, 149), ('ex77', 16, 0.793123722076416, 134), ('ex78', 16, 0.6417196989059448, 44), ('ex79', 16, 0.7931238412857056, 139), ('ex80', 196, 0.4875001013278961, 1876), ('ex81', 196, 0.4912498891353607, 1417), ('ex82', 196, 0.47921842336654663, 1409), ('ex83', 196, 0.513593852519989, 1165), ('ex84', 196, 0.47562485933303833, 2064), ('ex85', 196, 0.49359384179115295, 1777), ('ex86', 196, 0.524374783039093, 1825), ('ex87', 196, 0.4987502098083496, 1135), ('ex88', 196, 0.4817185401916504, 1907), ('ex89', 196, 0.4884374141693115, 1726), ('ex90', 768, 0.5035936236381531, 6977), ('ex91', 768, 0.5189059972763062, 6811), ('ex92', 768, 0.5034374594688416, 11745), ('ex93', 768, 0.5064063668251038, 8845), ('ex94', 768, 0.5104693174362183, 7061), ('ex95', 768, 0.49312496185302734, 8751), ('ex96', 768, 0.5021876692771912, 10091), ('ex97', 768, 0.506250262260437, 9984), ('ex98', 768, 0.4985935688018799, 8717), ('ex99', 768, 0.5035935640335083, 8203)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b52922bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 100 benchmarks=  60.59670150279999  %\n",
      "11 networks exceeded size constraint:\n",
      "['ex14' 'ex90' 'ex91' 'ex92' 'ex93' 'ex94' 'ex95' 'ex96' 'ex97' 'ex98'\n",
      " 'ex99']\n",
      "overall accuracy across benchmarks under size constraints=  61.67589218428965  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 100 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e0667483",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f1490789790>]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(aig_sizes, '.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "62b39b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 32  32  64  64 128 128 256 256 512 512  32  64 128 256 512  32  64 128\n",
      " 256 512  16  16  32  32  64  64 128 128 256 256  20  40  60  80 100 120\n",
      " 140 160 180 200  16  10  32  18  64  34 128  66 256 130  19  44  59  45\n",
      "  48  42  83  24  80 394  43  37  52  38  47  19  47  46  33  16  23  23\n",
      "  35  16  16  16  16  16  16  16 196 196 196 196 196 196 196 196 196 196\n",
      " 768 768 768 768 768 768 768 768 768 768]\n"
     ]
    }
   ],
   "source": [
    "print(input_sizes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "035a3884",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[512 768 768 768 768 768 768 768 768 768 768]\n"
     ]
    }
   ],
   "source": [
    "print(input_sizes[size_exceeded])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d861a9a",
   "metadata": {},
   "source": [
    "insight: cater the pruning to sizes 512 and lower and see improvements in accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "fbefcada",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 2b - 3 layer NN with pruning (ignoring size of circuit > 768)\n",
    "\n",
    "#Net\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size, input_size//2)\n",
    "    self.linear2 = nn.Linear(input_size//2, input_size//4)\n",
    "    self.linear3 = nn.Linear(input_size//4,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    x = torch.sigmoid( self.linear3(x) )\n",
    "    return x\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    \n",
    "    # map [512 ..... 10 ] to [12 ... 8]\n",
    "    remain_after_pruning = 8 + ( (12-8)/(512-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "    # prune first layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.1\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 12\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.2\n",
    "    )\n",
    "    \n",
    "    input_layer2 = input_size//2\n",
    "    # map [256 ..... 5 ] to [12 ... 5]\n",
    "    remain_after_pruning = 5 + ( (12-5)/(256-5) )*(input_layer2-5)\n",
    "    pruning_ratio = (input_layer2-remain_after_pruning)/input_layer2\n",
    "    # prune second layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear2, 'weight', amount=0.1\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 12\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear2, 'weight', amount=0.2\n",
    "    )\n",
    "\n",
    "    input_layer3 = input_size//4\n",
    "    # map [128 ..... 2 ] to [12 ... 2]\n",
    "    remain_after_pruning = 2 + ( (12-2)/(128-2) )*(input_layer3-2)\n",
    "    pruning_ratio_layer3 = (input_layer3-remain_after_pruning)/input_layer3\n",
    "    # prune third layer\n",
    "    prune.ln_structured(\n",
    "       net.linear3, 'weight', amount=pruning_ratio_layer3, dim=1, n='fro'\n",
    "    )\n",
    "    \n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear3, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "086ad69a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  787\n",
      "test accuracy achieved:  0.5079687237739563\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1704\n",
      "test accuracy achieved:  0.9060929417610168\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1099\n",
      "test accuracy achieved:  0.4929686188697815\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2309\n",
      "test accuracy achieved:  0.9645308256149292\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2447\n",
      "test accuracy achieved:  0.5089065432548523\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5616\n",
      "test accuracy achieved:  0.8262486457824707\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5931\n",
      "test accuracy achieved:  0.5048436522483826\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  11249\n",
      "test accuracy achieved:  0.702968955039978\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  73272\n",
      "test accuracy achieved:  0.49999985098838806\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  107942\n",
      "test accuracy achieved:  0.5131253004074097\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1312\n",
      "test accuracy achieved:  0.7264061570167542\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2297\n",
      "test accuracy achieved:  0.6632816195487976\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4619\n",
      "test accuracy achieved:  0.6467191576957703\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10718\n",
      "test accuracy achieved:  0.6445317268371582\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  145821\n",
      "test accuracy achieved:  0.6585944890975952\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1829\n",
      "test accuracy achieved:  0.5053125619888306\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2357\n",
      "test accuracy achieved:  0.5009377002716064\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6745\n",
      "test accuracy achieved:  0.835623562335968\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  16492\n",
      "test accuracy achieved:  0.4900001585483551\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  107537\n",
      "test accuracy achieved:  0.502656102180481\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  546\n",
      "test accuracy achieved:  0.5031251907348633\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  476\n",
      "test accuracy achieved:  0.4924996793270111\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  668\n",
      "test accuracy achieved:  0.5014063119888306\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  934\n",
      "test accuracy achieved:  0.4984373450279236\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1468\n",
      "test accuracy achieved:  0.5034373998641968\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  875\n",
      "test accuracy achieved:  0.5010939836502075\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2937\n",
      "test accuracy achieved:  0.49968767166137695\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1483\n",
      "test accuracy achieved:  0.4898436963558197\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8152\n",
      "test accuracy achieved:  0.5046874284744263\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7519\n",
      "test accuracy achieved:  0.4921877980232239\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1511\n",
      "test accuracy achieved:  0.8812481760978699\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1650\n",
      "test accuracy achieved:  0.9093738794326782\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2204\n",
      "test accuracy achieved:  0.915155291557312\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3857\n",
      "test accuracy achieved:  0.9840624928474426\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4324\n",
      "test accuracy achieved:  0.8892173767089844\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5866\n",
      "test accuracy achieved:  0.5254685878753662\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6167\n",
      "test accuracy achieved:  0.6993750929832458\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5721\n",
      "test accuracy achieved:  0.713905930519104\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6078\n",
      "test accuracy achieved:  0.5226563215255737\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  11899\n",
      "test accuracy achieved:  0.8565611839294434\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  489\n",
      "test accuracy achieved:  0.5021876096725464\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  837\n",
      "test accuracy achieved:  0.5142186284065247\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1093\n",
      "test accuracy achieved:  0.500781238079071\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  607\n",
      "test accuracy achieved:  0.5023437142372131\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  911\n",
      "test accuracy achieved:  0.5010939240455627\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  846\n",
      "test accuracy achieved:  0.5104687213897705\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3250\n",
      "test accuracy achieved:  0.4940625727176666\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1150\n",
      "test accuracy achieved:  0.5007809400558472\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4353\n",
      "test accuracy achieved:  0.516562819480896\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2900\n",
      "test accuracy achieved:  0.5042189359664917\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1107\n",
      "test accuracy achieved:  0.7640615701675415\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  896\n",
      "test accuracy achieved:  0.5146878957748413\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1612\n",
      "test accuracy achieved:  0.5043749213218689\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1111\n",
      "test accuracy achieved:  0.5114064812660217\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1905\n",
      "test accuracy achieved:  0.6785942316055298\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1015\n",
      "test accuracy achieved:  0.7915615439414978\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4594\n",
      "test accuracy achieved:  0.9109363555908203\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  657\n",
      "test accuracy achieved:  0.8454673886299133\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1831\n",
      "test accuracy achieved:  0.7604681849479675\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  38784\n",
      "test accuracy achieved:  0.4899994730949402\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1785\n",
      "test accuracy achieved:  0.8098419904708862\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1403\n",
      "test accuracy achieved:  0.7514058947563171\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2171\n",
      "test accuracy achieved:  0.8384358286857605\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1632\n",
      "test accuracy achieved:  0.2073434591293335\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1382\n",
      "test accuracy achieved:  0.8514050245285034\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2099\n",
      "test accuracy achieved:  0.886248767375946\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2307\n",
      "test accuracy achieved:  0.7179686427116394\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2330\n",
      "test accuracy achieved:  0.7809362411499023\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1268\n",
      "test accuracy achieved:  0.7582802772521973\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  775\n",
      "test accuracy achieved:  0.9379684329032898\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1696\n",
      "test accuracy achieved:  0.9279678463935852\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1422\n",
      "test accuracy achieved:  0.899842381477356\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1293\n",
      "test accuracy achieved:  0.3442186117172241\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1604\n",
      "test accuracy achieved:  0.5762506723403931\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  796\n",
      "test accuracy achieved:  0.5117190480232239\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  321\n",
      "test accuracy achieved:  0.39468735456466675\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1094\n",
      "test accuracy achieved:  0.7931236028671265\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  602\n",
      "test accuracy achieved:  0.7931239604949951\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  856\n",
      "test accuracy achieved:  0.6417192220687866\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  691\n",
      "test accuracy achieved:  0.7931240797042847\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8367\n",
      "test accuracy achieved:  0.5125002264976501\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7751\n",
      "test accuracy achieved:  0.4912496507167816\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6307\n",
      "test accuracy achieved:  0.7521872520446777\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12586\n",
      "test accuracy achieved:  0.4945310056209564\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12219\n",
      "test accuracy achieved:  0.5243753790855408\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  11391\n",
      "test accuracy achieved:  0.512812614440918\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12141\n",
      "test accuracy achieved:  0.5243750810623169\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10078\n",
      "test accuracy achieved:  0.49875012040138245\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10252\n",
      "test accuracy achieved:  0.518281102180481\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9560\n",
      "test accuracy achieved:  0.4884372651576996\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1397109\n",
      "test accuracy achieved:  0.503593921661377\n",
      "\n",
      "working on truth table:  ex91\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1979235\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_6548/4136970049.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m   \u001b[0;31m#get accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m   \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_net\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data_iter\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m   \u001b[0;31m# print info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/tmp/ipykernel_6548/3658741905.py\u001b[0m in \u001b[0;36mtest_net\u001b[0;34m(net, test_data_iter)\u001b[0m\n\u001b[1;32m    110\u001b[0m       \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    111\u001b[0m       \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 112\u001b[0;31m       \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    113\u001b[0m     \u001b[0macc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_data_iter\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    114\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0macc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Run experiment 2b\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)):\n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  net = prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "3dd89931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.5079687237739563, 787), ('ex01', 32, 0.9060929417610168, 1704), ('ex02', 64, 0.4929686188697815, 1099), ('ex03', 64, 0.9645308256149292, 2309), ('ex04', 128, 0.5089065432548523, 2447), ('ex05', 128, 0.8262486457824707, 5616), ('ex06', 256, 0.5048436522483826, 5931), ('ex07', 256, 0.702968955039978, 11249), ('ex08', 512, 0.49999985098838806, 73272), ('ex09', 512, 0.5131253004074097, 107942), ('ex10', 32, 0.7264061570167542, 1312), ('ex11', 64, 0.6632816195487976, 2297), ('ex12', 128, 0.6467191576957703, 4619), ('ex13', 256, 0.6445317268371582, 10718), ('ex14', 512, 0.6585944890975952, 145821), ('ex15', 32, 0.5053125619888306, 1829), ('ex16', 64, 0.5009377002716064, 2357), ('ex17', 128, 0.835623562335968, 6745), ('ex18', 256, 0.4900001585483551, 16492), ('ex19', 512, 0.502656102180481, 107537), ('ex20', 16, 0.5031251907348633, 546), ('ex21', 16, 0.4924996793270111, 476), ('ex22', 32, 0.5014063119888306, 668), ('ex23', 32, 0.4984373450279236, 934), ('ex24', 64, 0.5034373998641968, 1468), ('ex25', 64, 0.5010939836502075, 875), ('ex26', 128, 0.49968767166137695, 2937), ('ex27', 128, 0.4898436963558197, 1483), ('ex28', 256, 0.5046874284744263, 8152), ('ex29', 256, 0.4921877980232239, 7519), ('ex30', 20, 0.8812481760978699, 1511), ('ex31', 40, 0.9093738794326782, 1650), ('ex32', 60, 0.915155291557312, 2204), ('ex33', 80, 0.9840624928474426, 3857), ('ex34', 100, 0.8892173767089844, 4324), ('ex35', 120, 0.5254685878753662, 5866), ('ex36', 140, 0.6993750929832458, 6167), ('ex37', 160, 0.713905930519104, 5721), ('ex38', 180, 0.5226563215255737, 6078), ('ex39', 200, 0.8565611839294434, 11899), ('ex40', 16, 0.5021876096725464, 489), ('ex41', 10, 0.5142186284065247, 837), ('ex42', 32, 0.500781238079071, 1093), ('ex43', 18, 0.5023437142372131, 607), ('ex44', 64, 0.5010939240455627, 911), ('ex45', 34, 0.5104687213897705, 846), ('ex46', 128, 0.4940625727176666, 3250), ('ex47', 66, 0.5007809400558472, 1150), ('ex48', 256, 0.516562819480896, 4353), ('ex49', 130, 0.5042189359664917, 2900), ('ex50', 19, 0.7640615701675415, 1107), ('ex51', 44, 0.5146878957748413, 896), ('ex52', 59, 0.5043749213218689, 1612), ('ex53', 45, 0.5114064812660217, 1111), ('ex54', 48, 0.6785942316055298, 1905), ('ex55', 42, 0.7915615439414978, 1015), ('ex56', 83, 0.9109363555908203, 4594), ('ex57', 24, 0.8454673886299133, 657), ('ex58', 80, 0.7604681849479675, 1831), ('ex59', 394, 0.4899994730949402, 38784), ('ex60', 43, 0.8098419904708862, 1785), ('ex61', 37, 0.7514058947563171, 1403), ('ex62', 52, 0.8384358286857605, 2171), ('ex63', 38, 0.2073434591293335, 1632), ('ex64', 47, 0.8514050245285034, 1382), ('ex65', 19, 0.886248767375946, 2099), ('ex66', 47, 0.7179686427116394, 2307), ('ex67', 46, 0.7809362411499023, 2330), ('ex68', 33, 0.7582802772521973, 1268), ('ex69', 16, 0.9379684329032898, 775), ('ex70', 23, 0.9279678463935852, 1696), ('ex71', 23, 0.899842381477356, 1422), ('ex72', 35, 0.3442186117172241, 1293), ('ex73', 16, 0.5762506723403931, 1604), ('ex74', 16, 0.5117190480232239, 796), ('ex75', 16, 0.39468735456466675, 321), ('ex76', 16, 0.7931236028671265, 1094), ('ex77', 16, 0.7931239604949951, 602), ('ex78', 16, 0.6417192220687866, 856), ('ex79', 16, 0.7931240797042847, 691), ('ex80', 196, 0.5125002264976501, 8367), ('ex81', 196, 0.4912496507167816, 7751), ('ex82', 196, 0.7521872520446777, 6307), ('ex83', 196, 0.4945310056209564, 12586), ('ex84', 196, 0.5243753790855408, 12219), ('ex85', 196, 0.512812614440918, 11391), ('ex86', 196, 0.5243750810623169, 12141), ('ex87', 196, 0.49875012040138245, 10078), ('ex88', 196, 0.518281102180481, 10252), ('ex89', 196, 0.4884372651576996, 9560), ('ex90', 768, 0.503593921661377, 1397109)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "8608e9c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp2b.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "030fa238",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 91 benchmarks=  63.01113213156606  %\n",
      "29 networks exceeded size constraint:\n",
      "['ex05' 'ex06' 'ex07' 'ex08' 'ex09' 'ex13' 'ex14' 'ex17' 'ex18' 'ex19'\n",
      " 'ex28' 'ex29' 'ex35' 'ex36' 'ex37' 'ex38' 'ex39' 'ex59' 'ex80' 'ex81'\n",
      " 'ex82' 'ex83' 'ex84' 'ex85' 'ex86' 'ex87' 'ex88' 'ex89' 'ex90']\n",
      "overall accuracy across benchmarks under size constraints=  65.38000380800617  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 91 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "b07cdf8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 1b - 2 layer NN with pruning (excluding size 768)\n",
    "\n",
    "#Net\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size,10)\n",
    "    self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    return x\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    remain_after_pruning = 8 + ( (12-8)/(512-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "\n",
    "    # prune first layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.1\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 10\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.2\n",
    "    )\n",
    "\n",
    "    # prune second layer\n",
    "    prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=0.2, dim=1, n='fro'\n",
    "    )\n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8ef7c32f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1436\n",
      "test accuracy achieved:  0.5176563262939453\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2233\n",
      "test accuracy achieved:  0.906092643737793\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1729\n",
      "test accuracy achieved:  0.49734368920326233\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2190\n",
      "test accuracy achieved:  0.9032794833183289\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3132\n",
      "test accuracy achieved:  0.5153126120567322\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3181\n",
      "test accuracy achieved:  0.9685938954353333\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7023\n",
      "test accuracy achieved:  0.5140624642372131\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4307\n",
      "test accuracy achieved:  0.9103110432624817\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  18413\n",
      "test accuracy achieved:  0.5026563405990601\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  15313\n",
      "test accuracy achieved:  0.9607809782028198\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2987\n",
      "test accuracy achieved:  0.7643742561340332\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2492\n",
      "test accuracy achieved:  0.7874990105628967\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3192\n",
      "test accuracy achieved:  0.6890629529953003\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6595\n",
      "test accuracy achieved:  0.7262504696846008\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  15443\n",
      "test accuracy achieved:  0.6890632510185242\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2357\n",
      "test accuracy achieved:  0.8315606117248535\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2627\n",
      "test accuracy achieved:  0.8367172479629517\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6156\n",
      "test accuracy achieved:  0.8249982595443726\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7669\n",
      "test accuracy achieved:  0.8279672861099243\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  30895\n",
      "test accuracy achieved:  0.8249987363815308\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1444\n",
      "test accuracy achieved:  0.5104687213897705\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1796\n",
      "test accuracy achieved:  0.5153126120567322\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1745\n",
      "test accuracy achieved:  0.5107811689376831\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1814\n",
      "test accuracy achieved:  0.5160935521125793\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1614\n",
      "test accuracy achieved:  0.5287504196166992\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1506\n",
      "test accuracy achieved:  0.5607814788818359\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4107\n",
      "test accuracy achieved:  0.5315622091293335\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3818\n",
      "test accuracy achieved:  0.5164063572883606\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6032\n",
      "test accuracy achieved:  0.4984373152256012\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7781\n",
      "test accuracy achieved:  0.5592191815376282\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2367\n",
      "test accuracy achieved:  0.9745312929153442\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2055\n",
      "test accuracy achieved:  0.9668750762939453\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2193\n",
      "test accuracy achieved:  0.967343807220459\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4330\n",
      "test accuracy achieved:  0.9857816696166992\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2788\n",
      "test accuracy achieved:  0.9682814478874207\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4262\n",
      "test accuracy achieved:  0.986875057220459\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3801\n",
      "test accuracy achieved:  0.9595307111740112\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3205\n",
      "test accuracy achieved:  0.9701560735702515\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3673\n",
      "test accuracy achieved:  0.971093475818634\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4772\n",
      "test accuracy achieved:  0.9843748807907104\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1432\n",
      "test accuracy achieved:  0.5606257319450378\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1525\n",
      "test accuracy achieved:  0.6029692888259888\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1706\n",
      "test accuracy achieved:  0.5254688858985901\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1575\n",
      "test accuracy achieved:  0.515468955039978\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2118\n",
      "test accuracy achieved:  0.5262499451637268\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1551\n",
      "test accuracy achieved:  0.5114063024520874\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4001\n",
      "test accuracy achieved:  0.5235936045646667\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1952\n",
      "test accuracy achieved:  0.5057810544967651\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8287\n",
      "test accuracy achieved:  0.5314064621925354\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3647\n",
      "test accuracy achieved:  0.49874988198280334\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1949\n",
      "test accuracy achieved:  0.774061918258667\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1861\n",
      "test accuracy achieved:  0.5234374403953552\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2416\n",
      "test accuracy achieved:  0.5946879386901855\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2872\n",
      "test accuracy achieved:  0.6820316910743713\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1823\n",
      "test accuracy achieved:  0.7740619778633118\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1705\n",
      "test accuracy achieved:  0.9345302581787109\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7258\n",
      "test accuracy achieved:  0.5882819294929504\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1649\n",
      "test accuracy achieved:  0.9623438715934753\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3679\n",
      "test accuracy achieved:  0.8699983358383179\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  16849\n",
      "test accuracy achieved:  0.6223443746566772\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1559\n",
      "test accuracy achieved:  0.6579695343971252\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2068\n",
      "test accuracy achieved:  0.8281232118606567\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2562\n",
      "test accuracy achieved:  0.873123288154602\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1683\n",
      "test accuracy achieved:  0.9014051556587219\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1949\n",
      "test accuracy achieved:  0.9812501668930054\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3018\n",
      "test accuracy achieved:  0.8723416328430176\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2206\n",
      "test accuracy achieved:  0.7870307564735413\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2225\n",
      "test accuracy achieved:  0.7287492156028748\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2598\n",
      "test accuracy achieved:  0.916405200958252\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1594\n",
      "test accuracy achieved:  0.9017173647880554\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2769\n",
      "test accuracy achieved:  0.9317178726196289\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1987\n",
      "test accuracy achieved:  0.8860921859741211\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1887\n",
      "test accuracy achieved:  0.8799988031387329\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2578\n",
      "test accuracy achieved:  0.6187508702278137\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1529\n",
      "test accuracy achieved:  0.5173437595367432\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  678\n",
      "test accuracy achieved:  0.3946871757507324\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1465\n",
      "test accuracy achieved:  0.7931240200996399\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1843\n",
      "test accuracy achieved:  0.7931236624717712\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1835\n",
      "test accuracy achieved:  0.6417193412780762\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1649\n",
      "test accuracy achieved:  0.8024986386299133\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5242\n",
      "test accuracy achieved:  0.5635939836502075\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5066\n",
      "test accuracy achieved:  0.7490622997283936\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4102\n",
      "test accuracy achieved:  0.7940613031387329\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4793\n",
      "test accuracy achieved:  0.7487496137619019\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7035\n",
      "test accuracy achieved:  0.7779676914215088\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7079\n",
      "test accuracy achieved:  0.7926556468009949\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5190\n",
      "test accuracy achieved:  0.6098448038101196\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4454\n",
      "test accuracy achieved:  0.7570306658744812\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6018\n",
      "test accuracy achieved:  0.813904881477356\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5782\n",
      "test accuracy achieved:  0.7662494778633118\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  70012\n",
      "test accuracy achieved:  0.5042189955711365\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 1b\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)-9): # ignore 768 \n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  net = prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "e7c32b72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.5176563262939453, 1436), ('ex01', 32, 0.906092643737793, 2233), ('ex02', 64, 0.49734368920326233, 1729), ('ex03', 64, 0.9032794833183289, 2190), ('ex04', 128, 0.5153126120567322, 3132), ('ex05', 128, 0.9685938954353333, 3181), ('ex06', 256, 0.5140624642372131, 7023), ('ex07', 256, 0.9103110432624817, 4307), ('ex08', 512, 0.5026563405990601, 18413), ('ex09', 512, 0.9607809782028198, 15313), ('ex10', 32, 0.7643742561340332, 2987), ('ex11', 64, 0.7874990105628967, 2492), ('ex12', 128, 0.6890629529953003, 3192), ('ex13', 256, 0.7262504696846008, 6595), ('ex14', 512, 0.6890632510185242, 15443), ('ex15', 32, 0.8315606117248535, 2357), ('ex16', 64, 0.8367172479629517, 2627), ('ex17', 128, 0.8249982595443726, 6156), ('ex18', 256, 0.8279672861099243, 7669), ('ex19', 512, 0.8249987363815308, 30895), ('ex20', 16, 0.5104687213897705, 1444), ('ex21', 16, 0.5153126120567322, 1796), ('ex22', 32, 0.5107811689376831, 1745), ('ex23', 32, 0.5160935521125793, 1814), ('ex24', 64, 0.5287504196166992, 1614), ('ex25', 64, 0.5607814788818359, 1506), ('ex26', 128, 0.5315622091293335, 4107), ('ex27', 128, 0.5164063572883606, 3818), ('ex28', 256, 0.4984373152256012, 6032), ('ex29', 256, 0.5592191815376282, 7781), ('ex30', 20, 0.9745312929153442, 2367), ('ex31', 40, 0.9668750762939453, 2055), ('ex32', 60, 0.967343807220459, 2193), ('ex33', 80, 0.9857816696166992, 4330), ('ex34', 100, 0.9682814478874207, 2788), ('ex35', 120, 0.986875057220459, 4262), ('ex36', 140, 0.9595307111740112, 3801), ('ex37', 160, 0.9701560735702515, 3205), ('ex38', 180, 0.971093475818634, 3673), ('ex39', 200, 0.9843748807907104, 4772), ('ex40', 16, 0.5606257319450378, 1432), ('ex41', 10, 0.6029692888259888, 1525), ('ex42', 32, 0.5254688858985901, 1706), ('ex43', 18, 0.515468955039978, 1575), ('ex44', 64, 0.5262499451637268, 2118), ('ex45', 34, 0.5114063024520874, 1551), ('ex46', 128, 0.5235936045646667, 4001), ('ex47', 66, 0.5057810544967651, 1952), ('ex48', 256, 0.5314064621925354, 8287), ('ex49', 130, 0.49874988198280334, 3647), ('ex50', 19, 0.774061918258667, 1949), ('ex51', 44, 0.5234374403953552, 1861), ('ex52', 59, 0.5946879386901855, 2416), ('ex53', 45, 0.6820316910743713, 2872), ('ex54', 48, 0.7740619778633118, 1823), ('ex55', 42, 0.9345302581787109, 1705), ('ex56', 83, 0.5882819294929504, 7258), ('ex57', 24, 0.9623438715934753, 1649), ('ex58', 80, 0.8699983358383179, 3679), ('ex59', 394, 0.6223443746566772, 16849), ('ex60', 43, 0.6579695343971252, 1559), ('ex61', 37, 0.8281232118606567, 2068), ('ex62', 52, 0.873123288154602, 2562), ('ex63', 38, 0.9014051556587219, 1683), ('ex64', 47, 0.9812501668930054, 1949), ('ex65', 19, 0.8723416328430176, 3018), ('ex66', 47, 0.7870307564735413, 2206), ('ex67', 46, 0.7287492156028748, 2225), ('ex68', 33, 0.916405200958252, 2598), ('ex69', 16, 0.9017173647880554, 1594), ('ex70', 23, 0.9317178726196289, 2769), ('ex71', 23, 0.8860921859741211, 1987), ('ex72', 35, 0.8799988031387329, 1887), ('ex73', 16, 0.6187508702278137, 2578), ('ex74', 16, 0.5173437595367432, 1529), ('ex75', 16, 0.3946871757507324, 678), ('ex76', 16, 0.7931240200996399, 1465), ('ex77', 16, 0.7931236624717712, 1843), ('ex78', 16, 0.6417193412780762, 1835), ('ex79', 16, 0.8024986386299133, 1649), ('ex80', 196, 0.5635939836502075, 5242), ('ex81', 196, 0.7490622997283936, 5066), ('ex82', 196, 0.7940613031387329, 4102), ('ex83', 196, 0.7487496137619019, 4793), ('ex84', 196, 0.7779676914215088, 7035), ('ex85', 196, 0.7926556468009949, 7079), ('ex86', 196, 0.6098448038101196, 5190), ('ex87', 196, 0.7570306658744812, 4454), ('ex88', 196, 0.813904881477356, 6018), ('ex89', 196, 0.7662494778633118, 5782), ('ex90', 768, 0.5042189955711365, 70012)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9c139465",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp1b.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "53570af6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 91 benchmarks=  72.73983421561482  %\n",
      "21 networks exceeded size constraint:\n",
      "['ex06' 'ex08' 'ex09' 'ex13' 'ex14' 'ex17' 'ex18' 'ex19' 'ex28' 'ex29'\n",
      " 'ex48' 'ex56' 'ex59' 'ex80' 'ex81' 'ex84' 'ex85' 'ex86' 'ex88' 'ex89'\n",
      " 'ex90']\n",
      "overall accuracy across benchmarks under size constraints=  74.20754901000431  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 91 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "f360ddb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 3 - 2 layer NN with pruning (excluding size 768 and RELU as activation)\n",
    "\n",
    "#Net\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size,10)\n",
    "    self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    return x\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    remain_after_pruning = 8 + ( (12-8)/(512-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "\n",
    "    # prune first layer\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.1\n",
    "    )\n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 10\n",
    "    )\n",
    "    prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.2\n",
    "    )\n",
    "\n",
    "    # prune second layer\n",
    "    prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=0.2, dim=1, n='fro'\n",
    "    )\n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net\n",
    "\n",
    "# get_lut_y\n",
    "def get_lut_y_sigmoid(input_size,w,b):\n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = 1/(1 + np.exp(-out)) >=0.5\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0   \n",
    "    return lut_y\n",
    "\n",
    "# get_lut_y\n",
    "def get_lut_y_relu(input_size,w,b):\n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = out >=0\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0   \n",
    "    return lut_y\n",
    "\n",
    "def get_aig_size(net):\n",
    "    # get list of neurons in NN\n",
    "    neurons = [] # each element is a neuron with a weight vector and a bias scalar\n",
    "    weights = [] # each element is the weight matrix of a layer\n",
    "    biases  = [] # each element contains biases for that layer\n",
    "    for name, param in net.named_parameters():\n",
    "        if '.weight'in name:\n",
    "            weights.append( param.detach().cpu().numpy() )\n",
    "        if '.bias' in name:\n",
    "            biases.append( param.detach().cpu().numpy() )\n",
    "\n",
    "    weights.reverse()\n",
    "    biases.reverse()\n",
    "    ignore_neurons = [] # element in list: (i,j) neuron j in layer i\n",
    "    for i,layer_weights in enumerate(weights): # i = layer (starting from highest)\n",
    "\n",
    "        # check which neurons in lower layer can be ignored\n",
    "        for k in range( len(layer_weights[0]) ):\n",
    "            if( len( np.nonzero(layer_weights[:,k])[0] )==0 ):\n",
    "                ignore_neurons.append( (i+1,k) )\n",
    "\n",
    "        for j,weight_vector in enumerate(layer_weights): # j = neuron in layer i\n",
    "            if not (i,j) in ignore_neurons:\n",
    "                isRELU = not (i==0)\n",
    "                neurons.append((weight_vector,biases[i][j],isRELU))\n",
    "\n",
    "    # get size of aig  \n",
    "#     print(\"getting size of aig\")\n",
    "    size_aig = 0\n",
    "\n",
    "    for neuron in neurons: \n",
    "        '''form LUT for each neuron'''\n",
    "        w = neuron[0]\n",
    "        b = neuron[1]\n",
    "        isRELU = neuron[2]\n",
    "#         print(isRELU)\n",
    "        w = w[w.nonzero()]\n",
    "        input_size = len(w)\n",
    "        # get the LUT\n",
    "        if (isRELU):\n",
    "            lut_y = get_lut_y_relu(input_size, w, b)\n",
    "        else:\n",
    "            lut_y = get_lut_y_sigmoid(input_size, w, b)\n",
    "            \n",
    "        '''create text for verilog file representing LUT'''\n",
    "        n=input_size\n",
    "#         print(input_size)\n",
    "        file_string ='module lut_verilog(\\ninput wire['+str(input_size-1)+':0] in,\\noutput reg out\\n);\\n\\nalways@(in) begin\\ncase(in)\\n'\n",
    "        input_vector = np.zeros( (input_size) )\n",
    "        for idx in range ( pow(2,input_size) ):\n",
    "            # add to file string\n",
    "            file_string += str(input_size)+'\\'b'+''.join(str(int(e)) for e in input_vector)+' : out = '+str(int(lut_y[idx]))+';\\n'\n",
    "            # increment input vector\n",
    "            for i in range(len(input_vector)-1, -1, -1):\n",
    "                if input_vector[i] == 0:\n",
    "                    input_vector[i] = 1\n",
    "                    break\n",
    "                input_vector[i] = 0\n",
    "        file_string+='endcase\\nend\\nendmodule\\n'\n",
    "\n",
    "        '''write to verilog file'''\n",
    "        f = open(\"lut_verilog.v\", \"w\")\n",
    "        f.write(file_string)\n",
    "        f.close()\n",
    "\n",
    "        '''produce the .aig file using yosys script'''\n",
    "        cmd = \"yosys neuron_to_aig_size.ys >/dev/null 2>&1\"\n",
    "        os.system(cmd)\n",
    "\n",
    "        '''get the number of and gates in aig and add to the running sum'''\n",
    "        f = open(\"lut_verilog.aig\", \"r\")\n",
    "        line = f.readline()\n",
    "        size_aig = size_aig + int(line.split(' ')[5].split('\\n')[0])\n",
    "        #     print(\"size: \", line.split(' ')[5].split('\\n')[0] )\n",
    "        #     print(\"running sum: \",size_aig)\n",
    "    return size_aig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "c3548636",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2808\n",
      "test accuracy achieved:  0.9146865606307983\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2075\n",
      "test accuracy achieved:  0.9359360933303833\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2032\n",
      "test accuracy achieved:  0.4996872544288635\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2112\n",
      "test accuracy achieved:  0.9401556253433228\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2222\n",
      "test accuracy achieved:  0.5045312643051147\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4183\n",
      "test accuracy achieved:  0.9626563191413879\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3566\n",
      "test accuracy achieved:  0.5057811737060547\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6994\n",
      "test accuracy achieved:  0.9521875381469727\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  13073\n",
      "test accuracy achieved:  0.5185939073562622\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  21015\n",
      "test accuracy achieved:  0.9839062690734863\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2472\n",
      "test accuracy achieved:  0.8589041829109192\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2328\n",
      "test accuracy achieved:  0.8192172050476074\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3210\n",
      "test accuracy achieved:  0.7948426008224487\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5331\n",
      "test accuracy achieved:  0.8292170763015747\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  19413\n",
      "test accuracy achieved:  0.782342791557312\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1423\n",
      "test accuracy achieved:  0.8998421430587769\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1877\n",
      "test accuracy achieved:  0.8942174911499023\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3969\n",
      "test accuracy achieved:  0.741093099117279\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5901\n",
      "test accuracy achieved:  0.7067192792892456\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  15585\n",
      "test accuracy achieved:  0.8243733644485474\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1706\n",
      "test accuracy achieved:  0.5103126168251038\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1974\n",
      "test accuracy achieved:  0.9925001263618469\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1839\n",
      "test accuracy achieved:  0.5171876549720764\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2081\n",
      "test accuracy achieved:  1.0\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1937\n",
      "test accuracy achieved:  0.5109375715255737\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2497\n",
      "test accuracy achieved:  1.0\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1788\n",
      "test accuracy achieved:  0.5001562833786011\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3681\n",
      "test accuracy achieved:  0.5101563930511475\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4783\n",
      "test accuracy achieved:  0.5090625286102295\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4222\n",
      "test accuracy achieved:  0.5078126788139343\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2140\n",
      "test accuracy achieved:  0.9729684591293335\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2482\n",
      "test accuracy achieved:  0.9696875810623169\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2019\n",
      "test accuracy achieved:  0.9710938334465027\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3005\n",
      "test accuracy achieved:  0.981874942779541\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3771\n",
      "test accuracy achieved:  0.9843751192092896\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4005\n",
      "test accuracy achieved:  0.9868753552436829\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4913\n",
      "test accuracy achieved:  0.9831250309944153\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5173\n",
      "test accuracy achieved:  0.9854687452316284\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5506\n",
      "test accuracy achieved:  0.9710936546325684\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6899\n",
      "test accuracy achieved:  0.9862500429153442\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1765\n",
      "test accuracy achieved:  0.6257820129394531\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1833\n",
      "test accuracy achieved:  0.9056239128112793\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1699\n",
      "test accuracy achieved:  0.5123441219329834\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1651\n",
      "test accuracy achieved:  0.5342187881469727\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1316\n",
      "test accuracy achieved:  0.519687294960022\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1430\n",
      "test accuracy achieved:  0.5142184495925903\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3148\n",
      "test accuracy achieved:  0.504844069480896\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1791\n",
      "test accuracy achieved:  0.5071873664855957\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6776\n",
      "test accuracy achieved:  0.48515599966049194\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2597\n",
      "test accuracy achieved:  0.5034373998641968\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1849\n",
      "test accuracy achieved:  0.893280029296875\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1637\n",
      "test accuracy achieved:  0.550312876701355\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2206\n",
      "test accuracy achieved:  0.6262500286102295\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1507\n",
      "test accuracy achieved:  0.8012482523918152\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1912\n",
      "test accuracy achieved:  0.9345303773880005\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2356\n",
      "test accuracy achieved:  0.9859377145767212\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3335\n",
      "test accuracy achieved:  0.8735917806625366\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2025\n",
      "test accuracy achieved:  0.9721872210502625\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2989\n",
      "test accuracy achieved:  0.9534371495246887\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7660\n",
      "test accuracy achieved:  0.8182799220085144\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2460\n",
      "test accuracy achieved:  0.896873950958252\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2333\n",
      "test accuracy achieved:  0.9967187643051147\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2418\n",
      "test accuracy achieved:  0.8432797193527222\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1974\n",
      "test accuracy achieved:  0.9165619611740112\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1457\n",
      "test accuracy achieved:  0.9812498092651367\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1940\n",
      "test accuracy achieved:  0.849373459815979\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1631\n",
      "test accuracy achieved:  0.878436267375946\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2278\n",
      "test accuracy achieved:  0.8435918688774109\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2238\n",
      "test accuracy achieved:  0.9242178797721863\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1665\n",
      "test accuracy achieved:  0.9696876406669617\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1978\n",
      "test accuracy achieved:  0.9918750524520874\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1803\n",
      "test accuracy achieved:  0.9943749308586121\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2035\n",
      "test accuracy achieved:  0.9195305109024048\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2342\n",
      "test accuracy achieved:  0.6775004267692566\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1705\n",
      "test accuracy achieved:  0.5326565504074097\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  557\n",
      "test accuracy achieved:  0.397812157869339\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1829\n",
      "test accuracy achieved:  0.2259373962879181\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1382\n",
      "test accuracy achieved:  0.22515615820884705\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2044\n",
      "test accuracy achieved:  0.6417193412780762\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1731\n",
      "test accuracy achieved:  0.2501562237739563\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3195\n",
      "test accuracy achieved:  0.6767185926437378\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5163\n",
      "test accuracy achieved:  0.6976565718650818\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5166\n",
      "test accuracy achieved:  0.7676557302474976\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3823\n",
      "test accuracy achieved:  0.4490625262260437\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3963\n",
      "test accuracy achieved:  0.5925005078315735\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4038\n",
      "test accuracy achieved:  0.8289044499397278\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3573\n",
      "test accuracy achieved:  0.621407151222229\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4725\n",
      "test accuracy achieved:  0.5948439836502075\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4193\n",
      "test accuracy achieved:  0.5767194032669067\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4249\n",
      "test accuracy achieved:  0.5256251096725464\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  23578\n",
      "test accuracy achieved:  0.5009377598762512\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 3\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)-9): # ignore 768 \n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  net = prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "535d9db7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.9146865606307983, 2808), ('ex01', 32, 0.9359360933303833, 2075), ('ex02', 64, 0.4996872544288635, 2032), ('ex03', 64, 0.9401556253433228, 2112), ('ex04', 128, 0.5045312643051147, 2222), ('ex05', 128, 0.9626563191413879, 4183), ('ex06', 256, 0.5057811737060547, 3566), ('ex07', 256, 0.9521875381469727, 6994), ('ex08', 512, 0.5185939073562622, 13073), ('ex09', 512, 0.9839062690734863, 21015), ('ex10', 32, 0.8589041829109192, 2472), ('ex11', 64, 0.8192172050476074, 2328), ('ex12', 128, 0.7948426008224487, 3210), ('ex13', 256, 0.8292170763015747, 5331), ('ex14', 512, 0.782342791557312, 19413), ('ex15', 32, 0.8998421430587769, 1423), ('ex16', 64, 0.8942174911499023, 1877), ('ex17', 128, 0.741093099117279, 3969), ('ex18', 256, 0.7067192792892456, 5901), ('ex19', 512, 0.8243733644485474, 15585), ('ex20', 16, 0.5103126168251038, 1706), ('ex21', 16, 0.9925001263618469, 1974), ('ex22', 32, 0.5171876549720764, 1839), ('ex23', 32, 1.0, 2081), ('ex24', 64, 0.5109375715255737, 1937), ('ex25', 64, 1.0, 2497), ('ex26', 128, 0.5001562833786011, 1788), ('ex27', 128, 0.5101563930511475, 3681), ('ex28', 256, 0.5090625286102295, 4783), ('ex29', 256, 0.5078126788139343, 4222), ('ex30', 20, 0.9729684591293335, 2140), ('ex31', 40, 0.9696875810623169, 2482), ('ex32', 60, 0.9710938334465027, 2019), ('ex33', 80, 0.981874942779541, 3005), ('ex34', 100, 0.9843751192092896, 3771), ('ex35', 120, 0.9868753552436829, 4005), ('ex36', 140, 0.9831250309944153, 4913), ('ex37', 160, 0.9854687452316284, 5173), ('ex38', 180, 0.9710936546325684, 5506), ('ex39', 200, 0.9862500429153442, 6899), ('ex40', 16, 0.6257820129394531, 1765), ('ex41', 10, 0.9056239128112793, 1833), ('ex42', 32, 0.5123441219329834, 1699), ('ex43', 18, 0.5342187881469727, 1651), ('ex44', 64, 0.519687294960022, 1316), ('ex45', 34, 0.5142184495925903, 1430), ('ex46', 128, 0.504844069480896, 3148), ('ex47', 66, 0.5071873664855957, 1791), ('ex48', 256, 0.48515599966049194, 6776), ('ex49', 130, 0.5034373998641968, 2597), ('ex50', 19, 0.893280029296875, 1849), ('ex51', 44, 0.550312876701355, 1637), ('ex52', 59, 0.6262500286102295, 2206), ('ex53', 45, 0.8012482523918152, 1507), ('ex54', 48, 0.9345303773880005, 1912), ('ex55', 42, 0.9859377145767212, 2356), ('ex56', 83, 0.8735917806625366, 3335), ('ex57', 24, 0.9721872210502625, 2025), ('ex58', 80, 0.9534371495246887, 2989), ('ex59', 394, 0.8182799220085144, 7660), ('ex60', 43, 0.896873950958252, 2460), ('ex61', 37, 0.9967187643051147, 2333), ('ex62', 52, 0.8432797193527222, 2418), ('ex63', 38, 0.9165619611740112, 1974), ('ex64', 47, 0.9812498092651367, 1457), ('ex65', 19, 0.849373459815979, 1940), ('ex66', 47, 0.878436267375946, 1631), ('ex67', 46, 0.8435918688774109, 2278), ('ex68', 33, 0.9242178797721863, 2238), ('ex69', 16, 0.9696876406669617, 1665), ('ex70', 23, 0.9918750524520874, 1978), ('ex71', 23, 0.9943749308586121, 1803), ('ex72', 35, 0.9195305109024048, 2035), ('ex73', 16, 0.6775004267692566, 2342), ('ex74', 16, 0.5326565504074097, 1705), ('ex75', 16, 0.397812157869339, 557), ('ex76', 16, 0.2259373962879181, 1829), ('ex77', 16, 0.22515615820884705, 1382), ('ex78', 16, 0.6417193412780762, 2044), ('ex79', 16, 0.2501562237739563, 1731), ('ex80', 196, 0.6767185926437378, 3195), ('ex81', 196, 0.6976565718650818, 5163), ('ex82', 196, 0.7676557302474976, 5166), ('ex83', 196, 0.4490625262260437, 3823), ('ex84', 196, 0.5925005078315735, 3963), ('ex85', 196, 0.8289044499397278, 4038), ('ex86', 196, 0.621407151222229, 3573), ('ex87', 196, 0.5948439836502075, 4725), ('ex88', 196, 0.5767194032669067, 4193), ('ex89', 196, 0.5256251096725464, 4249), ('ex90', 768, 0.5009377598762512, 23578)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "f9b58732",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp3.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "f7f332dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 91 benchmarks=  74.75838074972341  %\n",
      "15 networks exceeded size constraint:\n",
      "['ex07' 'ex08' 'ex09' 'ex13' 'ex14' 'ex18' 'ex19' 'ex37' 'ex38' 'ex39'\n",
      " 'ex48' 'ex59' 'ex81' 'ex82' 'ex90']\n",
      "overall accuracy across benchmarks under size constraints=  73.97406293373359  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 91 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "70e7f309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Experiment 4 - 2 layer NN with global pruning (excluding size 768 and RELU as activation)\n",
    "\n",
    "#Net\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size,10)\n",
    "    self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.relu( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    return x\n",
    "\n",
    "# prune\n",
    "def prune_model(input_size, net):\n",
    "    \n",
    "    parameters_to_prune = (\n",
    "    (net.linear1, 'weight'),\n",
    "    (net.linear2, 'weight')\n",
    "    )\n",
    "\n",
    "    prune.global_unstructured(\n",
    "        parameters_to_prune,\n",
    "        pruning_method=prune.L1Unstructured,\n",
    "        amount=0.3,\n",
    "    )\n",
    "    \n",
    "    remain_after_pruning = 8 + ( (10-8)/(512-10) )*(input_size-10)\n",
    "    pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "    \n",
    "    prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 12\n",
    "    )\n",
    "    \n",
    "    # after pruning\n",
    "    prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "    prune.remove(net.linear2, 'weight') # makes pruning permanent\n",
    "\n",
    "    return net\n",
    "\n",
    "# get_lut_y\n",
    "def get_lut_y_sigmoid(input_size,w,b):\n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = 1/(1 + np.exp(-out)) >=0.5\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0   \n",
    "    return lut_y\n",
    "\n",
    "# get_lut_y\n",
    "def get_lut_y_relu(input_size,w,b):\n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = out >=0\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0   \n",
    "    return lut_y\n",
    "\n",
    "def get_aig_size(net):\n",
    "    # get list of neurons in NN\n",
    "    neurons = [] # each element is a neuron with a weight vector and a bias scalar\n",
    "    weights = [] # each element is the weight matrix of a layer\n",
    "    biases  = [] # each element contains biases for that layer\n",
    "    for name, param in net.named_parameters():\n",
    "        if '.weight'in name:\n",
    "            weights.append( param.detach().cpu().numpy() )\n",
    "        if '.bias' in name:\n",
    "            biases.append( param.detach().cpu().numpy() )\n",
    "\n",
    "    weights.reverse()\n",
    "    biases.reverse()\n",
    "    ignore_neurons = [] # element in list: (i,j) neuron j in layer i\n",
    "    for i,layer_weights in enumerate(weights): # i = layer (starting from highest)\n",
    "\n",
    "        # check which neurons in lower layer can be ignored\n",
    "        for k in range( len(layer_weights[0]) ):\n",
    "            if( len( np.nonzero(layer_weights[:,k])[0] )==0 ):\n",
    "                ignore_neurons.append( (i+1,k) )\n",
    "\n",
    "        for j,weight_vector in enumerate(layer_weights): # j = neuron in layer i\n",
    "            if not (i,j) in ignore_neurons:\n",
    "                isRELU = not (i==0)\n",
    "                neurons.append((weight_vector,biases[i][j],isRELU))\n",
    "\n",
    "    # get size of aig  \n",
    "#     print(\"getting size of aig\")\n",
    "    size_aig = 0\n",
    "\n",
    "    for neuron in neurons: \n",
    "        '''form LUT for each neuron'''\n",
    "        w = neuron[0]\n",
    "        b = neuron[1]\n",
    "        isRELU = neuron[2]\n",
    "#         print(isRELU)\n",
    "        w = w[w.nonzero()]\n",
    "        input_size = len(w)\n",
    "        # get the LUT\n",
    "        if (isRELU):\n",
    "            lut_y = get_lut_y_relu(input_size, w, b)\n",
    "        else:\n",
    "            lut_y = get_lut_y_sigmoid(input_size, w, b)\n",
    "            \n",
    "        '''create text for verilog file representing LUT'''\n",
    "        n=input_size\n",
    "#         print(input_size)\n",
    "        file_string ='module lut_verilog(\\ninput wire['+str(input_size-1)+':0] in,\\noutput reg out\\n);\\n\\nalways@(in) begin\\ncase(in)\\n'\n",
    "        input_vector = np.zeros( (input_size) )\n",
    "        for idx in range ( pow(2,input_size) ):\n",
    "            # add to file string\n",
    "            file_string += str(input_size)+'\\'b'+''.join(str(int(e)) for e in input_vector)+' : out = '+str(int(lut_y[idx]))+';\\n'\n",
    "            # increment input vector\n",
    "            for i in range(len(input_vector)-1, -1, -1):\n",
    "                if input_vector[i] == 0:\n",
    "                    input_vector[i] = 1\n",
    "                    break\n",
    "                input_vector[i] = 0\n",
    "        file_string+='endcase\\nend\\nendmodule\\n'\n",
    "\n",
    "        '''write to verilog file'''\n",
    "        f = open(\"lut_verilog.v\", \"w\")\n",
    "        f.write(file_string)\n",
    "        f.close()\n",
    "\n",
    "        '''produce the .aig file using yosys script'''\n",
    "        cmd = \"yosys neuron_to_aig_size.ys >/dev/null 2>&1\"\n",
    "        os.system(cmd)\n",
    "\n",
    "        '''get the number of and gates in aig and add to the running sum'''\n",
    "        f = open(\"lut_verilog.aig\", \"r\")\n",
    "        line = f.readline()\n",
    "        size_aig = size_aig + int(line.split(' ')[5].split('\\n')[0])\n",
    "        #     print(\"size: \", line.split(' ')[5].split('\\n')[0] )\n",
    "        #     print(\"running sum: \",size_aig)\n",
    "    return size_aig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "c0d187ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "working on truth table:  ex00\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3893\n",
      "test accuracy achieved:  0.6967187523841858\n",
      "\n",
      "working on truth table:  ex01\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3345\n",
      "test accuracy achieved:  0.9317179918289185\n",
      "\n",
      "working on truth table:  ex02\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4323\n",
      "test accuracy achieved:  0.7504680752754211\n",
      "\n",
      "working on truth table:  ex03\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4033\n",
      "test accuracy achieved:  0.9160928726196289\n",
      "\n",
      "working on truth table:  ex04\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3319\n",
      "test accuracy achieved:  0.5137501955032349\n",
      "\n",
      "working on truth table:  ex05\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4176\n",
      "test accuracy achieved:  0.9671874046325684\n",
      "\n",
      "working on truth table:  ex06\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5450\n",
      "test accuracy achieved:  0.5171875357627869\n",
      "\n",
      "working on truth table:  ex07\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7999\n",
      "test accuracy achieved:  0.9387494325637817\n",
      "\n",
      "working on truth table:  ex08\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  10781\n",
      "test accuracy achieved:  0.506250262260437\n",
      "\n",
      "working on truth table:  ex09\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  12781\n",
      "test accuracy achieved:  0.9842191934585571\n",
      "\n",
      "working on truth table:  ex10\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4618\n",
      "test accuracy achieved:  0.852811336517334\n",
      "\n",
      "working on truth table:  ex11\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4650\n",
      "test accuracy achieved:  0.8257796168327332\n",
      "\n",
      "working on truth table:  ex12\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4248\n",
      "test accuracy achieved:  0.7937485575675964\n",
      "\n",
      "working on truth table:  ex13\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5571\n",
      "test accuracy achieved:  0.766874372959137\n",
      "\n",
      "working on truth table:  ex14\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9639\n",
      "test accuracy achieved:  0.7571872472763062\n",
      "\n",
      "working on truth table:  ex15\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4052\n",
      "test accuracy achieved:  0.8978112936019897\n",
      "\n",
      "working on truth table:  ex16\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3395\n",
      "test accuracy achieved:  0.8917175531387329\n",
      "\n",
      "working on truth table:  ex17\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3904\n",
      "test accuracy achieved:  0.7814052700996399\n",
      "\n",
      "working on truth table:  ex18\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5977\n",
      "test accuracy achieved:  0.7017187476158142\n",
      "\n",
      "working on truth table:  ex19\n",
      "input size =  512\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  14567\n",
      "test accuracy achieved:  0.5360939502716064\n",
      "\n",
      "working on truth table:  ex20\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2525\n",
      "test accuracy achieved:  0.5235940217971802\n",
      "\n",
      "working on truth table:  ex21\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3016\n",
      "test accuracy achieved:  0.9832812547683716\n",
      "\n",
      "working on truth table:  ex22\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3529\n",
      "test accuracy achieved:  0.5195313692092896\n",
      "\n",
      "working on truth table:  ex23\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3897\n",
      "test accuracy achieved:  1.0\n",
      "\n",
      "working on truth table:  ex24\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3202\n",
      "test accuracy achieved:  0.4960938096046448\n",
      "\n",
      "working on truth table:  ex25\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1984\n",
      "test accuracy achieved:  0.5051563382148743\n",
      "\n",
      "working on truth table:  ex26\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4268\n",
      "test accuracy achieved:  0.5006247162818909\n",
      "\n",
      "working on truth table:  ex27\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4072\n",
      "test accuracy achieved:  1.0\n",
      "\n",
      "working on truth table:  ex28\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5106\n",
      "test accuracy achieved:  0.5001562833786011\n",
      "\n",
      "working on truth table:  ex29\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5495\n",
      "test accuracy achieved:  1.0\n",
      "\n",
      "working on truth table:  ex30\n",
      "input size =  20\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2408\n",
      "test accuracy achieved:  0.9723436236381531\n",
      "\n",
      "working on truth table:  ex31\n",
      "input size =  40\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3133\n",
      "test accuracy achieved:  0.9679689407348633\n",
      "\n",
      "working on truth table:  ex32\n",
      "input size =  60\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3903\n",
      "test accuracy achieved:  0.970000147819519\n",
      "\n",
      "working on truth table:  ex33\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4622\n",
      "test accuracy achieved:  0.9726560711860657\n",
      "\n",
      "working on truth table:  ex34\n",
      "input size =  100\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4073\n",
      "test accuracy achieved:  0.9659374356269836\n",
      "\n",
      "working on truth table:  ex35\n",
      "input size =  120\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4212\n",
      "test accuracy achieved:  0.9706252217292786\n",
      "\n",
      "working on truth table:  ex36\n",
      "input size =  140\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6847\n",
      "test accuracy achieved:  0.9831250309944153\n",
      "\n",
      "working on truth table:  ex37\n",
      "input size =  160\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7921\n",
      "test accuracy achieved:  0.9854686856269836\n",
      "\n",
      "working on truth table:  ex38\n",
      "input size =  180\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6846\n",
      "test accuracy achieved:  0.9715625643730164\n",
      "\n",
      "working on truth table:  ex39\n",
      "input size =  200\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4864\n",
      "test accuracy achieved:  0.9776561856269836\n",
      "\n",
      "working on truth table:  ex40\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3653\n",
      "test accuracy achieved:  0.6123446226119995\n",
      "\n",
      "working on truth table:  ex41\n",
      "input size =  10\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2888\n",
      "test accuracy achieved:  0.8682795763015747\n",
      "\n",
      "working on truth table:  ex42\n",
      "input size =  32\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2691\n",
      "test accuracy achieved:  0.5074999928474426\n",
      "\n",
      "working on truth table:  ex43\n",
      "input size =  18\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2089\n",
      "test accuracy achieved:  0.5456250905990601\n",
      "\n",
      "working on truth table:  ex44\n",
      "input size =  64\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3761\n",
      "test accuracy achieved:  0.5009373426437378\n",
      "\n",
      "working on truth table:  ex45\n",
      "input size =  34\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3702\n",
      "test accuracy achieved:  0.5265626311302185\n",
      "\n",
      "working on truth table:  ex46\n",
      "input size =  128\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3523\n",
      "test accuracy achieved:  0.5040624141693115\n",
      "\n",
      "working on truth table:  ex47\n",
      "input size =  66\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3053\n",
      "test accuracy achieved:  0.5140625238418579\n",
      "\n",
      "working on truth table:  ex48\n",
      "input size =  256\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6002\n",
      "test accuracy achieved:  0.5145314335823059\n",
      "\n",
      "working on truth table:  ex49\n",
      "input size =  130\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4125\n",
      "test accuracy achieved:  0.504218578338623\n",
      "\n",
      "working on truth table:  ex50\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4101\n",
      "test accuracy achieved:  0.8826549649238586\n",
      "\n",
      "working on truth table:  ex51\n",
      "input size =  44\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3282\n",
      "test accuracy achieved:  0.5628132820129395\n",
      "\n",
      "working on truth table:  ex52\n",
      "input size =  59\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3412\n",
      "test accuracy achieved:  0.6234382390975952\n",
      "\n",
      "working on truth table:  ex53\n",
      "input size =  45\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4348\n",
      "test accuracy achieved:  0.7984364628791809\n",
      "\n",
      "working on truth table:  ex54\n",
      "input size =  48\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3776\n",
      "test accuracy achieved:  0.9407804608345032\n",
      "\n",
      "working on truth table:  ex55\n",
      "input size =  42\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3745\n",
      "test accuracy achieved:  0.9848435521125793\n",
      "\n",
      "working on truth table:  ex56\n",
      "input size =  83\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2711\n",
      "test accuracy achieved:  0.8481237292289734\n",
      "\n",
      "working on truth table:  ex57\n",
      "input size =  24\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3764\n",
      "test accuracy achieved:  0.9803126454353333\n",
      "\n",
      "working on truth table:  ex58\n",
      "input size =  80\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4408\n",
      "test accuracy achieved:  0.9582813382148743\n",
      "\n",
      "working on truth table:  ex59\n",
      "input size =  394\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9604\n",
      "test accuracy achieved:  0.5928126573562622\n",
      "\n",
      "working on truth table:  ex60\n",
      "input size =  43\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4542\n",
      "test accuracy achieved:  0.8924986124038696\n",
      "\n",
      "working on truth table:  ex61\n",
      "input size =  37\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5008\n",
      "test accuracy achieved:  0.9967187643051147\n",
      "\n",
      "working on truth table:  ex62\n",
      "input size =  52\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4236\n",
      "test accuracy achieved:  0.8579676747322083\n",
      "\n",
      "working on truth table:  ex63\n",
      "input size =  38\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5118\n",
      "test accuracy achieved:  0.9328117370605469\n",
      "\n",
      "working on truth table:  ex64\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3000\n",
      "test accuracy achieved:  0.981249988079071\n",
      "\n",
      "working on truth table:  ex65\n",
      "input size =  19\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3642\n",
      "test accuracy achieved:  0.9392186403274536\n",
      "\n",
      "working on truth table:  ex66\n",
      "input size =  47\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3496\n",
      "test accuracy achieved:  0.8510920405387878\n",
      "\n",
      "working on truth table:  ex67\n",
      "input size =  46\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4986\n",
      "test accuracy achieved:  0.8384356498718262\n",
      "\n",
      "working on truth table:  ex68\n",
      "input size =  33\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4214\n",
      "test accuracy achieved:  0.9060922861099243\n",
      "\n",
      "working on truth table:  ex69\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3656\n",
      "test accuracy achieved:  0.9687502980232239\n",
      "\n",
      "working on truth table:  ex70\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3640\n",
      "test accuracy achieved:  0.9918750524520874\n",
      "\n",
      "working on truth table:  ex71\n",
      "input size =  23\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  4755\n",
      "test accuracy achieved:  0.9943751096725464\n",
      "\n",
      "working on truth table:  ex72\n",
      "input size =  35\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3828\n",
      "test accuracy achieved:  0.8670296669006348\n",
      "\n",
      "working on truth table:  ex73\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  3241\n",
      "test accuracy achieved:  0.659531831741333\n",
      "\n",
      "working on truth table:  ex74\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2416\n",
      "test accuracy achieved:  0.5149997472763062\n",
      "\n",
      "working on truth table:  ex75\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1010\n",
      "test accuracy achieved:  0.39749976992607117\n",
      "\n",
      "working on truth table:  ex76\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2594\n",
      "test accuracy achieved:  0.22281226515769958\n",
      "\n",
      "working on truth table:  ex77\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1850\n",
      "test accuracy achieved:  0.21796849370002747\n",
      "\n",
      "working on truth table:  ex78\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  2739\n",
      "test accuracy achieved:  0.6368752717971802\n",
      "\n",
      "working on truth table:  ex79\n",
      "input size =  16\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  1672\n",
      "test accuracy achieved:  0.22499990463256836\n",
      "\n",
      "working on truth table:  ex80\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9473\n",
      "test accuracy achieved:  0.5634379982948303\n",
      "\n",
      "working on truth table:  ex81\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7756\n",
      "test accuracy achieved:  0.7568740844726562\n",
      "\n",
      "working on truth table:  ex82\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  6972\n",
      "test accuracy achieved:  0.7396873235702515\n",
      "\n",
      "working on truth table:  ex83\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9066\n",
      "test accuracy achieved:  0.5912501811981201\n",
      "\n",
      "working on truth table:  ex84\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  7243\n",
      "test accuracy achieved:  0.4789060652256012\n",
      "\n",
      "working on truth table:  ex85\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  9721\n",
      "test accuracy achieved:  0.8015613555908203\n",
      "\n",
      "working on truth table:  ex86\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8085\n",
      "test accuracy achieved:  0.5585938692092896\n",
      "\n",
      "working on truth table:  ex87\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8356\n",
      "test accuracy achieved:  0.8017171621322632\n",
      "\n",
      "working on truth table:  ex88\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  8804\n",
      "test accuracy achieved:  0.7706242203712463\n",
      "\n",
      "working on truth table:  ex89\n",
      "input size =  196\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  5171\n",
      "test accuracy achieved:  0.67875075340271\n",
      "\n",
      "working on truth table:  ex90\n",
      "input size =  768\n",
      "pruning\n",
      "getting size of aig\n",
      "size of aig:  15571\n",
      "test accuracy achieved:  0.5274998545646667\n"
     ]
    }
   ],
   "source": [
    "# Run experiment 4\n",
    "\n",
    "# read the .pla file\n",
    "# preprocess the .pla file to get the features and labels as tensors\n",
    "# form a dataloader\n",
    "# define the neural net\n",
    "# train the model for 100 epochs\n",
    "# prune the model\n",
    "# get aig size\n",
    "# test the model, note the accuracy\n",
    "\n",
    "results = []\n",
    "for i in range(len(train_files)-9): # ignore 768 \n",
    "  \n",
    "  # get id of circuit\n",
    "  ex_id = train_files[i][ train_files[i].index('ex'):train_files[i].index('ex')+4  ]\n",
    "  \n",
    "  # read the .pla file and preprocess the .pla file to get the features and labels as tensors\n",
    "  features_train, labels_train, features_test, labels_test = get_tensors_from_example_files( train_files[i], test_files[i] )\n",
    "  \n",
    "  # form dataloaders\n",
    "  train_data_iter, test_data_iter = get_dataloaders( features_train, labels_train, features_test, labels_test )\n",
    "  \n",
    "  # get input size\n",
    "  input_size = features_train[0].size()[0]\n",
    "  \n",
    "  # form net\n",
    "  net, Loss, optimizer = define_neural_net( input_size )\n",
    "\n",
    "  print(\"\\nworking on truth table: \", ex_id)\n",
    "  print(\"input size = \", input_size)\n",
    "\n",
    "  # train\n",
    "  net = train_truth_table( net, Loss, optimizer, train_data_iter, 100, features_train, labels_train )\n",
    "\n",
    "  print(\"pruning\")\n",
    "  net = prune_model(input_size, net)\n",
    "  \n",
    "  print(\"getting size of aig\")\n",
    "  # get size of aig\n",
    "  size_aig = get_aig_size(net) \n",
    "  print(\"size of aig: \", size_aig)\n",
    "\n",
    "  #get accuracy\n",
    "  test_accuracy = test_net( net, test_data_iter )\n",
    "\n",
    "  # print info\n",
    "#   if (i%5==0):\n",
    "  print(\"test accuracy achieved: \", test_accuracy.item())\n",
    "\n",
    "  # get result and append results list\n",
    "  result = (ex_id, input_size, test_accuracy.item(), size_aig )\n",
    "  results.append( result )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "11f011dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ex00', 32, 0.6967187523841858, 3893), ('ex01', 32, 0.9317179918289185, 3345), ('ex02', 64, 0.7504680752754211, 4323), ('ex03', 64, 0.9160928726196289, 4033), ('ex04', 128, 0.5137501955032349, 3319), ('ex05', 128, 0.9671874046325684, 4176), ('ex06', 256, 0.5171875357627869, 5450), ('ex07', 256, 0.9387494325637817, 7999), ('ex08', 512, 0.506250262260437, 10781), ('ex09', 512, 0.9842191934585571, 12781), ('ex10', 32, 0.852811336517334, 4618), ('ex11', 64, 0.8257796168327332, 4650), ('ex12', 128, 0.7937485575675964, 4248), ('ex13', 256, 0.766874372959137, 5571), ('ex14', 512, 0.7571872472763062, 9639), ('ex15', 32, 0.8978112936019897, 4052), ('ex16', 64, 0.8917175531387329, 3395), ('ex17', 128, 0.7814052700996399, 3904), ('ex18', 256, 0.7017187476158142, 5977), ('ex19', 512, 0.5360939502716064, 14567), ('ex20', 16, 0.5235940217971802, 2525), ('ex21', 16, 0.9832812547683716, 3016), ('ex22', 32, 0.5195313692092896, 3529), ('ex23', 32, 1.0, 3897), ('ex24', 64, 0.4960938096046448, 3202), ('ex25', 64, 0.5051563382148743, 1984), ('ex26', 128, 0.5006247162818909, 4268), ('ex27', 128, 1.0, 4072), ('ex28', 256, 0.5001562833786011, 5106), ('ex29', 256, 1.0, 5495), ('ex30', 20, 0.9723436236381531, 2408), ('ex31', 40, 0.9679689407348633, 3133), ('ex32', 60, 0.970000147819519, 3903), ('ex33', 80, 0.9726560711860657, 4622), ('ex34', 100, 0.9659374356269836, 4073), ('ex35', 120, 0.9706252217292786, 4212), ('ex36', 140, 0.9831250309944153, 6847), ('ex37', 160, 0.9854686856269836, 7921), ('ex38', 180, 0.9715625643730164, 6846), ('ex39', 200, 0.9776561856269836, 4864), ('ex40', 16, 0.6123446226119995, 3653), ('ex41', 10, 0.8682795763015747, 2888), ('ex42', 32, 0.5074999928474426, 2691), ('ex43', 18, 0.5456250905990601, 2089), ('ex44', 64, 0.5009373426437378, 3761), ('ex45', 34, 0.5265626311302185, 3702), ('ex46', 128, 0.5040624141693115, 3523), ('ex47', 66, 0.5140625238418579, 3053), ('ex48', 256, 0.5145314335823059, 6002), ('ex49', 130, 0.504218578338623, 4125), ('ex50', 19, 0.8826549649238586, 4101), ('ex51', 44, 0.5628132820129395, 3282), ('ex52', 59, 0.6234382390975952, 3412), ('ex53', 45, 0.7984364628791809, 4348), ('ex54', 48, 0.9407804608345032, 3776), ('ex55', 42, 0.9848435521125793, 3745), ('ex56', 83, 0.8481237292289734, 2711), ('ex57', 24, 0.9803126454353333, 3764), ('ex58', 80, 0.9582813382148743, 4408), ('ex59', 394, 0.5928126573562622, 9604), ('ex60', 43, 0.8924986124038696, 4542), ('ex61', 37, 0.9967187643051147, 5008), ('ex62', 52, 0.8579676747322083, 4236), ('ex63', 38, 0.9328117370605469, 5118), ('ex64', 47, 0.981249988079071, 3000), ('ex65', 19, 0.9392186403274536, 3642), ('ex66', 47, 0.8510920405387878, 3496), ('ex67', 46, 0.8384356498718262, 4986), ('ex68', 33, 0.9060922861099243, 4214), ('ex69', 16, 0.9687502980232239, 3656), ('ex70', 23, 0.9918750524520874, 3640), ('ex71', 23, 0.9943751096725464, 4755), ('ex72', 35, 0.8670296669006348, 3828), ('ex73', 16, 0.659531831741333, 3241), ('ex74', 16, 0.5149997472763062, 2416), ('ex75', 16, 0.39749976992607117, 1010), ('ex76', 16, 0.22281226515769958, 2594), ('ex77', 16, 0.21796849370002747, 1850), ('ex78', 16, 0.6368752717971802, 2739), ('ex79', 16, 0.22499990463256836, 1672), ('ex80', 196, 0.5634379982948303, 9473), ('ex81', 196, 0.7568740844726562, 7756), ('ex82', 196, 0.7396873235702515, 6972), ('ex83', 196, 0.5912501811981201, 9066), ('ex84', 196, 0.4789060652256012, 7243), ('ex85', 196, 0.8015613555908203, 9721), ('ex86', 196, 0.5585938692092896, 8085), ('ex87', 196, 0.8017171621322632, 8356), ('ex88', 196, 0.7706242203712463, 8804), ('ex89', 196, 0.67875075340271, 5171), ('ex90', 768, 0.5274998545646667, 15571)]\n"
     ]
    }
   ],
   "source": [
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "d3da1f33",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"results_exp4.txt\",\"w\")\n",
    "f.write(str(results))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "6df7ba0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 91 benchmarks=  74.97318524580734  %\n",
      "28 networks exceeded size constraint:\n",
      "['ex06' 'ex07' 'ex08' 'ex09' 'ex13' 'ex14' 'ex18' 'ex19' 'ex28' 'ex29'\n",
      " 'ex36' 'ex37' 'ex38' 'ex48' 'ex59' 'ex61' 'ex63' 'ex80' 'ex81' 'ex82'\n",
      " 'ex83' 'ex84' 'ex85' 'ex86' 'ex87' 'ex88' 'ex89' 'ex90']\n",
      "overall accuracy across benchmarks under size constraints=  75.82734572508978  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 91 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5204304f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
