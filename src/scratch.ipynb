{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0e22b8b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils import data\n",
    "from torch import nn\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch.nn.utils.prune as prune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "c33997bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012.02530.pdf                   \u001b[0m\u001b[01;34miwls2020-lsml-contest\u001b[0m/\r\n",
      "DL_project_Experiments.ipynb     lut_verilog.aig\r\n",
      "DL_Project_Plan_Baleegh.pdf      lut_verilog.v\r\n",
      "DL_Project_Proposal_Baleegh.pdf  neuron_to_aig_size.ys\r\n",
      "DL_Project_Update_Baleegh.pdf    NN_to_AIG.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee44319f",
   "metadata": {},
   "source": [
    "## Training one circuit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b11c9568",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read file from train directory\n",
    "file_data = open('iwls2020-lsml-contest/benchmarks/train/ex41.train.pla', 'r')\n",
    "file_data = file_data.readlines()\n",
    "\n",
    "# preprocess file to separate inputs and outputs\n",
    "x = []\n",
    "y = []\n",
    "for line in file_data:\n",
    "  if not (line.startswith('.')):\n",
    "    x.append( line[:line.index(' ')] )\n",
    "    y.append( line[ line.index(' ')+1:line.index(' ')+2 ] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "8f966d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' convert data to tensors  '''\n",
    "\n",
    "# separates string to characters \n",
    "def split(word): \n",
    "    return [char for char in word] \n",
    "\n",
    "for i,input in enumerate(x):\n",
    "  x[i] = split(input)\n",
    "  # convert each character to integer\n",
    "  for j,bit in enumerate(x[i]):\n",
    "      x[i][j] = int(bit)\n",
    "\n",
    "features = torch.FloatTensor(x)\n",
    "y = [int(i) for i in y]\n",
    "labels = torch.FloatTensor(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "fc4c4ad2",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Form a data iterator with batch size 10 '''\n",
    "\n",
    "def load_array(data_arrays, batch_size, is_train=True):\n",
    "    \"\"\"Construct a PyTorch data iterator.\"\"\"\n",
    "    dataset = data.TensorDataset(*data_arrays)\n",
    "    return data.DataLoader(dataset, batch_size, shuffle=is_train)\n",
    "\n",
    "batch_size = 10\n",
    "data_iter = load_array((features, labels), batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "c131cacc",
   "metadata": {},
   "outputs": [],
   "source": [
    "''' Setting the neural network '''\n",
    "\n",
    "class BinaryClassification(nn.Module):\n",
    "  def __init__(self, input_size=32):\n",
    "    super(BinaryClassification, self).__init__()\n",
    "    self.linear1 = nn.Linear(input_size,10)\n",
    "    self.linear2 = nn.Linear(10,1)\n",
    "\n",
    "  def forward(self, x):\n",
    "    x = torch.sigmoid( self.linear1(x) )\n",
    "    x = torch.sigmoid( self.linear2(x) )\n",
    "    return x\n",
    "\n",
    "# instantating the network, loss function and optimizer\n",
    "\n",
    "net = BinaryClassification(10) # set input size as size of sample\n",
    "\n",
    "Loss = nn.BCELoss()\n",
    "optimizer = torch.optim.SGD(net.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "6ec69d5d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BinaryClassification(\n",
      "  (linear1): Linear(in_features=10, out_features=10, bias=True)\n",
      "  (linear2): Linear(in_features=10, out_features=1, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# print model\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "2f3de812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define accuracy function\n",
    "\n",
    "def accuracy(output,labels):\n",
    "  output = output >=0.5\n",
    "  acc = torch.sum(output==labels)/len(labels)\n",
    "  return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "id": "e9c5129f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch   1, loss 0.694, acc 0.506\n",
      "epoch  11, loss 0.686, acc 0.588\n",
      "epoch  21, loss 0.677, acc 0.579\n",
      "epoch  31, loss 0.673, acc 0.586\n",
      "epoch  41, loss 0.672, acc 0.587\n",
      "epoch  51, loss 0.671, acc 0.582\n",
      "epoch  61, loss 0.670, acc 0.591\n",
      "epoch  71, loss 0.669, acc 0.590\n",
      "epoch  81, loss 0.666, acc 0.595\n",
      "epoch  91, loss 0.660, acc 0.609\n",
      "epoch 101, loss 0.647, acc 0.630\n",
      "epoch 111, loss 0.622, acc 0.665\n",
      "epoch 121, loss 0.590, acc 0.718\n",
      "epoch 131, loss 0.558, acc 0.744\n",
      "epoch 141, loss 0.528, acc 0.755\n",
      "epoch 151, loss 0.499, acc 0.774\n",
      "epoch 161, loss 0.470, acc 0.787\n",
      "epoch 171, loss 0.443, acc 0.793\n",
      "epoch 181, loss 0.419, acc 0.806\n",
      "epoch 191, loss 0.397, acc 0.822\n",
      "epoch 201, loss 0.378, acc 0.833\n",
      "epoch 211, loss 0.361, acc 0.852\n",
      "epoch 221, loss 0.346, acc 0.859\n",
      "epoch 231, loss 0.333, acc 0.876\n",
      "epoch 241, loss 0.322, acc 0.882\n"
     ]
    }
   ],
   "source": [
    "''' train the model '''\n",
    "\n",
    "num_epochs = 250\n",
    "acc_list = []\n",
    "loss_list = []\n",
    "for epoch in range(num_epochs):\n",
    "    for X, y in data_iter:\n",
    "        output = net(X)\n",
    "        l = Loss(output, y.reshape(-1,1) )\n",
    "        optimizer.zero_grad()\n",
    "        l.backward()\n",
    "        optimizer.step()\n",
    "    if (epoch%10==0):\n",
    "      acc = accuracy(net(features), labels.reshape(-1,1))\n",
    "      l = Loss(net(features), labels.reshape(-1,1))\n",
    "      acc_list.append(acc)\n",
    "      loss_list.append(l)\n",
    "      print(f'epoch {epoch + 1:3d}, loss {l:.3f}, acc {acc:.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353f2cd8",
   "metadata": {},
   "source": [
    "## Pruning the NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "9069575f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear1.weight', Parameter containing:\n",
      "tensor([[ 1.0960e-01,  4.3661e-01,  2.6416e-01,  1.6291e-01, -2.6509e-02,\n",
      "          7.6564e-02,  6.7869e-02,  1.6099e-01, -8.0609e-02,  4.3602e-02],\n",
      "        [ 8.3641e-02,  2.9836e-02,  3.5097e-01,  2.2662e-01,  2.0432e+00,\n",
      "          3.6572e+00, -5.1624e+00,  9.9808e-01,  3.8695e+00, -3.7419e+00],\n",
      "        [ 1.2418e-01,  2.3284e-01,  2.5562e-01,  9.3909e-01,  1.3750e+00,\n",
      "          3.3864e+00, -5.3376e+00,  3.6121e+00,  4.4344e+00,  1.4706e+00],\n",
      "        [ 4.0909e-02,  8.5845e-02, -1.6959e-03, -1.4677e-01, -1.1396e+00,\n",
      "         -1.1615e+00,  6.7294e-01,  1.5922e+00,  1.2332e+00,  1.1715e+00],\n",
      "        [ 2.9991e-02,  1.7426e-01,  1.0923e-01, -1.6352e-02, -8.7618e-01,\n",
      "         -8.1659e-01,  4.5848e-01,  1.3804e+00,  9.7157e-01,  9.8646e-01],\n",
      "        [-2.8377e-02, -2.1358e-01, -3.0881e-02, -2.1885e-02,  1.3925e+00,\n",
      "          1.1089e+00, -4.3754e-01, -1.5286e+00, -1.2769e+00, -9.2894e-01],\n",
      "        [-6.4696e-02, -4.7815e-02,  3.8569e-01,  3.1519e-01, -5.3477e-01,\n",
      "         -3.0679e-01, -1.5744e-01,  9.4814e-01,  4.0667e-01,  4.7894e-01],\n",
      "        [-8.5963e-02, -2.8295e-01, -2.4633e-01, -3.0504e-01,  1.3863e+00,\n",
      "         -1.2826e+00, -2.8319e+00,  4.5161e-01, -4.8345e-01,  2.9240e+00],\n",
      "        [ 1.4565e-01, -1.4348e-01, -8.8089e-02,  9.3150e-02,  2.8659e-01,\n",
      "         -1.8165e-01,  1.8491e-01,  1.1035e-01,  3.1839e-01,  1.1745e-01],\n",
      "        [-3.0092e-01, -3.7465e-01,  5.0506e-03,  5.7433e-02, -1.4224e+00,\n",
      "          9.5491e-01, -6.5226e-01, -4.4109e-01, -6.8528e-01,  1.8320e+00]],\n",
      "       requires_grad=True)), ('linear1.bias', Parameter containing:\n",
      "tensor([-0.2295, -1.7540, -2.1298,  0.5336,  0.3105, -0.8131,  0.3295, -1.1484,\n",
      "        -0.1051, -0.8901], requires_grad=True)), ('linear2.weight', Parameter containing:\n",
      "tensor([[ 0.3784, -7.5175,  9.0798, -1.8427, -1.3592,  2.3969, -0.7881, -3.6174,\n",
      "          0.2834, -2.3275]], requires_grad=True)), ('linear2.bias', Parameter containing:\n",
      "tensor([0.8271], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# before pruning\n",
    "print(list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "id": "27bedca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# prune \n",
    "\n",
    "# get max fan in\n",
    "# max input size : 768, min: 10\n",
    "# max fan-in = 15\n",
    "\n",
    "# mapping function: output = output_start + ((output_end - output_start) / (input_end - input_start)) * (input - input_start)\n",
    "# map [10...768] to [8...12]\n",
    "\n",
    "input_size = 128\n",
    "remain_after_pruning = 8 + ( (12-8)/(768-10) )*(input_size-10)\n",
    "pruning_ratio = (input_size-remain_after_pruning)/input_size\n",
    "\n",
    "# prune first layer\n",
    "prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.2\n",
    "    )\n",
    "\n",
    "prune.ln_structured(\n",
    "       net.linear1, 'weight', amount=pruning_ratio, dim=1, n='fro' # sets max fan-in to 12\n",
    "    )\n",
    "\n",
    "prune.l1_unstructured(\n",
    "       net.linear1, 'weight', amount=0.3\n",
    "    )\n",
    "\n",
    "# prune second layer\n",
    "prune.ln_structured(\n",
    "       net.linear2, 'weight', amount=0.2, dim=1, n='fro'\n",
    "    )\n",
    "\n",
    "# parameters_to_prune = (\n",
    "#     (net.linear1, 'weight'),\n",
    "#     (net.linear2, 'weight')\n",
    "# )\n",
    "\n",
    "# prune.global_unstructured(\n",
    "#     parameters_to_prune,\n",
    "#     pruning_method=prune.L1Unstructured,\n",
    "#     amount=pruning_ratio,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "08da4950",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear1.weight_mask', tensor([[0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 0., 0., 0., 0.],\n",
      "        [0., 0., 0., 0., 0., 0., 1., 0., 0., 0.]])), ('linear2.weight_mask', tensor([[0., 1., 1., 1., 1., 1., 1., 1., 0., 1.]]))]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.named_buffers()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "id": "28c37398",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_masks = list(net.named_buffers())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac2853d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "2b9866ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=10, out_features=1, bias=True)"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# after pruning\n",
    "prune.remove(net.linear1, 'weight') # makes pruning permanent\n",
    "prune.remove(net.linear2, 'weight') # makes pruning permanent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "id": "ebd674bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear1.bias', Parameter containing:\n",
      "tensor([-0.2295, -1.7540, -2.1298,  0.5336,  0.3105, -0.8131,  0.3295, -1.1484,\n",
      "        -0.1051, -0.8901], requires_grad=True)), ('linear1.weight', Parameter containing:\n",
      "tensor([[ 0.0000,  0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -5.1624,  0.0000,\n",
      "          0.0000, -0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -5.3376,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000, -0.0000, -0.0000, -0.0000, -0.0000,  0.6729,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [ 0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.4585,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000,\n",
      "         -0.0000, -0.0000],\n",
      "        [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000, -0.0000, -0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000, -0.0000, -0.0000,  0.0000, -0.0000, -2.8319,  0.0000,\n",
      "         -0.0000,  0.0000],\n",
      "        [ 0.0000, -0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000,  0.0000,\n",
      "          0.0000,  0.0000],\n",
      "        [-0.0000, -0.0000,  0.0000,  0.0000, -0.0000,  0.0000, -0.6523, -0.0000,\n",
      "         -0.0000,  0.0000]], requires_grad=True)), ('linear2.bias', Parameter containing:\n",
      "tensor([0.8271], requires_grad=True)), ('linear2.weight', Parameter containing:\n",
      "tensor([[ 0.0000, -7.5175,  9.0798, -1.8427, -1.3592,  2.3969, -0.7881, -3.6174,\n",
      "          0.0000, -2.3275]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "id": "4943c0b5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(list(net.named_buffers()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "286bc8f0",
   "metadata": {},
   "source": [
    "## NN --> AIG "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72f60f42",
   "metadata": {},
   "source": [
    "### Neuron -> LUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "bf8bb289",
   "metadata": {},
   "outputs": [],
   "source": [
    "neurons = [] # each element is a neuron with a weight vector and a bias scalar\n",
    "weights = [] # each element is the weight matrix of a layer\n",
    "biases  = [] # each element contains biases for that layer\n",
    "for name, param in net.named_parameters():\n",
    "    if '.weight'in name:\n",
    "        weights.append( param.detach().numpy() )\n",
    "    if '.bias' in name:\n",
    "        biases.append( param.detach().numpy() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "7afe6120",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([[ 0.        ,  0.        ,  0.        ,  0.        , -0.        ,\n",
       "          0.        ,  0.        ,  0.        , -0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        , -5.1623898 ,  0.        ,  0.        , -0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        ,  0.        ,  0.        ,\n",
       "          0.        , -5.337557  ,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        , -0.        , -0.        , -0.        ,\n",
       "         -0.        ,  0.67293656,  0.        ,  0.        ,  0.        ],\n",
       "        [ 0.        ,  0.        ,  0.        , -0.        , -0.        ,\n",
       "         -0.        ,  0.458483  ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "          0.        , -0.        , -0.        , -0.        , -0.        ],\n",
       "        [-0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "         -0.        , -0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.        , -0.        , -0.        , -0.        ,  0.        ,\n",
       "         -0.        , -2.8319395 ,  0.        , -0.        ,  0.        ],\n",
       "        [ 0.        , -0.        , -0.        ,  0.        ,  0.        ,\n",
       "         -0.        ,  0.        ,  0.        ,  0.        ,  0.        ],\n",
       "        [-0.        , -0.        ,  0.        ,  0.        , -0.        ,\n",
       "          0.        , -0.6522644 , -0.        , -0.        ,  0.        ]],\n",
       "       dtype=float32),\n",
       " array([[ 0.        , -7.5174575 ,  9.0798025 , -1.8427022 , -1.3592473 ,\n",
       "          2.39685   , -0.78806216, -3.6174304 ,  0.        , -2.3274615 ]],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 243,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "7d978392",
   "metadata": {},
   "outputs": [],
   "source": [
    "weights.reverse()\n",
    "biases.reverse()\n",
    "ignore_neurons = [] # element in list: (i,j) neuron j in layer i\n",
    "for i,layer_weights in enumerate(weights): # i = layer (starting from highest)\n",
    "    \n",
    "    # check which neurons in lower layer can be ignored\n",
    "    for k in range( len(layer_weights[0]) ):\n",
    "        if( len( np.nonzero(layer_weights[:,k])[0] )==0 ):\n",
    "            ignore_neurons.append( (i+1,k) )\n",
    "    \n",
    "    for j,weight_vector in enumerate(layer_weights): # j = neuron in layer i\n",
    "        \n",
    "        if not (i,j) in ignore_neurons:\n",
    "            neurons.append((weight_vector,biases[i][j]))\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f3e0fe6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_lut_y\n",
    "def get_lut_y(input_size,w,b):\n",
    "    \n",
    "    lut_y = np.zeros( (pow(2,input_size)), dtype=bool )\n",
    "    \n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    \n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        \n",
    "#         print(idx)\n",
    "#         print(\"input vector: \", input_vector)\n",
    "        \n",
    "        #get entry in LUT\n",
    "        out = input_vector.dot(w) + b\n",
    "        lut_y[idx] = 1/(1 + np.exp(-out)) >=0.5\n",
    "        \n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0\n",
    "    \n",
    "    return lut_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "622d521d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-0.18343121 -0.168278    2.5306463   1.9195784  -0.70866174 -2.5188968\n",
      " -1.9900677  -1.3493629 ]\n",
      "-1.2743713\n",
      "8\n",
      "(256,)\n",
      "[0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "for neuron in neurons: \n",
    "    '''form LUT for each neuron'''\n",
    "    w = neuron[0]\n",
    "    b = neuron[1]\n",
    "    w = w[w.nonzero()]\n",
    "    input_size = len(w)\n",
    "    \n",
    "    print(w)\n",
    "    print(b)\n",
    "    print(input_size)\n",
    "    \n",
    "    lut_y = get_lut_y(input_size, w, b)\n",
    "    \n",
    "#     print( np.shape(lut_y) )\n",
    "#     print(lut_y[:10])\n",
    "    \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1fc02fa9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "[False]\n"
     ]
    }
   ],
   "source": [
    "print(len(lut_y))\n",
    "print(lut_y[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6d3dcf",
   "metadata": {},
   "source": [
    "### LUT --> Verilog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8bdfa544",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''create text for verilog file representing LUT'''\n",
    "\n",
    "n=input_size\n",
    "\n",
    "file_string ='module lut_verilog(\\ninput wire['+str(input_size-1)+':0] in,\\noutput reg out\\n);\\n\\nalways@(in) begin\\ncase(in)\\n'\n",
    "\n",
    "input_vector = np.zeros( (input_size) )\n",
    "for idx in range ( pow(2,input_size) ):\n",
    "    # add to file string\n",
    "    file_string += str(input_size)+'\\'b'+''.join(str(int(e)) for e in input_vector)+' : out = '+str(int(lut_y[idx]))+';\\n'\n",
    "    # increment input vector\n",
    "    for i in range(len(input_vector)-1, -1, -1):\n",
    "        if input_vector[i] == 0:\n",
    "            input_vector[i] = 1\n",
    "            break\n",
    "        input_vector[i] = 0\n",
    "\n",
    "file_string+='endcase\\nend\\nendmodule\\n'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "994ed8e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "module lut_verilog(\n",
      "input wire[7:0] in,\n",
      "output reg out\n",
      ");\n",
      "\n",
      "always@(in) begin\n",
      "case(in)\n",
      "8'b00000000 : out = 0;\n",
      "8'b00000001 : out = 0;\n",
      "8'b00000010 : out = 0;\n",
      "8'b00000011 : out = 0;\n",
      "8'b00000100 : out = 0;\n",
      "8'b00000101 : out = 0;\n",
      "8'b00000110 : out = 0;\n",
      "8'b00000111 : out = 0;\n",
      "8'b00001000 : out = 0;\n",
      "8'b00001001 : out = 0;\n",
      "8'b00001010 : out = 0;\n",
      "8'b00001011 : out = 0;\n",
      "8'b00001100 : out = 0;\n",
      "8'b00001101 : out = 0;\n",
      "8'b00001110 : out = 0;\n",
      "8'b00001111 : out = 0;\n",
      "8'b00010000 : out = 1;\n",
      "8'b00010001 : out = 0;\n",
      "8'b00010010 : out = 0;\n",
      "8'b00010011 : out = 0;\n",
      "8'b00010100 : out = 0;\n",
      "8'b00010101 : out = 0;\n",
      "8'b00010110 : out = 0;\n",
      "8'b00010111 : out = 0;\n",
      "8'b00011000 : out = 0;\n",
      "8'b00011001 : out = 0;\n",
      "8'b00011010 : out = 0;\n",
      "8'b00011011 : out = 0;\n",
      "8'b00011100 : out = 0;\n",
      "8'b00011101 : out = 0;\n",
      "8'b00011110 : out = 0;\n",
      "8'b00011111 : out = 0;\n",
      "8'b00100000 : out = 1;\n",
      "8'b00100001 : out = 0;\n",
      "8'b00100010 : out = 0;\n",
      "8'b00100011 : out = 0;\n",
      "8'b00100100 : out = 0;\n",
      "8'b00100101 : out = 0;\n",
      "8'b00100110 : out = 0;\n",
      "8'b00100111 : out = 0;\n",
      "8'b00101000 : out = 1;\n",
      "8'b00101001 : out = 0;\n",
      "8'b00101010 : out = 0;\n",
      "8'b00101011 : out = 0;\n",
      "8'b00101100 : out = 0;\n",
      "8'b00101101 : out = 0;\n",
      "8'b00101110 : out = 0;\n",
      "8'b00101111 : out = 0;\n",
      "8'b00110000 : out = 1;\n",
      "8'b00110001 : out = 1;\n",
      "8'b00110010 : out = 1;\n",
      "8'b00110011 : out = 0;\n",
      "8'b00110100 : out = 1;\n",
      "8'b00110101 : out = 0;\n",
      "8'b00110110 : out = 0;\n",
      "8'b00110111 : out = 0;\n",
      "8'b00111000 : out = 1;\n",
      "8'b00111001 : out = 1;\n",
      "8'b00111010 : out = 1;\n",
      "8'b00111011 : out = 0;\n",
      "8'b00111100 : out = 0;\n",
      "8'b00111101 : out = 0;\n",
      "8'b00111110 : out = 0;\n",
      "8'b00111111 : out = 0;\n",
      "8'b01000000 : out = 0;\n",
      "8'b01000001 : out = 0;\n",
      "8'b01000010 : out = 0;\n",
      "8'b01000011 : out = 0;\n",
      "8'b01000100 : out = 0;\n",
      "8'b01000101 : out = 0;\n",
      "8'b01000110 : out = 0;\n",
      "8'b01000111 : out = 0;\n",
      "8'b01001000 : out = 0;\n",
      "8'b01001001 : out = 0;\n",
      "8'b01001010 : out = 0;\n",
      "8'b01001011 : out = 0;\n",
      "8'b01001100 : out = 0;\n",
      "8'b01001101 : out = 0;\n",
      "8'b01001110 : out = 0;\n",
      "8'b01001111 : out = 0;\n",
      "8'b01010000 : out = 1;\n",
      "8'b01010001 : out = 0;\n",
      "8'b01010010 : out = 0;\n",
      "8'b01010011 : out = 0;\n",
      "8'b01010100 : out = 0;\n",
      "8'b01010101 : out = 0;\n",
      "8'b01010110 : out = 0;\n",
      "8'b01010111 : out = 0;\n",
      "8'b01011000 : out = 0;\n",
      "8'b01011001 : out = 0;\n",
      "8'b01011010 : out = 0;\n",
      "8'b01011011 : out = 0;\n",
      "8'b01011100 : out = 0;\n",
      "8'b01011101 : out = 0;\n",
      "8'b01011110 : out = 0;\n",
      "8'b01011111 : out = 0;\n",
      "8'b01100000 : out = 1;\n",
      "8'b01100001 : out = 0;\n",
      "8'b01100010 : out = 0;\n",
      "8'b01100011 : out = 0;\n",
      "8'b01100100 : out = 0;\n",
      "8'b01100101 : out = 0;\n",
      "8'b01100110 : out = 0;\n",
      "8'b01100111 : out = 0;\n",
      "8'b01101000 : out = 1;\n",
      "8'b01101001 : out = 0;\n",
      "8'b01101010 : out = 0;\n",
      "8'b01101011 : out = 0;\n",
      "8'b01101100 : out = 0;\n",
      "8'b01101101 : out = 0;\n",
      "8'b01101110 : out = 0;\n",
      "8'b01101111 : out = 0;\n",
      "8'b01110000 : out = 1;\n",
      "8'b01110001 : out = 1;\n",
      "8'b01110010 : out = 1;\n",
      "8'b01110011 : out = 0;\n",
      "8'b01110100 : out = 1;\n",
      "8'b01110101 : out = 0;\n",
      "8'b01110110 : out = 0;\n",
      "8'b01110111 : out = 0;\n",
      "8'b01111000 : out = 1;\n",
      "8'b01111001 : out = 1;\n",
      "8'b01111010 : out = 1;\n",
      "8'b01111011 : out = 0;\n",
      "8'b01111100 : out = 0;\n",
      "8'b01111101 : out = 0;\n",
      "8'b01111110 : out = 0;\n",
      "8'b01111111 : out = 0;\n",
      "8'b10000000 : out = 0;\n",
      "8'b10000001 : out = 0;\n",
      "8'b10000010 : out = 0;\n",
      "8'b10000011 : out = 0;\n",
      "8'b10000100 : out = 0;\n",
      "8'b10000101 : out = 0;\n",
      "8'b10000110 : out = 0;\n",
      "8'b10000111 : out = 0;\n",
      "8'b10001000 : out = 0;\n",
      "8'b10001001 : out = 0;\n",
      "8'b10001010 : out = 0;\n",
      "8'b10001011 : out = 0;\n",
      "8'b10001100 : out = 0;\n",
      "8'b10001101 : out = 0;\n",
      "8'b10001110 : out = 0;\n",
      "8'b10001111 : out = 0;\n",
      "8'b10010000 : out = 1;\n",
      "8'b10010001 : out = 0;\n",
      "8'b10010010 : out = 0;\n",
      "8'b10010011 : out = 0;\n",
      "8'b10010100 : out = 0;\n",
      "8'b10010101 : out = 0;\n",
      "8'b10010110 : out = 0;\n",
      "8'b10010111 : out = 0;\n",
      "8'b10011000 : out = 0;\n",
      "8'b10011001 : out = 0;\n",
      "8'b10011010 : out = 0;\n",
      "8'b10011011 : out = 0;\n",
      "8'b10011100 : out = 0;\n",
      "8'b10011101 : out = 0;\n",
      "8'b10011110 : out = 0;\n",
      "8'b10011111 : out = 0;\n",
      "8'b10100000 : out = 1;\n",
      "8'b10100001 : out = 0;\n",
      "8'b10100010 : out = 0;\n",
      "8'b10100011 : out = 0;\n",
      "8'b10100100 : out = 0;\n",
      "8'b10100101 : out = 0;\n",
      "8'b10100110 : out = 0;\n",
      "8'b10100111 : out = 0;\n",
      "8'b10101000 : out = 1;\n",
      "8'b10101001 : out = 0;\n",
      "8'b10101010 : out = 0;\n",
      "8'b10101011 : out = 0;\n",
      "8'b10101100 : out = 0;\n",
      "8'b10101101 : out = 0;\n",
      "8'b10101110 : out = 0;\n",
      "8'b10101111 : out = 0;\n",
      "8'b10110000 : out = 1;\n",
      "8'b10110001 : out = 1;\n",
      "8'b10110010 : out = 1;\n",
      "8'b10110011 : out = 0;\n",
      "8'b10110100 : out = 1;\n",
      "8'b10110101 : out = 0;\n",
      "8'b10110110 : out = 0;\n",
      "8'b10110111 : out = 0;\n",
      "8'b10111000 : out = 1;\n",
      "8'b10111001 : out = 1;\n",
      "8'b10111010 : out = 1;\n",
      "8'b10111011 : out = 0;\n",
      "8'b10111100 : out = 0;\n",
      "8'b10111101 : out = 0;\n",
      "8'b10111110 : out = 0;\n",
      "8'b10111111 : out = 0;\n",
      "8'b11000000 : out = 0;\n",
      "8'b11000001 : out = 0;\n",
      "8'b11000010 : out = 0;\n",
      "8'b11000011 : out = 0;\n",
      "8'b11000100 : out = 0;\n",
      "8'b11000101 : out = 0;\n",
      "8'b11000110 : out = 0;\n",
      "8'b11000111 : out = 0;\n",
      "8'b11001000 : out = 0;\n",
      "8'b11001001 : out = 0;\n",
      "8'b11001010 : out = 0;\n",
      "8'b11001011 : out = 0;\n",
      "8'b11001100 : out = 0;\n",
      "8'b11001101 : out = 0;\n",
      "8'b11001110 : out = 0;\n",
      "8'b11001111 : out = 0;\n",
      "8'b11010000 : out = 1;\n",
      "8'b11010001 : out = 0;\n",
      "8'b11010010 : out = 0;\n",
      "8'b11010011 : out = 0;\n",
      "8'b11010100 : out = 0;\n",
      "8'b11010101 : out = 0;\n",
      "8'b11010110 : out = 0;\n",
      "8'b11010111 : out = 0;\n",
      "8'b11011000 : out = 0;\n",
      "8'b11011001 : out = 0;\n",
      "8'b11011010 : out = 0;\n",
      "8'b11011011 : out = 0;\n",
      "8'b11011100 : out = 0;\n",
      "8'b11011101 : out = 0;\n",
      "8'b11011110 : out = 0;\n",
      "8'b11011111 : out = 0;\n",
      "8'b11100000 : out = 1;\n",
      "8'b11100001 : out = 0;\n",
      "8'b11100010 : out = 0;\n",
      "8'b11100011 : out = 0;\n",
      "8'b11100100 : out = 0;\n",
      "8'b11100101 : out = 0;\n",
      "8'b11100110 : out = 0;\n",
      "8'b11100111 : out = 0;\n",
      "8'b11101000 : out = 1;\n",
      "8'b11101001 : out = 0;\n",
      "8'b11101010 : out = 0;\n",
      "8'b11101011 : out = 0;\n",
      "8'b11101100 : out = 0;\n",
      "8'b11101101 : out = 0;\n",
      "8'b11101110 : out = 0;\n",
      "8'b11101111 : out = 0;\n",
      "8'b11110000 : out = 1;\n",
      "8'b11110001 : out = 1;\n",
      "8'b11110010 : out = 1;\n",
      "8'b11110011 : out = 0;\n",
      "8'b11110100 : out = 1;\n",
      "8'b11110101 : out = 0;\n",
      "8'b11110110 : out = 0;\n",
      "8'b11110111 : out = 0;\n",
      "8'b11111000 : out = 1;\n",
      "8'b11111001 : out = 1;\n",
      "8'b11111010 : out = 1;\n",
      "8'b11111011 : out = 0;\n",
      "8'b11111100 : out = 0;\n",
      "8'b11111101 : out = 0;\n",
      "8'b11111110 : out = 0;\n",
      "8'b11111111 : out = 0;\n",
      "endcase\n",
      "end\n",
      "endmodule\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(file_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b80f6bb6",
   "metadata": {},
   "source": [
    "### Verilog LUT --> AIG"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14060aa9",
   "metadata": {},
   "source": [
    "#### On the verilog file run the following commands:\n",
    "\n",
    "read_verilog lut_<>.v\n",
    "\n",
    "synth -flatten -top g <top_module>\n",
    "\n",
    "aigmap\n",
    "\n",
    "write_aiger lut_<>.aig\n",
    "\n",
    "\n",
    "get first line of lut_<>.aig : aig xxxx xx x x xxxx\n",
    "\n",
    "get the first number after aig <-- number of and gates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "000e0045",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " /----------------------------------------------------------------------------\\\n",
      " |                                                                            |\n",
      " |  yosys -- Yosys Open SYnthesis Suite                                       |\n",
      " |                                                                            |\n",
      " |  Copyright (C) 2012 - 2020  Claire Xenia Wolf <claire@yosyshq.com>         |\n",
      " |                                                                            |\n",
      " |  Permission to use, copy, modify, and/or distribute this software for any  |\n",
      " |  purpose with or without fee is hereby granted, provided that the above    |\n",
      " |  copyright notice and this permission notice appear in all copies.         |\n",
      " |                                                                            |\n",
      " |  THE SOFTWARE IS PROVIDED \"AS IS\" AND THE AUTHOR DISCLAIMS ALL WARRANTIES  |\n",
      " |  WITH REGARD TO THIS SOFTWARE INCLUDING ALL IMPLIED WARRANTIES OF          |\n",
      " |  MERCHANTABILITY AND FITNESS. IN NO EVENT SHALL THE AUTHOR BE LIABLE FOR   |\n",
      " |  ANY SPECIAL, DIRECT, INDIRECT, OR CONSEQUENTIAL DAMAGES OR ANY DAMAGES    |\n",
      " |  WHATSOEVER RESULTING FROM LOSS OF USE, DATA OR PROFITS, WHETHER IN AN     |\n",
      " |  ACTION OF CONTRACT, NEGLIGENCE OR OTHER TORTIOUS ACTION, ARISING OUT OF   |\n",
      " |  OR IN CONNECTION WITH THE USE OR PERFORMANCE OF THIS SOFTWARE.            |\n",
      " |                                                                            |\n",
      " \\----------------------------------------------------------------------------/\n",
      "\n",
      " Yosys 0.12+36 (git sha1 7608985d2, clang 10.0.0-4ubuntu1 -fPIC -Os)\n",
      "\n",
      "\n",
      "-- Executing script file `neuron_to_aig_size.ys' --\n",
      "\n",
      "1. Executing Verilog-2005 frontend: lut_verilog.v\n",
      "Parsing Verilog input from `lut_verilog.v' to AST representation.\n",
      "Generating RTLIL representation for module `\\lut_verilog'.\n",
      "Note: Assuming pure combinatorial block at lut_verilog.v:6.1-265.4 in\n",
      "compliance with IEC 62142(E):2005 / IEEE Std. 1364.1(E):2002. Recommending\n",
      "use of @* instead of @(...) for better match of synthesis and simulation.\n",
      "Successfully finished Verilog frontend.\n",
      "\n",
      "2. Executing SYNTH pass.\n",
      "\n",
      "2.1. Executing HIERARCHY pass (managing design hierarchy).\n",
      "\n",
      "2.1.1. Analyzing design hierarchy..\n",
      "Top module:  \\lut_verilog\n",
      "\n",
      "2.1.2. Analyzing design hierarchy..\n",
      "Top module:  \\lut_verilog\n",
      "Removed 0 unused modules.\n",
      "\n",
      "2.2. Executing PROC pass (convert processes to netlists).\n",
      "\n",
      "2.2.1. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
      "Cleaned up 0 empty switches.\n",
      "\n",
      "2.2.2. Executing PROC_RMDEAD pass (remove dead branches from decision trees).\n",
      "Removed 1 dead cases from process $proc$lut_verilog.v:6$1 in module lut_verilog.\n",
      "Marked 1 switch rules as full_case in process $proc$lut_verilog.v:6$1 in module lut_verilog.\n",
      "Removed a total of 1 dead cases.\n",
      "\n",
      "2.2.3. Executing PROC_PRUNE pass (remove redundant assignments in processes).\n",
      "Removed 0 redundant assignments.\n",
      "Promoted 1 assignment to connection.\n",
      "\n",
      "2.2.4. Executing PROC_INIT pass (extract init attributes).\n",
      "\n",
      "2.2.5. Executing PROC_ARST pass (detect async resets in processes).\n",
      "\n",
      "2.2.6. Executing PROC_MUX pass (convert decision trees to multiplexers).\n",
      "Creating decoders for process `\\lut_verilog.$proc$lut_verilog.v:6$1'.\n",
      "     1/1: $1\\out[0:0]\n",
      "\n",
      "2.2.7. Executing PROC_DLATCH pass (convert process syncs to latches).\n",
      "No latch inferred for signal `\\lut_verilog.\\out' from process `\\lut_verilog.$proc$lut_verilog.v:6$1'.\n",
      "\n",
      "2.2.8. Executing PROC_DFF pass (convert process syncs to FFs).\n",
      "\n",
      "2.2.9. Executing PROC_MEMWR pass (convert process memory writes to cells).\n",
      "\n",
      "2.2.10. Executing PROC_CLEAN pass (remove empty switches from decision trees).\n",
      "Found and cleaned up 1 empty switch in `\\lut_verilog.$proc$lut_verilog.v:6$1'.\n",
      "Removing empty process `lut_verilog.$proc$lut_verilog.v:6$1'.\n",
      "Cleaned up 1 empty switch.\n",
      "\n",
      "2.2.11. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.3. Executing FLATTEN pass (flatten design).\n",
      "\n",
      "2.4. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.5. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "Removed 0 unused cells and 3 unused wires.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.6. Executing CHECK pass (checking for obvious problems).\n",
      "Checking module lut_verilog...\n",
      "Found and reported 0 problems.\n",
      "\n",
      "2.7. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.7.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.7.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.7.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
      "Running muxtree optimizer on module \\lut_verilog..\n",
      "  Creating internal representation of mux trees.\n",
      "  Evaluating internal representation of mux trees.\n",
      "  Analyzing evaluation results.\n",
      "Removed 0 multiplexer ports.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.7.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "    New ctrl vector for $pmux cell $procmux$2: { $auto$opt_reduce.cc:134:opt_mux$262 $auto$opt_reduce.cc:134:opt_mux$260 }\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "Performed a total of 1 changes.\n",
      "\n",
      "2.7.5. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.7.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.7.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.7.8. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.7.9. Rerunning OPT passes. (Maybe there is more to do..)\n",
      "\n",
      "2.7.10. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
      "Running muxtree optimizer on module \\lut_verilog..\n",
      "  Creating internal representation of mux trees.\n",
      "  Evaluating internal representation of mux trees.\n",
      "  Analyzing evaluation results.\n",
      "Removed 0 multiplexer ports.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.7.11. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "Performed a total of 0 changes.\n",
      "\n",
      "2.7.12. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.7.13. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.7.14. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.7.15. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.7.16. Finished OPT passes. (There is nothing left to do.)\n",
      "\n",
      "2.8. Executing FSM pass (extract and optimize FSM).\n",
      "\n",
      "2.8.1. Executing FSM_DETECT pass (finding FSMs in design).\n",
      "\n",
      "2.8.2. Executing FSM_EXTRACT pass (extracting FSM from design).\n",
      "\n",
      "2.8.3. Executing FSM_OPT pass (simple optimizations of FSMs).\n",
      "\n",
      "2.8.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.8.5. Executing FSM_OPT pass (simple optimizations of FSMs).\n",
      "\n",
      "2.8.6. Executing FSM_RECODE pass (re-assigning FSM state encoding).\n",
      "\n",
      "2.8.7. Executing FSM_INFO pass (dumping all available information on FSM cells).\n",
      "\n",
      "2.8.8. Executing FSM_MAP pass (mapping FSMs to basic logic).\n",
      "\n",
      "2.9. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.9.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.9.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.9.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
      "Running muxtree optimizer on module \\lut_verilog..\n",
      "  Creating internal representation of mux trees.\n",
      "  Evaluating internal representation of mux trees.\n",
      "  Analyzing evaluation results.\n",
      "Removed 0 multiplexer ports.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.9.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "Performed a total of 0 changes.\n",
      "\n",
      "2.9.5. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.9.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.9.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.9.8. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.9.9. Finished OPT passes. (There is nothing left to do.)\n",
      "\n",
      "2.10. Executing WREDUCE pass (reducing word size of cells).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$131_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$132_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$133_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$134_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$135_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$136_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$137_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$138_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$139_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$140_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$141_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$142_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$143_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$144_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$145_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$146_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$147_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$148_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$149_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$150_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$151_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$152_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$153_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$154_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$155_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$156_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$157_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$158_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$159_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$160_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$161_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$162_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$163_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$164_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$165_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$166_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$167_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$168_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$169_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$170_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$171_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$172_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$173_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$174_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$175_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$176_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$177_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$178_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$179_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$180_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$181_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$182_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$183_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$184_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$185_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$186_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$187_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$188_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$189_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$190_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$191_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$192_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$193_CMP0 ($eq).\n",
      "Removed top 1 bits (of 8) from port B of cell lut_verilog.$procmux$194_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$195_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$196_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$197_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$198_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$199_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$200_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$201_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$202_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$203_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$204_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$205_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$206_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$207_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$208_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$209_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$210_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$211_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$212_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$213_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$214_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$215_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$216_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$217_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$218_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$219_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$220_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$221_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$222_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$223_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$224_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$225_CMP0 ($eq).\n",
      "Removed top 2 bits (of 8) from port B of cell lut_verilog.$procmux$226_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$227_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$228_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$229_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$230_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$231_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$232_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$233_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$234_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$235_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$236_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$237_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$238_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$239_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$240_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$241_CMP0 ($eq).\n",
      "Removed top 3 bits (of 8) from port B of cell lut_verilog.$procmux$242_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$243_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$244_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$245_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$246_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$247_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$248_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$249_CMP0 ($eq).\n",
      "Removed top 4 bits (of 8) from port B of cell lut_verilog.$procmux$250_CMP0 ($eq).\n",
      "Removed top 5 bits (of 8) from port B of cell lut_verilog.$procmux$251_CMP0 ($eq).\n",
      "Removed top 5 bits (of 8) from port B of cell lut_verilog.$procmux$252_CMP0 ($eq).\n",
      "Removed top 5 bits (of 8) from port B of cell lut_verilog.$procmux$253_CMP0 ($eq).\n",
      "Removed top 5 bits (of 8) from port B of cell lut_verilog.$procmux$254_CMP0 ($eq).\n",
      "Removed top 6 bits (of 8) from port B of cell lut_verilog.$procmux$255_CMP0 ($eq).\n",
      "Removed top 6 bits (of 8) from port B of cell lut_verilog.$procmux$256_CMP0 ($eq).\n",
      "Removed top 7 bits (of 8) from port B of cell lut_verilog.$procmux$257_CMP0 ($eq).\n",
      "\n",
      "2.11. Executing PEEPOPT pass (run peephole optimizers).\n",
      "\n",
      "2.12. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.13. Executing ALUMACC pass (create $alu and $macc cells).\n",
      "Extracting $alu and $macc cells in module lut_verilog:\n",
      "  created 0 $alu and 0 $macc cells.\n",
      "\n",
      "2.14. Executing SHARE pass (SAT-based resource sharing).\n",
      "\n",
      "2.15. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.15.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.15.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.15.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
      "Running muxtree optimizer on module \\lut_verilog..\n",
      "  Creating internal representation of mux trees.\n",
      "  Evaluating internal representation of mux trees.\n",
      "  Analyzing evaluation results.\n",
      "Removed 0 multiplexer ports.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.15.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "Performed a total of 0 changes.\n",
      "\n",
      "2.15.5. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.15.6. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.15.7. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.15.8. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.15.9. Finished OPT passes. (There is nothing left to do.)\n",
      "\n",
      "2.16. Executing MEMORY pass.\n",
      "\n",
      "2.16.1. Executing OPT_MEM pass (optimize memories).\n",
      "Performed a total of 0 transformations.\n",
      "\n",
      "2.16.2. Executing OPT_MEM_PRIORITY pass (removing unnecessary memory write priority relations).\n",
      "Performed a total of 0 transformations.\n",
      "\n",
      "2.16.3. Executing OPT_MEM_FEEDBACK pass (finding memory read-to-write feedback paths).\n",
      "\n",
      "2.16.4. Executing MEMORY_DFF pass (merging $dff cells to $memrd).\n",
      "\n",
      "2.16.5. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.16.6. Executing MEMORY_SHARE pass (consolidating $memrd/$memwr cells).\n",
      "\n",
      "2.16.7. Executing OPT_MEM_WIDEN pass (optimize memories where all ports are wide).\n",
      "Performed a total of 0 transformations.\n",
      "\n",
      "2.16.8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.16.9. Executing MEMORY_COLLECT pass (generating $mem cells).\n",
      "\n",
      "2.17. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.18. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.18.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "<suppressed ~2 debug messages>\n",
      "\n",
      "2.18.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.18.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.18.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "Removed 41 unused cells and 41 unused wires.\n",
      "<suppressed ~42 debug messages>\n",
      "\n",
      "2.18.5. Finished fast OPT passes.\n",
      "\n",
      "2.19. Executing MEMORY_MAP pass (converting memories to logic and flip-flops).\n",
      "\n",
      "2.20. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.20.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.20.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.20.3. Executing OPT_MUXTREE pass (detect dead branches in mux trees).\n",
      "Running muxtree optimizer on module \\lut_verilog..\n",
      "  Creating internal representation of mux trees.\n",
      "  No muxes found in this module.\n",
      "Removed 0 multiplexer ports.\n",
      "\n",
      "2.20.4. Executing OPT_REDUCE pass (consolidate $*mux and $reduce_* inputs).\n",
      "  Optimizing cells in module \\lut_verilog.\n",
      "Performed a total of 0 changes.\n",
      "\n",
      "2.20.5. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.20.6. Executing OPT_SHARE pass.\n",
      "\n",
      "2.20.7. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.20.8. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "\n",
      "2.20.9. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.20.10. Finished OPT passes. (There is nothing left to do.)\n",
      "\n",
      "2.21. Executing TECHMAP pass (map to technology primitives).\n",
      "\n",
      "2.21.1. Executing Verilog-2005 frontend: /usr/local/bin/../share/yosys/techmap.v\n",
      "Parsing Verilog input from `/usr/local/bin/../share/yosys/techmap.v' to AST representation.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_bool_ops'.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_reduce_ops'.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_logic_ops'.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_compare_ops'.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_various'.\n",
      "Generating RTLIL representation for module `\\_90_simplemap_registers'.\n",
      "Generating RTLIL representation for module `\\_90_shift_ops_shr_shl_sshl_sshr'.\n",
      "Generating RTLIL representation for module `\\_90_shift_shiftx'.\n",
      "Generating RTLIL representation for module `\\_90_fa'.\n",
      "Generating RTLIL representation for module `\\_90_lcu'.\n",
      "Generating RTLIL representation for module `\\_90_alu'.\n",
      "Generating RTLIL representation for module `\\_90_macc'.\n",
      "Generating RTLIL representation for module `\\_90_alumacc'.\n",
      "Generating RTLIL representation for module `\\$__div_mod_u'.\n",
      "Generating RTLIL representation for module `\\$__div_mod_trunc'.\n",
      "Generating RTLIL representation for module `\\_90_div'.\n",
      "Generating RTLIL representation for module `\\_90_mod'.\n",
      "Generating RTLIL representation for module `\\$__div_mod_floor'.\n",
      "Generating RTLIL representation for module `\\_90_divfloor'.\n",
      "Generating RTLIL representation for module `\\_90_modfloor'.\n",
      "Generating RTLIL representation for module `\\_90_pow'.\n",
      "Generating RTLIL representation for module `\\_90_pmux'.\n",
      "Generating RTLIL representation for module `\\_90_lut'.\n",
      "Successfully finished Verilog frontend.\n",
      "\n",
      "2.21.2. Continuing TECHMAP pass.\n",
      "Using extmapper simplemap for cells of type $eq.\n",
      "Using extmapper simplemap for cells of type $reduce_or.\n",
      "Using extmapper simplemap for cells of type $not.\n",
      "Using extmapper simplemap for cells of type $logic_not.\n",
      "No more expansions possible.\n",
      "<suppressed ~287 debug messages>\n",
      "\n",
      "2.22. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.22.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "<suppressed ~1720 debug messages>\n",
      "\n",
      "2.22.2. Executing OPT_MERGE pass (detect identical cells).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finding identical cells in module `\\lut_verilog'.\n",
      "<suppressed ~6360 debug messages>\n",
      "Removed a total of 2120 cells.\n",
      "\n",
      "2.22.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.22.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "Removed 0 unused cells and 1695 unused wires.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.22.5. Finished fast OPT passes.\n",
      "\n",
      "2.23. Executing ABC pass (technology mapping using ABC).\n",
      "\n",
      "2.23.1. Extracting gate netlist of module `\\lut_verilog' to `<abc-temp-dir>/input.blif'..\n",
      "Extracted 704 gates and 712 wires to a netlist network with 8 inputs and 1 outputs.\n",
      "\n",
      "2.23.1.1. Executing ABC.\n",
      "Running ABC command: <yosys-exe-dir>/yosys-abc -s -f <abc-temp-dir>/abc.script 2>&1\n",
      "ABC: ABC command line: \"source <abc-temp-dir>/abc.script\".\n",
      "ABC: \n",
      "ABC: + read_blif <abc-temp-dir>/input.blif \n",
      "ABC: + read_library <abc-temp-dir>/stdcells.genlib \n",
      "ABC: Entered genlib library with 13 gates from file \"<abc-temp-dir>/stdcells.genlib\".\n",
      "ABC: + strash \n",
      "ABC: + dretime \n",
      "ABC: + map \n",
      "ABC: + write_blif <abc-temp-dir>/output.blif \n",
      "\n",
      "2.23.1.2. Re-integrating ABC results.\n",
      "ABC RESULTS:               AND cells:        9\n",
      "ABC RESULTS:            ANDNOT cells:      219\n",
      "ABC RESULTS:              NAND cells:        4\n",
      "ABC RESULTS:               NOR cells:       13\n",
      "ABC RESULTS:                OR cells:      226\n",
      "ABC RESULTS:             ORNOT cells:        8\n",
      "ABC RESULTS:        internal signals:      703\n",
      "ABC RESULTS:           input signals:        8\n",
      "ABC RESULTS:          output signals:        1\n",
      "Removing temp directory.\n",
      "\n",
      "2.24. Executing OPT pass (performing simple optimizations).\n",
      "\n",
      "2.24.1. Executing OPT_EXPR pass (perform const folding).\n",
      "Optimizing module lut_verilog.\n",
      "\n",
      "2.24.2. Executing OPT_MERGE pass (detect identical cells).\n",
      "Finding identical cells in module `\\lut_verilog'.\n",
      "Removed a total of 0 cells.\n",
      "\n",
      "2.24.3. Executing OPT_DFF pass (perform DFF optimizations).\n",
      "\n",
      "2.24.4. Executing OPT_CLEAN pass (remove unused cells and wires).\n",
      "Finding unused cells or wires in module \\lut_verilog..\n",
      "Removed 0 unused cells and 497 unused wires.\n",
      "<suppressed ~1 debug messages>\n",
      "\n",
      "2.24.5. Finished fast OPT passes.\n",
      "\n",
      "2.25. Executing HIERARCHY pass (managing design hierarchy).\n",
      "\n",
      "2.25.1. Analyzing design hierarchy..\n",
      "Top module:  \\lut_verilog\n",
      "\n",
      "2.25.2. Analyzing design hierarchy..\n",
      "Top module:  \\lut_verilog\n",
      "Removed 0 unused modules.\n",
      "\n",
      "2.26. Printing statistics.\n",
      "\n",
      "=== lut_verilog ===\n",
      "\n",
      "   Number of wires:                480\n",
      "   Number of wire bits:            487\n",
      "   Number of public wires:           2\n",
      "   Number of public wire bits:       9\n",
      "   Number of memories:               0\n",
      "   Number of memory bits:            0\n",
      "   Number of processes:              0\n",
      "   Number of cells:                479\n",
      "     $_ANDNOT_                     219\n",
      "     $_AND_                          9\n",
      "     $_NAND_                         4\n",
      "     $_NOR_                         13\n",
      "     $_ORNOT_                        8\n",
      "     $_OR_                         226\n",
      "\n",
      "2.27. Executing CHECK pass (checking for obvious problems).\n",
      "Checking module lut_verilog...\n",
      "Found and reported 0 problems.\n",
      "\n",
      "3. Executing AIGMAP pass (map logic to AIG).\n",
      "Module lut_verilog: replaced 470 cells with 1413 new cells, skipped 9 cells.\n",
      "  replaced 5 cell types:\n",
      "       4 $_NAND_\n",
      "     226 $_OR_\n",
      "      13 $_NOR_\n",
      "     219 $_ANDNOT_\n",
      "       8 $_ORNOT_\n",
      "  not replaced 1 cell types:\n",
      "       9 $_AND_\n",
      "\n",
      "4. Executing AIGER backend.\n",
      "\n",
      "End of script. Logfile hash: 89d6adada9, CPU: user 0.27s system 0.00s, MEM: 21.84 MB peak\n",
      "Yosys 0.12+36 (git sha1 7608985d2, clang 10.0.0-4ubuntu1 -fPIC -Os)\n",
      "Time spent: 29% 14x opt_expr (0 sec), 14% 1x abc (0 sec), ...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd = \"yosys neuron_to_aig_size.ys\"\n",
    "os.system(cmd)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc4db8d",
   "metadata": {},
   "source": [
    "get size of aig from lut_verilog.aig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "7c50d3be",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open(\"lut_verilog.aig\", \"r\")\n",
    "line = f.readline()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "68000803",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_and_gates = line.split(' ')[5].split('\\n')[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "4eda6978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'479'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_and_gates"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cc73fb5",
   "metadata": {},
   "source": [
    "### NN -> Size of AIG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "adad1fff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('linear1.bias', Parameter containing:\n",
      "tensor([ 0.0115, -0.0297, -0.0472,  0.1345,  0.0106, -0.0527,  0.0350, -0.0378,\n",
      "         0.0463,  0.1565], requires_grad=True)), ('linear1.weight', Parameter containing:\n",
      "tensor([[0., -0., 0.,  ..., -0., -0., -0.],\n",
      "        [-0., 0., 0.,  ..., -0., 0., -0.],\n",
      "        [-0., -0., 0.,  ..., -0., -0., 0.],\n",
      "        ...,\n",
      "        [-0., -0., -0.,  ..., -0., 0., 0.],\n",
      "        [0., -0., -0.,  ..., -0., 0., 0.],\n",
      "        [0., -0., 0.,  ..., 0., -0., 0.]], requires_grad=True)), ('linear2.bias', Parameter containing:\n",
      "tensor([-0.0186], requires_grad=True)), ('linear2.weight', Parameter containing:\n",
      "tensor([[-1.3229, -0.6032, -0.0000,  0.7034,  0.8241, -0.0000, -0.3962, -0.8190,\n",
      "          0.4833,  0.8182]], requires_grad=True))]\n"
     ]
    }
   ],
   "source": [
    "# model after pruning\n",
    "print(list(net.named_parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "87bfc9e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get list of neurons in NN\n",
    "\n",
    "neurons = [] # each element is a neuron with a weight vector and a bias scalar\n",
    "weights = [] # each element is the weight matrix of a layer\n",
    "biases  = [] # each element contains biases for that layer\n",
    "for name, param in net.named_parameters():\n",
    "    if '.weight'in name:\n",
    "        weights.append( param.detach().numpy() )\n",
    "    if '.bias' in name:\n",
    "        biases.append( param.detach().numpy() )\n",
    "        \n",
    "for i,layer_weights in enumerate(weights): # i = layer\n",
    "    for j,weight_vector in enumerate(layer_weights): # j = neuron in layer i\n",
    "        neurons.append((weight_vector,biases[i][j]))\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "bc28746f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11\n",
      "size:  4407\n",
      "running sum:  4407\n",
      "9\n",
      "size:  1242\n",
      "running sum:  5649\n",
      "4\n",
      "size:  0\n",
      "running sum:  5649\n",
      "6\n",
      "size:  149\n",
      "running sum:  5798\n",
      "9\n",
      "size:  994\n",
      "running sum:  6792\n",
      "0\n",
      "size:  994\n",
      "running sum:  7786\n",
      "5\n",
      "size:  50\n",
      "running sum:  7836\n",
      "9\n",
      "size:  1250\n",
      "running sum:  9086\n",
      "8\n",
      "size:  513\n",
      "running sum:  9599\n",
      "8\n",
      "size:  487\n",
      "running sum:  10086\n",
      "8\n",
      "size:  332\n",
      "running sum:  10418\n"
     ]
    }
   ],
   "source": [
    "size_aig = 0\n",
    "\n",
    "for neuron in neurons: \n",
    "    \n",
    "    '''form LUT for each neuron'''\n",
    "    w = neuron[0]\n",
    "    b = neuron[1]\n",
    "    w = w[w.nonzero()]\n",
    "    input_size = len(w)\n",
    "    \n",
    "    # get the LUT\n",
    "    lut_y = get_lut_y(input_size, w, b)\n",
    "    \n",
    "    \n",
    "    '''create text for verilog file representing LUT'''\n",
    "    n=input_size\n",
    "    print(input_size)\n",
    "\n",
    "    file_string ='module lut_verilog(\\ninput wire['+str(input_size-1)+':0] in,\\noutput reg out\\n);\\n\\nalways@(in) begin\\ncase(in)\\n'\n",
    "\n",
    "    input_vector = np.zeros( (input_size) )\n",
    "    for idx in range ( pow(2,input_size) ):\n",
    "        # add to file string\n",
    "        file_string += str(input_size)+'\\'b'+''.join(str(int(e)) for e in input_vector)+' : out = '+str(int(lut_y[idx]))+';\\n'\n",
    "        # increment input vector\n",
    "        for i in range(len(input_vector)-1, -1, -1):\n",
    "            if input_vector[i] == 0:\n",
    "                input_vector[i] = 1\n",
    "                break\n",
    "            input_vector[i] = 0\n",
    "\n",
    "    file_string+='endcase\\nend\\nendmodule\\n'\n",
    "    \n",
    "    \n",
    "    '''write to verilog file'''\n",
    "    f = open(\"lut_verilog.v\", \"w\")\n",
    "    f.write(file_string)\n",
    "    f.close()\n",
    "    \n",
    "    \n",
    "    '''produce the .aig file using yosys script'''\n",
    "    cmd = \"yosys neuron_to_aig_size.ys >/dev/null 2>&1\"\n",
    "    os.system(cmd)\n",
    "    \n",
    "    \n",
    "    '''get the number of and gates in aig and add to the running sum'''\n",
    "    f = open(\"lut_verilog.aig\", \"r\")\n",
    "    line = f.readline()\n",
    "    size_aig = size_aig + int(line.split(' ')[5].split('\\n')[0])\n",
    "    print(\"size: \", line.split(' ')[5].split('\\n')[0] )\n",
    "    print(\"running sum: \",size_aig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c58715f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = [('ex00', 32, 0.5079687237739563, 424), ('ex01', 32, 0.937498927116394, 807), ('ex02', 64, 0.5070310831069946, 213), ('ex03', 64, 0.7887492775917053, 932), ('ex04', 128, 0.5089061260223389, 173), ('ex05', 128, 0.8073423504829407, 1288), ('ex06', 256, 0.4951561987400055, 592), ('ex07', 256, 0.6717190146446228, 2201), ('ex08', 512, 0.5, 2503), ('ex09', 512, 0.5049999952316284, 3809), ('ex10', 32, 0.6587504744529724, 1317), ('ex11', 64, 0.6632817983627319, 1430), ('ex12', 128, 0.6528134942054749, 983), ('ex13', 256, 0.6445316076278687, 1476), ('ex14', 512, 0.6585946679115295, 5021), ('ex15', 32, 0.4946872591972351, 892), ('ex16', 64, 0.7410939335823059, 1998), ('ex17', 128, 0.49406275153160095, 2098), ('ex18', 256, 0.4899999499320984, 1954), ('ex19', 512, 0.49734362959861755, 3527), ('ex20', 16, 0.4968748092651367, 313), ('ex21', 16, 0.5075001120567322, 186), ('ex22', 32, 0.5014060735702515, 33), ('ex23', 32, 0.5015626549720764, 134), ('ex24', 64, 0.503437340259552, 144), ('ex25', 64, 0.5010939836502075, 157), ('ex26', 128, 0.4996875822544098, 149), ('ex27', 128, 0.5101560354232788, 198), ('ex28', 256, 0.5046876072883606, 678), ('ex29', 256, 0.5078125, 662), ('ex30', 20, 0.9414055943489075, 419), ('ex31', 40, 0.9531248211860657, 1314), ('ex32', 60, 0.7974989414215088, 872), ('ex33', 80, 0.7918737530708313, 1333), ('ex34', 100, 0.504843533039093, 1376), ('ex35', 120, 0.5017188787460327, 876), ('ex36', 140, 0.7356252074241638, 1302), ('ex37', 160, 0.8126554489135742, 1095), ('ex38', 180, 0.645469069480896, 1245), ('ex39', 200, 0.6748441457748413, 1720), ('ex40', 16, 0.5021877884864807, 66), ('ex41', 10, 0.5821877717971802, 85), ('ex42', 32, 0.5007809400558472, 174), ('ex43', 18, 0.5023436546325684, 226), ('ex44', 64, 0.4989061951637268, 242), ('ex45', 34, 0.4895310401916504, 148), ('ex46', 128, 0.505937397480011, 72), ('ex47', 66, 0.5007813572883606, 287), ('ex48', 256, 0.4834372103214264, 886), ('ex49', 130, 0.4957813620567322, 391), ('ex50', 19, 0.5525004863739014, 152), ('ex51', 44, 0.5146876573562622, 418), ('ex52', 59, 0.5998443961143494, 452), ('ex53', 45, 0.7521870136260986, 434), ('ex54', 48, 0.7574991583824158, 632), ('ex55', 42, 0.5773441791534424, 436), ('ex56', 83, 0.910936713218689, 1289), ('ex57', 24, 0.18484333157539368, 202), ('ex58', 80, 0.7604680061340332, 728), ('ex59', 394, 0.5225000977516174, 2377), ('ex60', 43, 0.680469274520874, 950), ('ex61', 37, 0.7514058351516724, 586), ('ex62', 52, 0.851248562335968, 1096), ('ex63', 38, 0.8873423337936401, 684), ('ex64', 47, 0.8873424530029297, 491), ('ex65', 19, 0.7584373950958252, 435), ('ex66', 47, 0.7898426651954651, 731), ('ex67', 46, 0.7809368371963501, 797), ('ex68', 33, 0.8792176246643066, 647), ('ex69', 16, 0.9460933804512024, 371), ('ex70', 23, 0.8728114366531372, 375), ('ex71', 23, 0.8998425602912903, 598), ('ex72', 35, 0.24999991059303284, 513), ('ex73', 16, 0.6410942673683167, 207), ('ex74', 16, 0.5117186903953552, 45), ('ex75', 16, 0.3946872353553772, 71), ('ex76', 16, 0.7931239604949951, 149), ('ex77', 16, 0.793123722076416, 134), ('ex78', 16, 0.6417196989059448, 44), ('ex79', 16, 0.7931238412857056, 139), ('ex80', 196, 0.4875001013278961, 1876), ('ex81', 196, 0.4912498891353607, 1417), ('ex82', 196, 0.47921842336654663, 1409), ('ex83', 196, 0.513593852519989, 1165), ('ex84', 196, 0.47562485933303833, 2064), ('ex85', 196, 0.49359384179115295, 1777), ('ex86', 196, 0.524374783039093, 1825), ('ex87', 196, 0.4987502098083496, 1135), ('ex88', 196, 0.4817185401916504, 1907), ('ex89', 196, 0.4884374141693115, 1726), ('ex90', 768, 0.5035936236381531, 6977), ('ex91', 768, 0.5189059972763062, 6811), ('ex92', 768, 0.5034374594688416, 11745), ('ex93', 768, 0.5064063668251038, 8845), ('ex94', 768, 0.5104693174362183, 7061), ('ex95', 768, 0.49312496185302734, 8751), ('ex96', 768, 0.5021876692771912, 10091), ('ex97', 768, 0.506250262260437, 9984), ('ex98', 768, 0.4985935688018799, 8717), ('ex99', 768, 0.5035935640335083, 8203)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "261a8cbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "overall accuracy across 100 benchmarks=  60.59670150279999  %\n",
      "11 networks exceeded size constraint:\n",
      "['ex14' 'ex90' 'ex91' 'ex92' 'ex93' 'ex94' 'ex95' 'ex96' 'ex97' 'ex98'\n",
      " 'ex99']\n",
      "overall accuracy across benchmarks under size constraints=  61.67589218428965  %\n"
     ]
    }
   ],
   "source": [
    "# Analysis\n",
    "ids = np.asarray([res[0] for res in results])\n",
    "input_sizes = np.asarray([res[1] for res in results])\n",
    "acc = np.asarray([res[2] for res in results])\n",
    "aig_sizes = np.asarray([res[3] for res in results])\n",
    "\n",
    "avg_accuracy = np.sum(acc)/len(acc)\n",
    "print(\"overall accuracy across 100 benchmarks= \", avg_accuracy*100, \" %\")\n",
    "\n",
    "size_exceeded = np.where( aig_sizes>5000 )[0]\n",
    "size_satisfied = np.where( aig_sizes<=5000 )[0]\n",
    "\n",
    "print(str(len(size_exceeded)), \"networks exceeded size constraint:\" )\n",
    "print( ids[size_exceeded] )\n",
    "\n",
    "avg_accuracy_pass = np.sum(acc[size_satisfied])/len(acc[size_satisfied])\n",
    "print(\"overall accuracy across benchmarks under size constraints= \", avg_accuracy_pass*100, \" %\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8081b2f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.lines.Line2D at 0x7fd74a72ed90>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(aig_sizes, '.')\n",
    "plt.ylabel('Number of AND gates in AIG')\n",
    "plt.xlabel('Benchmark ID')\n",
    "plt.axhline(y=5000, color='r', linestyle='-')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "df1ef57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Varying circuit constraint analysis\n",
    "\n",
    "results_1a = [('ex00', 32, 0.5146874785423279, 746), ('ex01', 32, 0.933906078338623, 833), ('ex02', 64, 0.5320314168930054, 1834), ('ex03', 64, 0.899686336517334, 1811), ('ex04', 128, 0.5065627694129944, 4196), ('ex05', 128, 0.9406243562698364, 1480), ('ex06', 256, 0.5460940599441528, 17706), ('ex07', 256, 0.968593418598175, 3359), ('ex08', 512, 0.5090627074241638, 180419), ('ex09', 512, 0.9509369134902954, 44771), ('ex10', 32, 0.798279881477356, 1339), ('ex11', 64, 0.7360932230949402, 1464), ('ex12', 128, 0.6610943675041199, 2468), ('ex13', 256, 0.645156741142273, 3501), ('ex14', 512, 0.6582816243171692, 28840), ('ex15', 32, 0.8281232714653015, 1379), ('ex16', 64, 0.8364049792289734, 3465), ('ex17', 128, 0.7753114104270935, 3559), ('ex18', 256, 0.6401569843292236, 7443), ('ex19', 512, 0.8251544237136841, 29426), ('ex20', 16, 0.5125001668930054, 468), ('ex21', 16, 0.5309373140335083, 560), ('ex22', 32, 0.49859386682510376, 479), ('ex23', 32, 0.5295314788818359, 510), ('ex24', 64, 0.5250004529953003, 1075), ('ex25', 64, 0.5065627098083496, 866), ('ex26', 128, 0.53578120470047, 3512), ('ex27', 128, 0.4903126657009125, 4252), ('ex28', 256, 0.5429688692092896, 15794), ('ex29', 256, 0.5259374976158142, 13754), ('ex30', 20, 0.9374991655349731, 683), ('ex31', 40, 0.9679688215255737, 1385), ('ex32', 60, 0.9346866607666016, 805), ('ex33', 80, 0.9857813715934753, 2434), ('ex34', 100, 0.9687497019767761, 2041), ('ex35', 120, 0.970624566078186, 1770), ('ex36', 140, 0.9823437929153442, 2002), ('ex37', 160, 0.9701560735702515, 3013), ('ex38', 180, 0.9435935020446777, 2881), ('ex39', 200, 0.9718747138977051, 2237), ('ex40', 16, 0.5432815551757812, 380), ('ex41', 10, 0.6075006127357483, 754), ('ex42', 32, 0.528906524181366, 787), ('ex43', 18, 0.5210939645767212, 639), ('ex44', 64, 0.5295316576957703, 1524), ('ex45', 34, 0.5214067697525024, 791), ('ex46', 128, 0.5337501764297485, 2131), ('ex47', 66, 0.513750433921814, 856), ('ex48', 256, 0.528906524181366, 12667), ('ex49', 130, 0.5198441743850708, 2071), ('ex50', 19, 0.7932802438735962, 988), ('ex51', 44, 0.5106251239776611, 2100), ('ex52', 59, 0.595625638961792, 1484), ('ex53', 45, 0.7521874904632568, 1219), ('ex54', 48, 0.7521868944168091, 1148), ('ex55', 42, 0.8315609693527222, 504), ('ex56', 83, 0.6192189455032349, 2029), ('ex57', 24, 0.9676566123962402, 429), ('ex58', 80, 0.8768739700317383, 1542), ('ex59', 394, 0.6692193150520325, 12793), ('ex60', 43, 0.7682810425758362, 1816), ('ex61', 37, 0.7579684853553772, 989), ('ex62', 52, 0.8782796859741211, 1574), ('ex63', 38, 0.8879672288894653, 1135), ('ex64', 47, 0.9506245851516724, 1054), ('ex65', 19, 0.7746871709823608, 1245), ('ex66', 47, 0.7760927677154541, 1247), ('ex67', 46, 0.7404682636260986, 1206), ('ex68', 33, 0.9443745613098145, 1058), ('ex69', 16, 0.9343745112419128, 524), ('ex70', 23, 0.9335931539535522, 872), ('ex71', 23, 0.9189052581787109, 717), ('ex72', 35, 0.8815611600875854, 625), ('ex73', 16, 0.6075009107589722, 1103), ('ex74', 16, 0.5117185711860657, 376), ('ex75', 16, 0.3946872651576996, 263), ('ex76', 16, 0.793123722076416, 1013), ('ex77', 16, 0.7931236028671265, 853), ('ex78', 16, 0.6417192816734314, 479), ('ex79', 16, 0.7931238412857056, 981), ('ex80', 196, 0.5768752098083496, 3315), ('ex81', 196, 0.7396873235702515, 4352), ('ex82', 196, 0.8343733549118042, 6597), ('ex83', 196, 0.8339049220085144, 4939), ('ex84', 196, 0.7879678010940552, 13012), ('ex85', 196, 0.5296874046325684, 7323), ('ex86', 196, 0.5348438024520874, 8226), ('ex87', 196, 0.7910926938056946, 3942), ('ex88', 196, 0.8290611505508423, 12914), ('ex89', 196, 0.7828117609024048, 10836), ('ex90', 768, 0.5201565027236938, 375187), ('ex91', 768, 0.5110938549041748, 476028), ('ex92', 768, 0.5476566553115845, 474636), ('ex93', 768, 0.5317188501358032, 661743), ('ex94', 768, 0.553750216960907, 1017241), ('ex95', 768, 0.5987504720687866, 550106), ('ex96', 768, 0.5248436331748962, 148062), ('ex97', 768, 0.5040621757507324, 458732), ('ex98', 768, 0.4987497329711914, 396343), ('ex99', 768, 0.5329688787460327, 209708)]\n",
    "results_1b = [('ex00', 32, 0.5176563262939453, 1436), ('ex01', 32, 0.906092643737793, 2233), ('ex02', 64, 0.49734368920326233, 1729), ('ex03', 64, 0.9032794833183289, 2190), ('ex04', 128, 0.5153126120567322, 3132), ('ex05', 128, 0.9685938954353333, 3181), ('ex06', 256, 0.5140624642372131, 7023), ('ex07', 256, 0.9103110432624817, 4307), ('ex08', 512, 0.5026563405990601, 18413), ('ex09', 512, 0.9607809782028198, 15313), ('ex10', 32, 0.7643742561340332, 2987), ('ex11', 64, 0.7874990105628967, 2492), ('ex12', 128, 0.6890629529953003, 3192), ('ex13', 256, 0.7262504696846008, 6595), ('ex14', 512, 0.6890632510185242, 15443), ('ex15', 32, 0.8315606117248535, 2357), ('ex16', 64, 0.8367172479629517, 2627), ('ex17', 128, 0.8249982595443726, 6156), ('ex18', 256, 0.8279672861099243, 7669), ('ex19', 512, 0.8249987363815308, 30895), ('ex20', 16, 0.5104687213897705, 1444), ('ex21', 16, 0.5153126120567322, 1796), ('ex22', 32, 0.5107811689376831, 1745), ('ex23', 32, 0.5160935521125793, 1814), ('ex24', 64, 0.5287504196166992, 1614), ('ex25', 64, 0.5607814788818359, 1506), ('ex26', 128, 0.5315622091293335, 4107), ('ex27', 128, 0.5164063572883606, 3818), ('ex28', 256, 0.4984373152256012, 6032), ('ex29', 256, 0.5592191815376282, 7781), ('ex30', 20, 0.9745312929153442, 2367), ('ex31', 40, 0.9668750762939453, 2055), ('ex32', 60, 0.967343807220459, 2193), ('ex33', 80, 0.9857816696166992, 4330), ('ex34', 100, 0.9682814478874207, 2788), ('ex35', 120, 0.986875057220459, 4262), ('ex36', 140, 0.9595307111740112, 3801), ('ex37', 160, 0.9701560735702515, 3205), ('ex38', 180, 0.971093475818634, 3673), ('ex39', 200, 0.9843748807907104, 4772), ('ex40', 16, 0.5606257319450378, 1432), ('ex41', 10, 0.6029692888259888, 1525), ('ex42', 32, 0.5254688858985901, 1706), ('ex43', 18, 0.515468955039978, 1575), ('ex44', 64, 0.5262499451637268, 2118), ('ex45', 34, 0.5114063024520874, 1551), ('ex46', 128, 0.5235936045646667, 4001), ('ex47', 66, 0.5057810544967651, 1952), ('ex48', 256, 0.5314064621925354, 8287), ('ex49', 130, 0.49874988198280334, 3647), ('ex50', 19, 0.774061918258667, 1949), ('ex51', 44, 0.5234374403953552, 1861), ('ex52', 59, 0.5946879386901855, 2416), ('ex53', 45, 0.6820316910743713, 2872), ('ex54', 48, 0.7740619778633118, 1823), ('ex55', 42, 0.9345302581787109, 1705), ('ex56', 83, 0.5882819294929504, 7258), ('ex57', 24, 0.9623438715934753, 1649), ('ex58', 80, 0.8699983358383179, 3679), ('ex59', 394, 0.6223443746566772, 16849), ('ex60', 43, 0.6579695343971252, 1559), ('ex61', 37, 0.8281232118606567, 2068), ('ex62', 52, 0.873123288154602, 2562), ('ex63', 38, 0.9014051556587219, 1683), ('ex64', 47, 0.9812501668930054, 1949), ('ex65', 19, 0.8723416328430176, 3018), ('ex66', 47, 0.7870307564735413, 2206), ('ex67', 46, 0.7287492156028748, 2225), ('ex68', 33, 0.916405200958252, 2598), ('ex69', 16, 0.9017173647880554, 1594), ('ex70', 23, 0.9317178726196289, 2769), ('ex71', 23, 0.8860921859741211, 1987), ('ex72', 35, 0.8799988031387329, 1887), ('ex73', 16, 0.6187508702278137, 2578), ('ex74', 16, 0.5173437595367432, 1529), ('ex75', 16, 0.3946871757507324, 678), ('ex76', 16, 0.7931240200996399, 1465), ('ex77', 16, 0.7931236624717712, 1843), ('ex78', 16, 0.6417193412780762, 1835), ('ex79', 16, 0.8024986386299133, 1649), ('ex80', 196, 0.5635939836502075, 5242), ('ex81', 196, 0.7490622997283936, 5066), ('ex82', 196, 0.7940613031387329, 4102), ('ex83', 196, 0.7487496137619019, 4793), ('ex84', 196, 0.7779676914215088, 7035), ('ex85', 196, 0.7926556468009949, 7079), ('ex86', 196, 0.6098448038101196, 5190), ('ex87', 196, 0.7570306658744812, 4454), ('ex88', 196, 0.813904881477356, 6018), ('ex89', 196, 0.7662494778633118, 5782), ('ex90', 768, 0.5042189955711365, 70012)]\n",
    "results_2a = [('ex00', 32, 0.5079687237739563, 424), ('ex01', 32, 0.937498927116394, 807), ('ex02', 64, 0.5070310831069946, 213), ('ex03', 64, 0.7887492775917053, 932), ('ex04', 128, 0.5089061260223389, 173), ('ex05', 128, 0.8073423504829407, 1288), ('ex06', 256, 0.4951561987400055, 592), ('ex07', 256, 0.6717190146446228, 2201), ('ex08', 512, 0.5, 2503), ('ex09', 512, 0.5049999952316284, 3809), ('ex10', 32, 0.6587504744529724, 1317), ('ex11', 64, 0.6632817983627319, 1430), ('ex12', 128, 0.6528134942054749, 983), ('ex13', 256, 0.6445316076278687, 1476), ('ex14', 512, 0.6585946679115295, 5021), ('ex15', 32, 0.4946872591972351, 892), ('ex16', 64, 0.7410939335823059, 1998), ('ex17', 128, 0.49406275153160095, 2098), ('ex18', 256, 0.4899999499320984, 1954), ('ex19', 512, 0.49734362959861755, 3527), ('ex20', 16, 0.4968748092651367, 313), ('ex21', 16, 0.5075001120567322, 186), ('ex22', 32, 0.5014060735702515, 33), ('ex23', 32, 0.5015626549720764, 134), ('ex24', 64, 0.503437340259552, 144), ('ex25', 64, 0.5010939836502075, 157), ('ex26', 128, 0.4996875822544098, 149), ('ex27', 128, 0.5101560354232788, 198), ('ex28', 256, 0.5046876072883606, 678), ('ex29', 256, 0.5078125, 662), ('ex30', 20, 0.9414055943489075, 419), ('ex31', 40, 0.9531248211860657, 1314), ('ex32', 60, 0.7974989414215088, 872), ('ex33', 80, 0.7918737530708313, 1333), ('ex34', 100, 0.504843533039093, 1376), ('ex35', 120, 0.5017188787460327, 876), ('ex36', 140, 0.7356252074241638, 1302), ('ex37', 160, 0.8126554489135742, 1095), ('ex38', 180, 0.645469069480896, 1245), ('ex39', 200, 0.6748441457748413, 1720), ('ex40', 16, 0.5021877884864807, 66), ('ex41', 10, 0.5821877717971802, 85), ('ex42', 32, 0.5007809400558472, 174), ('ex43', 18, 0.5023436546325684, 226), ('ex44', 64, 0.4989061951637268, 242), ('ex45', 34, 0.4895310401916504, 148), ('ex46', 128, 0.505937397480011, 72), ('ex47', 66, 0.5007813572883606, 287), ('ex48', 256, 0.4834372103214264, 886), ('ex49', 130, 0.4957813620567322, 391), ('ex50', 19, 0.5525004863739014, 152), ('ex51', 44, 0.5146876573562622, 418), ('ex52', 59, 0.5998443961143494, 452), ('ex53', 45, 0.7521870136260986, 434), ('ex54', 48, 0.7574991583824158, 632), ('ex55', 42, 0.5773441791534424, 436), ('ex56', 83, 0.910936713218689, 1289), ('ex57', 24, 0.18484333157539368, 202), ('ex58', 80, 0.7604680061340332, 728), ('ex59', 394, 0.5225000977516174, 2377), ('ex60', 43, 0.680469274520874, 950), ('ex61', 37, 0.7514058351516724, 586), ('ex62', 52, 0.851248562335968, 1096), ('ex63', 38, 0.8873423337936401, 684), ('ex64', 47, 0.8873424530029297, 491), ('ex65', 19, 0.7584373950958252, 435), ('ex66', 47, 0.7898426651954651, 731), ('ex67', 46, 0.7809368371963501, 797), ('ex68', 33, 0.8792176246643066, 647), ('ex69', 16, 0.9460933804512024, 371), ('ex70', 23, 0.8728114366531372, 375), ('ex71', 23, 0.8998425602912903, 598), ('ex72', 35, 0.24999991059303284, 513), ('ex73', 16, 0.6410942673683167, 207), ('ex74', 16, 0.5117186903953552, 45), ('ex75', 16, 0.3946872353553772, 71), ('ex76', 16, 0.7931239604949951, 149), ('ex77', 16, 0.793123722076416, 134), ('ex78', 16, 0.6417196989059448, 44), ('ex79', 16, 0.7931238412857056, 139), ('ex80', 196, 0.4875001013278961, 1876), ('ex81', 196, 0.4912498891353607, 1417), ('ex82', 196, 0.47921842336654663, 1409), ('ex83', 196, 0.513593852519989, 1165), ('ex84', 196, 0.47562485933303833, 2064), ('ex85', 196, 0.49359384179115295, 1777), ('ex86', 196, 0.524374783039093, 1825), ('ex87', 196, 0.4987502098083496, 1135), ('ex88', 196, 0.4817185401916504, 1907), ('ex89', 196, 0.4884374141693115, 1726), ('ex90', 768, 0.5035936236381531, 6977), ('ex91', 768, 0.5189059972763062, 6811), ('ex92', 768, 0.5034374594688416, 11745), ('ex93', 768, 0.5064063668251038, 8845), ('ex94', 768, 0.5104693174362183, 7061), ('ex95', 768, 0.49312496185302734, 8751), ('ex96', 768, 0.5021876692771912, 10091), ('ex97', 768, 0.506250262260437, 9984), ('ex98', 768, 0.4985935688018799, 8717), ('ex99', 768, 0.5035935640335083, 8203)]\n",
    "results_2b = [('ex00', 32, 0.5176563262939453, 1436), ('ex01', 32, 0.906092643737793, 2233), ('ex02', 64, 0.49734368920326233, 1729), ('ex03', 64, 0.9032794833183289, 2190), ('ex04', 128, 0.5153126120567322, 3132), ('ex05', 128, 0.9685938954353333, 3181), ('ex06', 256, 0.5140624642372131, 7023), ('ex07', 256, 0.9103110432624817, 4307), ('ex08', 512, 0.5026563405990601, 18413), ('ex09', 512, 0.9607809782028198, 15313), ('ex10', 32, 0.7643742561340332, 2987), ('ex11', 64, 0.7874990105628967, 2492), ('ex12', 128, 0.6890629529953003, 3192), ('ex13', 256, 0.7262504696846008, 6595), ('ex14', 512, 0.6890632510185242, 15443), ('ex15', 32, 0.8315606117248535, 2357), ('ex16', 64, 0.8367172479629517, 2627), ('ex17', 128, 0.8249982595443726, 6156), ('ex18', 256, 0.8279672861099243, 7669), ('ex19', 512, 0.8249987363815308, 30895), ('ex20', 16, 0.5104687213897705, 1444), ('ex21', 16, 0.5153126120567322, 1796), ('ex22', 32, 0.5107811689376831, 1745), ('ex23', 32, 0.5160935521125793, 1814), ('ex24', 64, 0.5287504196166992, 1614), ('ex25', 64, 0.5607814788818359, 1506), ('ex26', 128, 0.5315622091293335, 4107), ('ex27', 128, 0.5164063572883606, 3818), ('ex28', 256, 0.4984373152256012, 6032), ('ex29', 256, 0.5592191815376282, 7781), ('ex30', 20, 0.9745312929153442, 2367), ('ex31', 40, 0.9668750762939453, 2055), ('ex32', 60, 0.967343807220459, 2193), ('ex33', 80, 0.9857816696166992, 4330), ('ex34', 100, 0.9682814478874207, 2788), ('ex35', 120, 0.986875057220459, 4262), ('ex36', 140, 0.9595307111740112, 3801), ('ex37', 160, 0.9701560735702515, 3205), ('ex38', 180, 0.971093475818634, 3673), ('ex39', 200, 0.9843748807907104, 4772), ('ex40', 16, 0.5606257319450378, 1432), ('ex41', 10, 0.6029692888259888, 1525), ('ex42', 32, 0.5254688858985901, 1706), ('ex43', 18, 0.515468955039978, 1575), ('ex44', 64, 0.5262499451637268, 2118), ('ex45', 34, 0.5114063024520874, 1551), ('ex46', 128, 0.5235936045646667, 4001), ('ex47', 66, 0.5057810544967651, 1952), ('ex48', 256, 0.5314064621925354, 8287), ('ex49', 130, 0.49874988198280334, 3647), ('ex50', 19, 0.774061918258667, 1949), ('ex51', 44, 0.5234374403953552, 1861), ('ex52', 59, 0.5946879386901855, 2416), ('ex53', 45, 0.6820316910743713, 2872), ('ex54', 48, 0.7740619778633118, 1823), ('ex55', 42, 0.9345302581787109, 1705), ('ex56', 83, 0.5882819294929504, 7258), ('ex57', 24, 0.9623438715934753, 1649), ('ex58', 80, 0.8699983358383179, 3679), ('ex59', 394, 0.6223443746566772, 16849), ('ex60', 43, 0.6579695343971252, 1559), ('ex61', 37, 0.8281232118606567, 2068), ('ex62', 52, 0.873123288154602, 2562), ('ex63', 38, 0.9014051556587219, 1683), ('ex64', 47, 0.9812501668930054, 1949), ('ex65', 19, 0.8723416328430176, 3018), ('ex66', 47, 0.7870307564735413, 2206), ('ex67', 46, 0.7287492156028748, 2225), ('ex68', 33, 0.916405200958252, 2598), ('ex69', 16, 0.9017173647880554, 1594), ('ex70', 23, 0.9317178726196289, 2769), ('ex71', 23, 0.8860921859741211, 1987), ('ex72', 35, 0.8799988031387329, 1887), ('ex73', 16, 0.6187508702278137, 2578), ('ex74', 16, 0.5173437595367432, 1529), ('ex75', 16, 0.3946871757507324, 678), ('ex76', 16, 0.7931240200996399, 1465), ('ex77', 16, 0.7931236624717712, 1843), ('ex78', 16, 0.6417193412780762, 1835), ('ex79', 16, 0.8024986386299133, 1649), ('ex80', 196, 0.5635939836502075, 5242), ('ex81', 196, 0.7490622997283936, 5066), ('ex82', 196, 0.7940613031387329, 4102), ('ex83', 196, 0.7487496137619019, 4793), ('ex84', 196, 0.7779676914215088, 7035), ('ex85', 196, 0.7926556468009949, 7079), ('ex86', 196, 0.6098448038101196, 5190), ('ex87', 196, 0.7570306658744812, 4454), ('ex88', 196, 0.813904881477356, 6018), ('ex89', 196, 0.7662494778633118, 5782), ('ex90', 768, 0.5042189955711365, 70012)]\n",
    "results_3 = [('ex00', 32, 0.9146865606307983, 2808), ('ex01', 32, 0.9359360933303833, 2075), ('ex02', 64, 0.4996872544288635, 2032), ('ex03', 64, 0.9401556253433228, 2112), ('ex04', 128, 0.5045312643051147, 2222), ('ex05', 128, 0.9626563191413879, 4183), ('ex06', 256, 0.5057811737060547, 3566), ('ex07', 256, 0.9521875381469727, 6994), ('ex08', 512, 0.5185939073562622, 13073), ('ex09', 512, 0.9839062690734863, 21015), ('ex10', 32, 0.8589041829109192, 2472), ('ex11', 64, 0.8192172050476074, 2328), ('ex12', 128, 0.7948426008224487, 3210), ('ex13', 256, 0.8292170763015747, 5331), ('ex14', 512, 0.782342791557312, 19413), ('ex15', 32, 0.8998421430587769, 1423), ('ex16', 64, 0.8942174911499023, 1877), ('ex17', 128, 0.741093099117279, 3969), ('ex18', 256, 0.7067192792892456, 5901), ('ex19', 512, 0.8243733644485474, 15585), ('ex20', 16, 0.5103126168251038, 1706), ('ex21', 16, 0.9925001263618469, 1974), ('ex22', 32, 0.5171876549720764, 1839), ('ex23', 32, 1.0, 2081), ('ex24', 64, 0.5109375715255737, 1937), ('ex25', 64, 1.0, 2497), ('ex26', 128, 0.5001562833786011, 1788), ('ex27', 128, 0.5101563930511475, 3681), ('ex28', 256, 0.5090625286102295, 4783), ('ex29', 256, 0.5078126788139343, 4222), ('ex30', 20, 0.9729684591293335, 2140), ('ex31', 40, 0.9696875810623169, 2482), ('ex32', 60, 0.9710938334465027, 2019), ('ex33', 80, 0.981874942779541, 3005), ('ex34', 100, 0.9843751192092896, 3771), ('ex35', 120, 0.9868753552436829, 4005), ('ex36', 140, 0.9831250309944153, 4913), ('ex37', 160, 0.9854687452316284, 5173), ('ex38', 180, 0.9710936546325684, 5506), ('ex39', 200, 0.9862500429153442, 6899), ('ex40', 16, 0.6257820129394531, 1765), ('ex41', 10, 0.9056239128112793, 1833), ('ex42', 32, 0.5123441219329834, 1699), ('ex43', 18, 0.5342187881469727, 1651), ('ex44', 64, 0.519687294960022, 1316), ('ex45', 34, 0.5142184495925903, 1430), ('ex46', 128, 0.504844069480896, 3148), ('ex47', 66, 0.5071873664855957, 1791), ('ex48', 256, 0.48515599966049194, 6776), ('ex49', 130, 0.5034373998641968, 2597), ('ex50', 19, 0.893280029296875, 1849), ('ex51', 44, 0.550312876701355, 1637), ('ex52', 59, 0.6262500286102295, 2206), ('ex53', 45, 0.8012482523918152, 1507), ('ex54', 48, 0.9345303773880005, 1912), ('ex55', 42, 0.9859377145767212, 2356), ('ex56', 83, 0.8735917806625366, 3335), ('ex57', 24, 0.9721872210502625, 2025), ('ex58', 80, 0.9534371495246887, 2989), ('ex59', 394, 0.8182799220085144, 7660), ('ex60', 43, 0.896873950958252, 2460), ('ex61', 37, 0.9967187643051147, 2333), ('ex62', 52, 0.8432797193527222, 2418), ('ex63', 38, 0.9165619611740112, 1974), ('ex64', 47, 0.9812498092651367, 1457), ('ex65', 19, 0.849373459815979, 1940), ('ex66', 47, 0.878436267375946, 1631), ('ex67', 46, 0.8435918688774109, 2278), ('ex68', 33, 0.9242178797721863, 2238), ('ex69', 16, 0.9696876406669617, 1665), ('ex70', 23, 0.9918750524520874, 1978), ('ex71', 23, 0.9943749308586121, 1803), ('ex72', 35, 0.9195305109024048, 2035), ('ex73', 16, 0.6775004267692566, 2342), ('ex74', 16, 0.5326565504074097, 1705), ('ex75', 16, 0.397812157869339, 557), ('ex76', 16, 0.2259373962879181, 1829), ('ex77', 16, 0.22515615820884705, 1382), ('ex78', 16, 0.6417193412780762, 2044), ('ex79', 16, 0.2501562237739563, 1731), ('ex80', 196, 0.6767185926437378, 3195), ('ex81', 196, 0.6976565718650818, 5163), ('ex82', 196, 0.7676557302474976, 5166), ('ex83', 196, 0.4490625262260437, 3823), ('ex84', 196, 0.5925005078315735, 3963), ('ex85', 196, 0.8289044499397278, 4038), ('ex86', 196, 0.621407151222229, 3573), ('ex87', 196, 0.5948439836502075, 4725), ('ex88', 196, 0.5767194032669067, 4193), ('ex89', 196, 0.5256251096725464, 4249), ('ex90', 768, 0.5009377598762512, 23578)]\n",
    "results_4 = [('ex00', 32, 0.6967187523841858, 3893), ('ex01', 32, 0.9317179918289185, 3345), ('ex02', 64, 0.7504680752754211, 4323), ('ex03', 64, 0.9160928726196289, 4033), ('ex04', 128, 0.5137501955032349, 3319), ('ex05', 128, 0.9671874046325684, 4176), ('ex06', 256, 0.5171875357627869, 5450), ('ex07', 256, 0.9387494325637817, 7999), ('ex08', 512, 0.506250262260437, 10781), ('ex09', 512, 0.9842191934585571, 12781), ('ex10', 32, 0.852811336517334, 4618), ('ex11', 64, 0.8257796168327332, 4650), ('ex12', 128, 0.7937485575675964, 4248), ('ex13', 256, 0.766874372959137, 5571), ('ex14', 512, 0.7571872472763062, 9639), ('ex15', 32, 0.8978112936019897, 4052), ('ex16', 64, 0.8917175531387329, 3395), ('ex17', 128, 0.7814052700996399, 3904), ('ex18', 256, 0.7017187476158142, 5977), ('ex19', 512, 0.5360939502716064, 14567), ('ex20', 16, 0.5235940217971802, 2525), ('ex21', 16, 0.9832812547683716, 3016), ('ex22', 32, 0.5195313692092896, 3529), ('ex23', 32, 1.0, 3897), ('ex24', 64, 0.4960938096046448, 3202), ('ex25', 64, 0.5051563382148743, 1984), ('ex26', 128, 0.5006247162818909, 4268), ('ex27', 128, 1.0, 4072), ('ex28', 256, 0.5001562833786011, 5106), ('ex29', 256, 1.0, 5495), ('ex30', 20, 0.9723436236381531, 2408), ('ex31', 40, 0.9679689407348633, 3133), ('ex32', 60, 0.970000147819519, 3903), ('ex33', 80, 0.9726560711860657, 4622), ('ex34', 100, 0.9659374356269836, 4073), ('ex35', 120, 0.9706252217292786, 4212), ('ex36', 140, 0.9831250309944153, 6847), ('ex37', 160, 0.9854686856269836, 7921), ('ex38', 180, 0.9715625643730164, 6846), ('ex39', 200, 0.9776561856269836, 4864), ('ex40', 16, 0.6123446226119995, 3653), ('ex41', 10, 0.8682795763015747, 2888), ('ex42', 32, 0.5074999928474426, 2691), ('ex43', 18, 0.5456250905990601, 2089), ('ex44', 64, 0.5009373426437378, 3761), ('ex45', 34, 0.5265626311302185, 3702), ('ex46', 128, 0.5040624141693115, 3523), ('ex47', 66, 0.5140625238418579, 3053), ('ex48', 256, 0.5145314335823059, 6002), ('ex49', 130, 0.504218578338623, 4125), ('ex50', 19, 0.8826549649238586, 4101), ('ex51', 44, 0.5628132820129395, 3282), ('ex52', 59, 0.6234382390975952, 3412), ('ex53', 45, 0.7984364628791809, 4348), ('ex54', 48, 0.9407804608345032, 3776), ('ex55', 42, 0.9848435521125793, 3745), ('ex56', 83, 0.8481237292289734, 2711), ('ex57', 24, 0.9803126454353333, 3764), ('ex58', 80, 0.9582813382148743, 4408), ('ex59', 394, 0.5928126573562622, 9604), ('ex60', 43, 0.8924986124038696, 4542), ('ex61', 37, 0.9967187643051147, 5008), ('ex62', 52, 0.8579676747322083, 4236), ('ex63', 38, 0.9328117370605469, 5118), ('ex64', 47, 0.981249988079071, 3000), ('ex65', 19, 0.9392186403274536, 3642), ('ex66', 47, 0.8510920405387878, 3496), ('ex67', 46, 0.8384356498718262, 4986), ('ex68', 33, 0.9060922861099243, 4214), ('ex69', 16, 0.9687502980232239, 3656), ('ex70', 23, 0.9918750524520874, 3640), ('ex71', 23, 0.9943751096725464, 4755), ('ex72', 35, 0.8670296669006348, 3828), ('ex73', 16, 0.659531831741333, 3241), ('ex74', 16, 0.5149997472763062, 2416), ('ex75', 16, 0.39749976992607117, 1010), ('ex76', 16, 0.22281226515769958, 2594), ('ex77', 16, 0.21796849370002747, 1850), ('ex78', 16, 0.6368752717971802, 2739), ('ex79', 16, 0.22499990463256836, 1672), ('ex80', 196, 0.5634379982948303, 9473), ('ex81', 196, 0.7568740844726562, 7756), ('ex82', 196, 0.7396873235702515, 6972), ('ex83', 196, 0.5912501811981201, 9066), ('ex84', 196, 0.4789060652256012, 7243), ('ex85', 196, 0.8015613555908203, 9721), ('ex86', 196, 0.5585938692092896, 8085), ('ex87', 196, 0.8017171621322632, 8356), ('ex88', 196, 0.7706242203712463, 8804), ('ex89', 196, 0.67875075340271, 5171), ('ex90', 768, 0.5274998545646667, 15571)]\n",
    "\n",
    "size_constraints = np.array([5000, 6000, 7500, 10000,100000, 1e8 ], dtype = int)\n",
    "\n",
    "def get_acc_sc( results ):\n",
    "    acc = np.asarray([res[2] for res in results])\n",
    "    aig_sizes = np.asarray([res[3] for res in results])\n",
    "    size_constraints = np.array([5000,6000,7000,10000,100000, 1e9 ])\n",
    "    acc_sc = []\n",
    "    for size_c in size_constraints:\n",
    "        size_satisfied = np.where( aig_sizes<=size_c )[0]\n",
    "        acc_sc.append( np.sum(acc[size_satisfied])/len(acc[size_satisfied]) )\n",
    "    return acc_sc\n",
    "\n",
    "acc_1a_sc = get_acc_sc( results_1a )\n",
    "acc_1b_sc = get_acc_sc( results_1b )\n",
    "acc_2a_sc = get_acc_sc( results_2a )\n",
    "acc_2b_sc = get_acc_sc( results_2b )\n",
    "acc_3_sc = get_acc_sc( results_3 )\n",
    "acc_4_sc = get_acc_sc( results_4 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0bfe0bfa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fd749c73eb0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x_array = np.arange(len(size_constraints))\n",
    "plt.plot(x_array, acc_1a_sc, label = '1a')\n",
    "plt.plot(x_array, acc_1b_sc, label = '1b')\n",
    "plt.plot(x_array, acc_2a_sc, label = '2a')\n",
    "plt.plot(x_array, acc_2b_sc, label = '2b')\n",
    "plt.plot(x_array, acc_3_sc, label = '3')\n",
    "plt.plot(x_array, acc_4_sc, label = '4')\n",
    "\n",
    "plt.xlabel('size constraint (#AND gates in AIG)')\n",
    "plt.ylabel('avg acc across bm satisfying constraints')\n",
    "plt.xticks(x_array, size_constraints )\n",
    "plt.ylim([0.6,0.8])\n",
    "plt.legend( loc = 'lower right')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad408e0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
